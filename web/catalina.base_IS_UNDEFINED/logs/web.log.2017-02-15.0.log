2017-02-15 20:15:05.877 [main] INFO  org.apache.kafka.clients.producer.ProducerConfig - ProducerConfig values: 
	acks = 1
	batch.size = 16384
	block.on.buffer.full = false
	bootstrap.servers = [10.1.131.18:9092]
	buffer.memory = 33554432
	client.id = 
	compression.type = none
	connections.max.idle.ms = 540000
	interceptor.classes = null
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 0
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.fetch.timeout.ms = 60000
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	receive.buffer.bytes = 32768
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 0
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	timeout.ms = 30000
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer

2017-02-15 20:15:05.995 [main] INFO  org.apache.kafka.clients.producer.ProducerConfig - ProducerConfig values: 
	acks = 1
	batch.size = 16384
	block.on.buffer.full = false
	bootstrap.servers = [10.1.131.18:9092]
	buffer.memory = 33554432
	client.id = producer-1
	compression.type = none
	connections.max.idle.ms = 540000
	interceptor.classes = null
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 0
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.fetch.timeout.ms = 60000
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	receive.buffer.bytes = 32768
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 0
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	timeout.ms = 30000
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer

2017-02-15 20:15:06.010 [main] DEBUG org.apache.kafka.common.metrics.Metrics - Added sensor with name bufferpool-wait-time
2017-02-15 20:15:06.015 [main] DEBUG org.apache.kafka.common.metrics.Metrics - Added sensor with name buffer-exhausted-records
2017-02-15 20:15:06.019 [main] DEBUG org.apache.kafka.clients.Metadata - Updated cluster metadata version 1 to Cluster(id = null, nodes = [10.1.131.18:9092 (id: -1 rack: null)], partitions = [])
2017-02-15 20:15:06.060 [main] DEBUG org.apache.kafka.common.metrics.Metrics - Added sensor with name connections-closed:
2017-02-15 20:15:06.060 [main] DEBUG org.apache.kafka.common.metrics.Metrics - Added sensor with name connections-created:
2017-02-15 20:15:06.060 [main] DEBUG org.apache.kafka.common.metrics.Metrics - Added sensor with name bytes-sent-received:
2017-02-15 20:15:06.061 [main] DEBUG org.apache.kafka.common.metrics.Metrics - Added sensor with name bytes-sent:
2017-02-15 20:15:06.062 [main] DEBUG org.apache.kafka.common.metrics.Metrics - Added sensor with name bytes-received:
2017-02-15 20:15:06.062 [main] DEBUG org.apache.kafka.common.metrics.Metrics - Added sensor with name select-time:
2017-02-15 20:15:06.063 [main] DEBUG org.apache.kafka.common.metrics.Metrics - Added sensor with name io-time:
2017-02-15 20:15:06.070 [main] DEBUG org.apache.kafka.common.metrics.Metrics - Added sensor with name batch-size
2017-02-15 20:15:06.071 [main] DEBUG org.apache.kafka.common.metrics.Metrics - Added sensor with name compression-rate
2017-02-15 20:15:06.071 [main] DEBUG org.apache.kafka.common.metrics.Metrics - Added sensor with name queue-time
2017-02-15 20:15:06.071 [main] DEBUG org.apache.kafka.common.metrics.Metrics - Added sensor with name request-time
2017-02-15 20:15:06.072 [main] DEBUG org.apache.kafka.common.metrics.Metrics - Added sensor with name produce-throttle-time
2017-02-15 20:15:06.072 [main] DEBUG org.apache.kafka.common.metrics.Metrics - Added sensor with name records-per-request
2017-02-15 20:15:06.072 [main] DEBUG org.apache.kafka.common.metrics.Metrics - Added sensor with name record-retries
2017-02-15 20:15:06.073 [main] DEBUG org.apache.kafka.common.metrics.Metrics - Added sensor with name errors
2017-02-15 20:15:06.073 [main] DEBUG org.apache.kafka.common.metrics.Metrics - Added sensor with name record-size-max
2017-02-15 20:15:06.075 [kafka-producer-network-thread | producer-1] DEBUG org.apache.kafka.clients.producer.internals.Sender - Starting Kafka producer I/O thread.
2017-02-15 20:15:06.080 [main] INFO  org.apache.kafka.common.utils.AppInfoParser - Kafka version : 0.10.1.0
2017-02-15 20:15:06.080 [main] INFO  org.apache.kafka.common.utils.AppInfoParser - Kafka commitId : 3402a74efb23d1d4
2017-02-15 20:15:06.081 [main] DEBUG org.apache.kafka.clients.producer.KafkaProducer - Kafka producer started
2017-02-15 20:15:06.119 [kafka-producer-network-thread | producer-1] DEBUG org.apache.kafka.clients.NetworkClient - Initialize connection to node -1 for sending metadata request
2017-02-15 20:15:06.119 [kafka-producer-network-thread | producer-1] DEBUG org.apache.kafka.clients.NetworkClient - Initiating connection to node -1 at 10.1.131.18:9092.
2017-02-15 20:15:06.162 [kafka-producer-network-thread | producer-1] DEBUG org.apache.kafka.common.metrics.Metrics - Added sensor with name node--1.bytes-sent
2017-02-15 20:15:06.162 [kafka-producer-network-thread | producer-1] DEBUG org.apache.kafka.common.metrics.Metrics - Added sensor with name node--1.bytes-received
2017-02-15 20:15:06.162 [kafka-producer-network-thread | producer-1] DEBUG org.apache.kafka.common.metrics.Metrics - Added sensor with name node--1.latency
2017-02-15 20:15:06.163 [kafka-producer-network-thread | producer-1] DEBUG org.apache.kafka.common.network.Selector - Created socket with SO_RCVBUF = 32768, SO_SNDBUF = 131072, SO_TIMEOUT = 0 to node -1
2017-02-15 20:15:06.163 [kafka-producer-network-thread | producer-1] DEBUG org.apache.kafka.clients.NetworkClient - Completed connection to node -1
2017-02-15 20:15:06.282 [kafka-producer-network-thread | producer-1] DEBUG org.apache.kafka.clients.NetworkClient - Sending metadata request {topics=[file_syn]} to node -1
2017-02-15 20:15:06.353 [kafka-producer-network-thread | producer-1] DEBUG org.apache.kafka.clients.Metadata - Updated cluster metadata version 2 to Cluster(id = 5ynpwwfGT3KEdCwLvR2Jog, nodes = [10.1.131.18:9092 (id: 0 rack: null)], partitions = [Partition(topic = file_syn, partition = 0, leader = 0, replicas = [0,], isr = [0,])])
2017-02-15 20:15:06.367 [kafka-producer-network-thread | producer-1] DEBUG org.apache.kafka.clients.NetworkClient - Initiating connection to node 0 at 10.1.131.18:9092.
2017-02-15 20:15:06.407 [kafka-producer-network-thread | producer-1] DEBUG org.apache.kafka.common.metrics.Metrics - Added sensor with name node-0.bytes-sent
2017-02-15 20:15:06.408 [kafka-producer-network-thread | producer-1] DEBUG org.apache.kafka.common.metrics.Metrics - Added sensor with name node-0.bytes-received
2017-02-15 20:15:06.408 [kafka-producer-network-thread | producer-1] DEBUG org.apache.kafka.common.metrics.Metrics - Added sensor with name node-0.latency
2017-02-15 20:15:06.409 [kafka-producer-network-thread | producer-1] DEBUG org.apache.kafka.common.network.Selector - Created socket with SO_RCVBUF = 32768, SO_SNDBUF = 131072, SO_TIMEOUT = 0 to node 0
2017-02-15 20:15:06.409 [kafka-producer-network-thread | producer-1] DEBUG org.apache.kafka.clients.NetworkClient - Completed connection to node 0
2017-02-15 20:15:06.409 [kafka-producer-network-thread | producer-1] DEBUG org.apache.kafka.common.metrics.Metrics - Added sensor with name topic.file_syn.records-per-batch
2017-02-15 20:15:06.410 [kafka-producer-network-thread | producer-1] DEBUG org.apache.kafka.common.metrics.Metrics - Added sensor with name topic.file_syn.bytes
2017-02-15 20:15:06.410 [kafka-producer-network-thread | producer-1] DEBUG org.apache.kafka.common.metrics.Metrics - Added sensor with name topic.file_syn.compression-rate
2017-02-15 20:15:06.410 [kafka-producer-network-thread | producer-1] DEBUG org.apache.kafka.common.metrics.Metrics - Added sensor with name topic.file_syn.record-retries
2017-02-15 20:15:06.410 [kafka-producer-network-thread | producer-1] DEBUG org.apache.kafka.common.metrics.Metrics - Added sensor with name topic.file_syn.record-errors
2017-02-15 20:16:02.765 [main] INFO  org.apache.kafka.clients.producer.ProducerConfig - ProducerConfig values: 
	acks = 1
	batch.size = 16384
	block.on.buffer.full = false
	bootstrap.servers = [10.1.131.18:9092]
	buffer.memory = 33554432
	client.id = 
	compression.type = none
	connections.max.idle.ms = 540000
	interceptor.classes = null
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 0
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.fetch.timeout.ms = 60000
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	receive.buffer.bytes = 32768
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 0
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	timeout.ms = 30000
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer

2017-02-15 20:16:02.822 [main] INFO  org.apache.kafka.clients.producer.ProducerConfig - ProducerConfig values: 
	acks = 1
	batch.size = 16384
	block.on.buffer.full = false
	bootstrap.servers = [10.1.131.18:9092]
	buffer.memory = 33554432
	client.id = producer-1
	compression.type = none
	connections.max.idle.ms = 540000
	interceptor.classes = null
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 0
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.fetch.timeout.ms = 60000
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	receive.buffer.bytes = 32768
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 0
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	timeout.ms = 30000
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer

2017-02-15 20:16:02.834 [main] DEBUG org.apache.kafka.common.metrics.Metrics - Added sensor with name bufferpool-wait-time
2017-02-15 20:16:02.840 [main] DEBUG org.apache.kafka.common.metrics.Metrics - Added sensor with name buffer-exhausted-records
2017-02-15 20:16:02.843 [main] DEBUG org.apache.kafka.clients.Metadata - Updated cluster metadata version 1 to Cluster(id = null, nodes = [10.1.131.18:9092 (id: -1 rack: null)], partitions = [])
2017-02-15 20:16:02.867 [main] DEBUG org.apache.kafka.common.metrics.Metrics - Added sensor with name connections-closed:
2017-02-15 20:16:02.868 [main] DEBUG org.apache.kafka.common.metrics.Metrics - Added sensor with name connections-created:
2017-02-15 20:16:02.868 [main] DEBUG org.apache.kafka.common.metrics.Metrics - Added sensor with name bytes-sent-received:
2017-02-15 20:16:02.868 [main] DEBUG org.apache.kafka.common.metrics.Metrics - Added sensor with name bytes-sent:
2017-02-15 20:16:02.870 [main] DEBUG org.apache.kafka.common.metrics.Metrics - Added sensor with name bytes-received:
2017-02-15 20:16:02.870 [main] DEBUG org.apache.kafka.common.metrics.Metrics - Added sensor with name select-time:
2017-02-15 20:16:02.870 [main] DEBUG org.apache.kafka.common.metrics.Metrics - Added sensor with name io-time:
2017-02-15 20:16:02.877 [main] DEBUG org.apache.kafka.common.metrics.Metrics - Added sensor with name batch-size
2017-02-15 20:16:02.877 [main] DEBUG org.apache.kafka.common.metrics.Metrics - Added sensor with name compression-rate
2017-02-15 20:16:02.878 [main] DEBUG org.apache.kafka.common.metrics.Metrics - Added sensor with name queue-time
2017-02-15 20:16:02.878 [main] DEBUG org.apache.kafka.common.metrics.Metrics - Added sensor with name request-time
2017-02-15 20:16:02.878 [main] DEBUG org.apache.kafka.common.metrics.Metrics - Added sensor with name produce-throttle-time
2017-02-15 20:16:02.879 [main] DEBUG org.apache.kafka.common.metrics.Metrics - Added sensor with name records-per-request
2017-02-15 20:16:02.879 [main] DEBUG org.apache.kafka.common.metrics.Metrics - Added sensor with name record-retries
2017-02-15 20:16:02.879 [main] DEBUG org.apache.kafka.common.metrics.Metrics - Added sensor with name errors
2017-02-15 20:16:02.879 [main] DEBUG org.apache.kafka.common.metrics.Metrics - Added sensor with name record-size-max
2017-02-15 20:16:02.882 [kafka-producer-network-thread | producer-1] DEBUG org.apache.kafka.clients.producer.internals.Sender - Starting Kafka producer I/O thread.
2017-02-15 20:16:02.886 [main] INFO  org.apache.kafka.common.utils.AppInfoParser - Kafka version : 0.10.1.0
2017-02-15 20:16:02.886 [main] INFO  org.apache.kafka.common.utils.AppInfoParser - Kafka commitId : 3402a74efb23d1d4
2017-02-15 20:16:02.887 [main] DEBUG org.apache.kafka.clients.producer.KafkaProducer - Kafka producer started
2017-02-15 20:16:02.943 [kafka-producer-network-thread | producer-1] DEBUG org.apache.kafka.clients.NetworkClient - Initialize connection to node -1 for sending metadata request
2017-02-15 20:16:02.943 [kafka-producer-network-thread | producer-1] DEBUG org.apache.kafka.clients.NetworkClient - Initiating connection to node -1 at 10.1.131.18:9092.
2017-02-15 20:16:02.988 [kafka-producer-network-thread | producer-1] DEBUG org.apache.kafka.common.metrics.Metrics - Added sensor with name node--1.bytes-sent
2017-02-15 20:16:02.989 [kafka-producer-network-thread | producer-1] DEBUG org.apache.kafka.common.metrics.Metrics - Added sensor with name node--1.bytes-received
2017-02-15 20:16:02.989 [kafka-producer-network-thread | producer-1] DEBUG org.apache.kafka.common.metrics.Metrics - Added sensor with name node--1.latency
2017-02-15 20:16:02.990 [kafka-producer-network-thread | producer-1] DEBUG org.apache.kafka.common.network.Selector - Created socket with SO_RCVBUF = 32768, SO_SNDBUF = 131072, SO_TIMEOUT = 0 to node -1
2017-02-15 20:16:02.990 [kafka-producer-network-thread | producer-1] DEBUG org.apache.kafka.clients.NetworkClient - Completed connection to node -1
2017-02-15 20:16:03.095 [kafka-producer-network-thread | producer-1] DEBUG org.apache.kafka.clients.NetworkClient - Sending metadata request {topics=[file_syn]} to node -1
2017-02-15 20:16:03.172 [kafka-producer-network-thread | producer-1] DEBUG org.apache.kafka.clients.Metadata - Updated cluster metadata version 2 to Cluster(id = 5ynpwwfGT3KEdCwLvR2Jog, nodes = [10.1.131.18:9092 (id: 0 rack: null)], partitions = [Partition(topic = file_syn, partition = 0, leader = 0, replicas = [0,], isr = [0,])])
2017-02-15 20:16:03.187 [kafka-producer-network-thread | producer-1] DEBUG org.apache.kafka.clients.NetworkClient - Initiating connection to node 0 at 10.1.131.18:9092.
2017-02-15 20:16:03.229 [kafka-producer-network-thread | producer-1] DEBUG org.apache.kafka.common.metrics.Metrics - Added sensor with name node-0.bytes-sent
2017-02-15 20:16:03.230 [kafka-producer-network-thread | producer-1] DEBUG org.apache.kafka.common.metrics.Metrics - Added sensor with name node-0.bytes-received
2017-02-15 20:16:03.230 [kafka-producer-network-thread | producer-1] DEBUG org.apache.kafka.common.metrics.Metrics - Added sensor with name node-0.latency
2017-02-15 20:16:03.231 [kafka-producer-network-thread | producer-1] DEBUG org.apache.kafka.common.network.Selector - Created socket with SO_RCVBUF = 32768, SO_SNDBUF = 131072, SO_TIMEOUT = 0 to node 0
2017-02-15 20:16:03.231 [kafka-producer-network-thread | producer-1] DEBUG org.apache.kafka.clients.NetworkClient - Completed connection to node 0
2017-02-15 20:16:03.231 [kafka-producer-network-thread | producer-1] DEBUG org.apache.kafka.common.metrics.Metrics - Added sensor with name topic.file_syn.records-per-batch
2017-02-15 20:16:03.231 [kafka-producer-network-thread | producer-1] DEBUG org.apache.kafka.common.metrics.Metrics - Added sensor with name topic.file_syn.bytes
2017-02-15 20:16:03.231 [kafka-producer-network-thread | producer-1] DEBUG org.apache.kafka.common.metrics.Metrics - Added sensor with name topic.file_syn.compression-rate
2017-02-15 20:16:03.232 [kafka-producer-network-thread | producer-1] DEBUG org.apache.kafka.common.metrics.Metrics - Added sensor with name topic.file_syn.record-retries
2017-02-15 20:16:03.232 [kafka-producer-network-thread | producer-1] DEBUG org.apache.kafka.common.metrics.Metrics - Added sensor with name topic.file_syn.record-errors
2017-02-15 20:16:22.877 [main] INFO  org.apache.kafka.clients.producer.ProducerConfig - ProducerConfig values: 
	acks = 1
	batch.size = 16384
	block.on.buffer.full = false
	bootstrap.servers = [10.1.131.18:9092]
	buffer.memory = 33554432
	client.id = 
	compression.type = none
	connections.max.idle.ms = 540000
	interceptor.classes = null
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 0
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.fetch.timeout.ms = 60000
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	receive.buffer.bytes = 32768
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 0
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	timeout.ms = 30000
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer

2017-02-15 20:16:22.927 [main] INFO  org.apache.kafka.clients.producer.ProducerConfig - ProducerConfig values: 
	acks = 1
	batch.size = 16384
	block.on.buffer.full = false
	bootstrap.servers = [10.1.131.18:9092]
	buffer.memory = 33554432
	client.id = producer-1
	compression.type = none
	connections.max.idle.ms = 540000
	interceptor.classes = null
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 0
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.fetch.timeout.ms = 60000
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	receive.buffer.bytes = 32768
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 0
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	timeout.ms = 30000
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer

2017-02-15 20:16:22.939 [main] DEBUG org.apache.kafka.common.metrics.Metrics - Added sensor with name bufferpool-wait-time
2017-02-15 20:16:22.946 [main] DEBUG org.apache.kafka.common.metrics.Metrics - Added sensor with name buffer-exhausted-records
2017-02-15 20:16:22.949 [main] DEBUG org.apache.kafka.clients.Metadata - Updated cluster metadata version 1 to Cluster(id = null, nodes = [10.1.131.18:9092 (id: -1 rack: null)], partitions = [])
2017-02-15 20:16:22.972 [main] DEBUG org.apache.kafka.common.metrics.Metrics - Added sensor with name connections-closed:
2017-02-15 20:16:22.972 [main] DEBUG org.apache.kafka.common.metrics.Metrics - Added sensor with name connections-created:
2017-02-15 20:16:22.972 [main] DEBUG org.apache.kafka.common.metrics.Metrics - Added sensor with name bytes-sent-received:
2017-02-15 20:16:22.973 [main] DEBUG org.apache.kafka.common.metrics.Metrics - Added sensor with name bytes-sent:
2017-02-15 20:16:22.974 [main] DEBUG org.apache.kafka.common.metrics.Metrics - Added sensor with name bytes-received:
2017-02-15 20:16:22.975 [main] DEBUG org.apache.kafka.common.metrics.Metrics - Added sensor with name select-time:
2017-02-15 20:16:22.976 [main] DEBUG org.apache.kafka.common.metrics.Metrics - Added sensor with name io-time:
2017-02-15 20:16:22.984 [main] DEBUG org.apache.kafka.common.metrics.Metrics - Added sensor with name batch-size
2017-02-15 20:16:22.984 [main] DEBUG org.apache.kafka.common.metrics.Metrics - Added sensor with name compression-rate
2017-02-15 20:16:22.985 [main] DEBUG org.apache.kafka.common.metrics.Metrics - Added sensor with name queue-time
2017-02-15 20:16:22.985 [main] DEBUG org.apache.kafka.common.metrics.Metrics - Added sensor with name request-time
2017-02-15 20:16:22.985 [main] DEBUG org.apache.kafka.common.metrics.Metrics - Added sensor with name produce-throttle-time
2017-02-15 20:16:22.986 [main] DEBUG org.apache.kafka.common.metrics.Metrics - Added sensor with name records-per-request
2017-02-15 20:16:22.986 [main] DEBUG org.apache.kafka.common.metrics.Metrics - Added sensor with name record-retries
2017-02-15 20:16:22.986 [main] DEBUG org.apache.kafka.common.metrics.Metrics - Added sensor with name errors
2017-02-15 20:16:22.986 [main] DEBUG org.apache.kafka.common.metrics.Metrics - Added sensor with name record-size-max
2017-02-15 20:16:22.989 [kafka-producer-network-thread | producer-1] DEBUG org.apache.kafka.clients.producer.internals.Sender - Starting Kafka producer I/O thread.
2017-02-15 20:16:22.993 [main] INFO  org.apache.kafka.common.utils.AppInfoParser - Kafka version : 0.10.1.0
2017-02-15 20:16:22.993 [main] INFO  org.apache.kafka.common.utils.AppInfoParser - Kafka commitId : 3402a74efb23d1d4
2017-02-15 20:16:22.994 [main] DEBUG org.apache.kafka.clients.producer.KafkaProducer - Kafka producer started
2017-02-15 20:16:23.048 [kafka-producer-network-thread | producer-1] DEBUG org.apache.kafka.clients.NetworkClient - Initialize connection to node -1 for sending metadata request
2017-02-15 20:16:23.048 [kafka-producer-network-thread | producer-1] DEBUG org.apache.kafka.clients.NetworkClient - Initiating connection to node -1 at 10.1.131.18:9092.
2017-02-15 20:16:23.199 [kafka-producer-network-thread | producer-1] DEBUG org.apache.kafka.common.metrics.Metrics - Added sensor with name node--1.bytes-sent
2017-02-15 20:16:23.199 [kafka-producer-network-thread | producer-1] DEBUG org.apache.kafka.common.metrics.Metrics - Added sensor with name node--1.bytes-received
2017-02-15 20:16:23.200 [kafka-producer-network-thread | producer-1] DEBUG org.apache.kafka.common.metrics.Metrics - Added sensor with name node--1.latency
2017-02-15 20:16:23.200 [kafka-producer-network-thread | producer-1] DEBUG org.apache.kafka.common.network.Selector - Created socket with SO_RCVBUF = 32768, SO_SNDBUF = 131072, SO_TIMEOUT = 0 to node -1
2017-02-15 20:16:23.200 [kafka-producer-network-thread | producer-1] DEBUG org.apache.kafka.clients.NetworkClient - Completed connection to node -1
2017-02-15 20:16:23.313 [kafka-producer-network-thread | producer-1] DEBUG org.apache.kafka.clients.NetworkClient - Sending metadata request {topics=[cache]} to node -1
2017-02-15 20:16:23.398 [kafka-producer-network-thread | producer-1] DEBUG org.apache.kafka.clients.Metadata - Updated cluster metadata version 2 to Cluster(id = 5ynpwwfGT3KEdCwLvR2Jog, nodes = [10.1.131.18:9092 (id: 0 rack: null)], partitions = [Partition(topic = cache, partition = 0, leader = 0, replicas = [0,], isr = [0,])])
2017-02-15 20:16:23.417 [kafka-producer-network-thread | producer-1] DEBUG org.apache.kafka.clients.NetworkClient - Initiating connection to node 0 at 10.1.131.18:9092.
2017-02-15 20:16:23.628 [kafka-producer-network-thread | producer-1] DEBUG org.apache.kafka.common.metrics.Metrics - Added sensor with name node-0.bytes-sent
2017-02-15 20:16:23.629 [kafka-producer-network-thread | producer-1] DEBUG org.apache.kafka.common.metrics.Metrics - Added sensor with name node-0.bytes-received
2017-02-15 20:16:23.630 [kafka-producer-network-thread | producer-1] DEBUG org.apache.kafka.common.metrics.Metrics - Added sensor with name node-0.latency
2017-02-15 20:16:23.630 [kafka-producer-network-thread | producer-1] DEBUG org.apache.kafka.common.network.Selector - Created socket with SO_RCVBUF = 32768, SO_SNDBUF = 131072, SO_TIMEOUT = 0 to node 0
2017-02-15 20:16:23.630 [kafka-producer-network-thread | producer-1] DEBUG org.apache.kafka.clients.NetworkClient - Completed connection to node 0
2017-02-15 20:16:23.631 [kafka-producer-network-thread | producer-1] DEBUG org.apache.kafka.common.metrics.Metrics - Added sensor with name topic.cache.records-per-batch
2017-02-15 20:16:23.631 [kafka-producer-network-thread | producer-1] DEBUG org.apache.kafka.common.metrics.Metrics - Added sensor with name topic.cache.bytes
2017-02-15 20:16:23.631 [kafka-producer-network-thread | producer-1] DEBUG org.apache.kafka.common.metrics.Metrics - Added sensor with name topic.cache.compression-rate
2017-02-15 20:16:23.631 [kafka-producer-network-thread | producer-1] DEBUG org.apache.kafka.common.metrics.Metrics - Added sensor with name topic.cache.record-retries
2017-02-15 20:16:23.632 [kafka-producer-network-thread | producer-1] DEBUG org.apache.kafka.common.metrics.Metrics - Added sensor with name topic.cache.record-errors
2017-02-15 20:28:30.299 [main] INFO  org.apache.kafka.clients.producer.ProducerConfig - ProducerConfig values: 
	acks = 1
	batch.size = 16384
	block.on.buffer.full = false
	bootstrap.servers = [10.1.131.18:9092]
	buffer.memory = 33554432
	client.id = 
	compression.type = none
	connections.max.idle.ms = 540000
	interceptor.classes = null
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 0
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.fetch.timeout.ms = 60000
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	receive.buffer.bytes = 32768
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 0
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	timeout.ms = 30000
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer

2017-02-15 20:28:30.352 [main] INFO  org.apache.kafka.clients.producer.ProducerConfig - ProducerConfig values: 
	acks = 1
	batch.size = 16384
	block.on.buffer.full = false
	bootstrap.servers = [10.1.131.18:9092]
	buffer.memory = 33554432
	client.id = producer-1
	compression.type = none
	connections.max.idle.ms = 540000
	interceptor.classes = null
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 0
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.fetch.timeout.ms = 60000
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	receive.buffer.bytes = 32768
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 0
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	timeout.ms = 30000
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer

2017-02-15 20:28:30.363 [main] DEBUG org.apache.kafka.common.metrics.Metrics - Added sensor with name bufferpool-wait-time
2017-02-15 20:28:30.369 [main] DEBUG org.apache.kafka.common.metrics.Metrics - Added sensor with name buffer-exhausted-records
2017-02-15 20:28:30.373 [main] DEBUG org.apache.kafka.clients.Metadata - Updated cluster metadata version 1 to Cluster(id = null, nodes = [10.1.131.18:9092 (id: -1 rack: null)], partitions = [])
2017-02-15 20:28:30.399 [main] DEBUG org.apache.kafka.common.metrics.Metrics - Added sensor with name connections-closed:
2017-02-15 20:28:30.400 [main] DEBUG org.apache.kafka.common.metrics.Metrics - Added sensor with name connections-created:
2017-02-15 20:28:30.400 [main] DEBUG org.apache.kafka.common.metrics.Metrics - Added sensor with name bytes-sent-received:
2017-02-15 20:28:30.400 [main] DEBUG org.apache.kafka.common.metrics.Metrics - Added sensor with name bytes-sent:
2017-02-15 20:28:30.402 [main] DEBUG org.apache.kafka.common.metrics.Metrics - Added sensor with name bytes-received:
2017-02-15 20:28:30.402 [main] DEBUG org.apache.kafka.common.metrics.Metrics - Added sensor with name select-time:
2017-02-15 20:28:30.403 [main] DEBUG org.apache.kafka.common.metrics.Metrics - Added sensor with name io-time:
2017-02-15 20:28:30.411 [main] DEBUG org.apache.kafka.common.metrics.Metrics - Added sensor with name batch-size
2017-02-15 20:28:30.411 [main] DEBUG org.apache.kafka.common.metrics.Metrics - Added sensor with name compression-rate
2017-02-15 20:28:30.412 [main] DEBUG org.apache.kafka.common.metrics.Metrics - Added sensor with name queue-time
2017-02-15 20:28:30.412 [main] DEBUG org.apache.kafka.common.metrics.Metrics - Added sensor with name request-time
2017-02-15 20:28:30.412 [main] DEBUG org.apache.kafka.common.metrics.Metrics - Added sensor with name produce-throttle-time
2017-02-15 20:28:30.412 [main] DEBUG org.apache.kafka.common.metrics.Metrics - Added sensor with name records-per-request
2017-02-15 20:28:30.413 [main] DEBUG org.apache.kafka.common.metrics.Metrics - Added sensor with name record-retries
2017-02-15 20:28:30.413 [main] DEBUG org.apache.kafka.common.metrics.Metrics - Added sensor with name errors
2017-02-15 20:28:30.413 [main] DEBUG org.apache.kafka.common.metrics.Metrics - Added sensor with name record-size-max
2017-02-15 20:28:30.416 [kafka-producer-network-thread | producer-1] DEBUG org.apache.kafka.clients.producer.internals.Sender - Starting Kafka producer I/O thread.
2017-02-15 20:28:30.421 [main] INFO  org.apache.kafka.common.utils.AppInfoParser - Kafka version : 0.10.1.0
2017-02-15 20:28:30.422 [main] INFO  org.apache.kafka.common.utils.AppInfoParser - Kafka commitId : 3402a74efb23d1d4
2017-02-15 20:28:30.423 [main] DEBUG org.apache.kafka.clients.producer.KafkaProducer - Kafka producer started
2017-02-15 20:28:30.473 [kafka-producer-network-thread | producer-1] DEBUG org.apache.kafka.clients.NetworkClient - Initialize connection to node -1 for sending metadata request
2017-02-15 20:28:30.473 [kafka-producer-network-thread | producer-1] DEBUG org.apache.kafka.clients.NetworkClient - Initiating connection to node -1 at 10.1.131.18:9092.
2017-02-15 20:28:30.524 [kafka-producer-network-thread | producer-1] DEBUG org.apache.kafka.common.metrics.Metrics - Added sensor with name node--1.bytes-sent
2017-02-15 20:28:30.525 [kafka-producer-network-thread | producer-1] DEBUG org.apache.kafka.common.metrics.Metrics - Added sensor with name node--1.bytes-received
2017-02-15 20:28:30.525 [kafka-producer-network-thread | producer-1] DEBUG org.apache.kafka.common.metrics.Metrics - Added sensor with name node--1.latency
2017-02-15 20:28:30.526 [kafka-producer-network-thread | producer-1] DEBUG org.apache.kafka.common.network.Selector - Created socket with SO_RCVBUF = 32768, SO_SNDBUF = 131072, SO_TIMEOUT = 0 to node -1
2017-02-15 20:28:30.526 [kafka-producer-network-thread | producer-1] DEBUG org.apache.kafka.clients.NetworkClient - Completed connection to node -1
2017-02-15 20:28:30.635 [kafka-producer-network-thread | producer-1] DEBUG org.apache.kafka.clients.NetworkClient - Sending metadata request {topics=[cache]} to node -1
2017-02-15 20:28:30.817 [kafka-producer-network-thread | producer-1] DEBUG org.apache.kafka.clients.Metadata - Updated cluster metadata version 2 to Cluster(id = 5ynpwwfGT3KEdCwLvR2Jog, nodes = [10.1.131.18:9092 (id: 0 rack: null)], partitions = [Partition(topic = cache, partition = 0, leader = 0, replicas = [0,], isr = [0,])])
2017-02-15 20:28:30.831 [kafka-producer-network-thread | producer-1] DEBUG org.apache.kafka.clients.NetworkClient - Initiating connection to node 0 at 10.1.131.18:9092.
2017-02-15 20:28:30.979 [kafka-producer-network-thread | producer-1] DEBUG org.apache.kafka.common.metrics.Metrics - Added sensor with name node-0.bytes-sent
2017-02-15 20:28:30.979 [kafka-producer-network-thread | producer-1] DEBUG org.apache.kafka.common.metrics.Metrics - Added sensor with name node-0.bytes-received
2017-02-15 20:28:30.980 [kafka-producer-network-thread | producer-1] DEBUG org.apache.kafka.common.metrics.Metrics - Added sensor with name node-0.latency
2017-02-15 20:28:30.980 [kafka-producer-network-thread | producer-1] DEBUG org.apache.kafka.common.network.Selector - Created socket with SO_RCVBUF = 32768, SO_SNDBUF = 131072, SO_TIMEOUT = 0 to node 0
2017-02-15 20:28:30.980 [kafka-producer-network-thread | producer-1] DEBUG org.apache.kafka.clients.NetworkClient - Completed connection to node 0
2017-02-15 20:28:30.981 [kafka-producer-network-thread | producer-1] DEBUG org.apache.kafka.common.metrics.Metrics - Added sensor with name topic.cache.records-per-batch
2017-02-15 20:28:30.982 [kafka-producer-network-thread | producer-1] DEBUG org.apache.kafka.common.metrics.Metrics - Added sensor with name topic.cache.bytes
2017-02-15 20:28:30.983 [kafka-producer-network-thread | producer-1] DEBUG org.apache.kafka.common.metrics.Metrics - Added sensor with name topic.cache.compression-rate
2017-02-15 20:28:30.983 [kafka-producer-network-thread | producer-1] DEBUG org.apache.kafka.common.metrics.Metrics - Added sensor with name topic.cache.record-retries
2017-02-15 20:28:30.983 [kafka-producer-network-thread | producer-1] DEBUG org.apache.kafka.common.metrics.Metrics - Added sensor with name topic.cache.record-errors
2017-02-15 20:28:49.201 [main] INFO  org.apache.kafka.clients.producer.ProducerConfig - ProducerConfig values: 
	acks = 1
	batch.size = 16384
	block.on.buffer.full = false
	bootstrap.servers = [10.1.131.18:9092]
	buffer.memory = 33554432
	client.id = 
	compression.type = none
	connections.max.idle.ms = 540000
	interceptor.classes = null
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 0
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.fetch.timeout.ms = 60000
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	receive.buffer.bytes = 32768
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 0
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	timeout.ms = 30000
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer

2017-02-15 20:28:49.265 [main] INFO  org.apache.kafka.clients.producer.ProducerConfig - ProducerConfig values: 
	acks = 1
	batch.size = 16384
	block.on.buffer.full = false
	bootstrap.servers = [10.1.131.18:9092]
	buffer.memory = 33554432
	client.id = producer-1
	compression.type = none
	connections.max.idle.ms = 540000
	interceptor.classes = null
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 0
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.fetch.timeout.ms = 60000
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	receive.buffer.bytes = 32768
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 0
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	timeout.ms = 30000
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer

2017-02-15 20:28:49.278 [main] DEBUG org.apache.kafka.common.metrics.Metrics - Added sensor with name bufferpool-wait-time
2017-02-15 20:28:49.284 [main] DEBUG org.apache.kafka.common.metrics.Metrics - Added sensor with name buffer-exhausted-records
2017-02-15 20:28:49.288 [main] DEBUG org.apache.kafka.clients.Metadata - Updated cluster metadata version 1 to Cluster(id = null, nodes = [10.1.131.18:9092 (id: -1 rack: null)], partitions = [])
2017-02-15 20:28:49.316 [main] DEBUG org.apache.kafka.common.metrics.Metrics - Added sensor with name connections-closed:
2017-02-15 20:28:49.317 [main] DEBUG org.apache.kafka.common.metrics.Metrics - Added sensor with name connections-created:
2017-02-15 20:28:49.317 [main] DEBUG org.apache.kafka.common.metrics.Metrics - Added sensor with name bytes-sent-received:
2017-02-15 20:28:49.317 [main] DEBUG org.apache.kafka.common.metrics.Metrics - Added sensor with name bytes-sent:
2017-02-15 20:28:49.319 [main] DEBUG org.apache.kafka.common.metrics.Metrics - Added sensor with name bytes-received:
2017-02-15 20:28:49.319 [main] DEBUG org.apache.kafka.common.metrics.Metrics - Added sensor with name select-time:
2017-02-15 20:28:49.320 [main] DEBUG org.apache.kafka.common.metrics.Metrics - Added sensor with name io-time:
2017-02-15 20:28:49.326 [main] DEBUG org.apache.kafka.common.metrics.Metrics - Added sensor with name batch-size
2017-02-15 20:28:49.327 [main] DEBUG org.apache.kafka.common.metrics.Metrics - Added sensor with name compression-rate
2017-02-15 20:28:49.327 [main] DEBUG org.apache.kafka.common.metrics.Metrics - Added sensor with name queue-time
2017-02-15 20:28:49.328 [main] DEBUG org.apache.kafka.common.metrics.Metrics - Added sensor with name request-time
2017-02-15 20:28:49.328 [main] DEBUG org.apache.kafka.common.metrics.Metrics - Added sensor with name produce-throttle-time
2017-02-15 20:28:49.329 [main] DEBUG org.apache.kafka.common.metrics.Metrics - Added sensor with name records-per-request
2017-02-15 20:28:49.330 [main] DEBUG org.apache.kafka.common.metrics.Metrics - Added sensor with name record-retries
2017-02-15 20:28:49.330 [main] DEBUG org.apache.kafka.common.metrics.Metrics - Added sensor with name errors
2017-02-15 20:28:49.330 [main] DEBUG org.apache.kafka.common.metrics.Metrics - Added sensor with name record-size-max
2017-02-15 20:28:49.333 [kafka-producer-network-thread | producer-1] DEBUG org.apache.kafka.clients.producer.internals.Sender - Starting Kafka producer I/O thread.
2017-02-15 20:28:49.337 [main] INFO  org.apache.kafka.common.utils.AppInfoParser - Kafka version : 0.10.1.0
2017-02-15 20:28:49.337 [main] INFO  org.apache.kafka.common.utils.AppInfoParser - Kafka commitId : 3402a74efb23d1d4
2017-02-15 20:28:49.338 [main] DEBUG org.apache.kafka.clients.producer.KafkaProducer - Kafka producer started
2017-02-15 20:28:49.388 [kafka-producer-network-thread | producer-1] DEBUG org.apache.kafka.clients.NetworkClient - Initialize connection to node -1 for sending metadata request
2017-02-15 20:28:49.388 [kafka-producer-network-thread | producer-1] DEBUG org.apache.kafka.clients.NetworkClient - Initiating connection to node -1 at 10.1.131.18:9092.
2017-02-15 20:28:49.430 [kafka-producer-network-thread | producer-1] DEBUG org.apache.kafka.common.metrics.Metrics - Added sensor with name node--1.bytes-sent
2017-02-15 20:28:49.430 [kafka-producer-network-thread | producer-1] DEBUG org.apache.kafka.common.metrics.Metrics - Added sensor with name node--1.bytes-received
2017-02-15 20:28:49.431 [kafka-producer-network-thread | producer-1] DEBUG org.apache.kafka.common.metrics.Metrics - Added sensor with name node--1.latency
2017-02-15 20:28:49.431 [kafka-producer-network-thread | producer-1] DEBUG org.apache.kafka.common.network.Selector - Created socket with SO_RCVBUF = 32768, SO_SNDBUF = 131072, SO_TIMEOUT = 0 to node -1
2017-02-15 20:28:49.431 [kafka-producer-network-thread | producer-1] DEBUG org.apache.kafka.clients.NetworkClient - Completed connection to node -1
2017-02-15 20:28:49.538 [kafka-producer-network-thread | producer-1] DEBUG org.apache.kafka.clients.NetworkClient - Sending metadata request {topics=[file_syn]} to node -1
2017-02-15 20:28:49.611 [kafka-producer-network-thread | producer-1] DEBUG org.apache.kafka.clients.Metadata - Updated cluster metadata version 2 to Cluster(id = 5ynpwwfGT3KEdCwLvR2Jog, nodes = [10.1.131.18:9092 (id: 0 rack: null)], partitions = [Partition(topic = file_syn, partition = 0, leader = 0, replicas = [0,], isr = [0,])])
2017-02-15 20:28:49.626 [kafka-producer-network-thread | producer-1] DEBUG org.apache.kafka.clients.NetworkClient - Initiating connection to node 0 at 10.1.131.18:9092.
2017-02-15 20:28:49.673 [kafka-producer-network-thread | producer-1] DEBUG org.apache.kafka.common.metrics.Metrics - Added sensor with name node-0.bytes-sent
2017-02-15 20:28:49.673 [kafka-producer-network-thread | producer-1] DEBUG org.apache.kafka.common.metrics.Metrics - Added sensor with name node-0.bytes-received
2017-02-15 20:28:49.673 [kafka-producer-network-thread | producer-1] DEBUG org.apache.kafka.common.metrics.Metrics - Added sensor with name node-0.latency
2017-02-15 20:28:49.674 [kafka-producer-network-thread | producer-1] DEBUG org.apache.kafka.common.network.Selector - Created socket with SO_RCVBUF = 32768, SO_SNDBUF = 131072, SO_TIMEOUT = 0 to node 0
2017-02-15 20:28:49.674 [kafka-producer-network-thread | producer-1] DEBUG org.apache.kafka.clients.NetworkClient - Completed connection to node 0
2017-02-15 20:28:49.674 [kafka-producer-network-thread | producer-1] DEBUG org.apache.kafka.common.metrics.Metrics - Added sensor with name topic.file_syn.records-per-batch
2017-02-15 20:28:49.675 [kafka-producer-network-thread | producer-1] DEBUG org.apache.kafka.common.metrics.Metrics - Added sensor with name topic.file_syn.bytes
2017-02-15 20:28:49.675 [kafka-producer-network-thread | producer-1] DEBUG org.apache.kafka.common.metrics.Metrics - Added sensor with name topic.file_syn.compression-rate
2017-02-15 20:28:49.675 [kafka-producer-network-thread | producer-1] DEBUG org.apache.kafka.common.metrics.Metrics - Added sensor with name topic.file_syn.record-retries
2017-02-15 20:28:49.675 [kafka-producer-network-thread | producer-1] DEBUG org.apache.kafka.common.metrics.Metrics - Added sensor with name topic.file_syn.record-errors
2017-02-15 20:29:02.932 [main] INFO  org.apache.kafka.clients.producer.ProducerConfig - ProducerConfig values: 
	acks = 1
	batch.size = 16384
	block.on.buffer.full = false
	bootstrap.servers = [10.1.131.18:9092]
	buffer.memory = 33554432
	client.id = 
	compression.type = none
	connections.max.idle.ms = 540000
	interceptor.classes = null
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 0
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.fetch.timeout.ms = 60000
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	receive.buffer.bytes = 32768
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 0
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	timeout.ms = 30000
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer

2017-02-15 20:29:02.986 [main] INFO  org.apache.kafka.clients.producer.ProducerConfig - ProducerConfig values: 
	acks = 1
	batch.size = 16384
	block.on.buffer.full = false
	bootstrap.servers = [10.1.131.18:9092]
	buffer.memory = 33554432
	client.id = producer-1
	compression.type = none
	connections.max.idle.ms = 540000
	interceptor.classes = null
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 0
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.fetch.timeout.ms = 60000
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	receive.buffer.bytes = 32768
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 0
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	timeout.ms = 30000
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer

2017-02-15 20:29:02.999 [main] DEBUG org.apache.kafka.common.metrics.Metrics - Added sensor with name bufferpool-wait-time
2017-02-15 20:29:03.005 [main] DEBUG org.apache.kafka.common.metrics.Metrics - Added sensor with name buffer-exhausted-records
2017-02-15 20:29:03.009 [main] DEBUG org.apache.kafka.clients.Metadata - Updated cluster metadata version 1 to Cluster(id = null, nodes = [10.1.131.18:9092 (id: -1 rack: null)], partitions = [])
2017-02-15 20:29:03.033 [main] DEBUG org.apache.kafka.common.metrics.Metrics - Added sensor with name connections-closed:
2017-02-15 20:29:03.033 [main] DEBUG org.apache.kafka.common.metrics.Metrics - Added sensor with name connections-created:
2017-02-15 20:29:03.033 [main] DEBUG org.apache.kafka.common.metrics.Metrics - Added sensor with name bytes-sent-received:
2017-02-15 20:29:03.034 [main] DEBUG org.apache.kafka.common.metrics.Metrics - Added sensor with name bytes-sent:
2017-02-15 20:29:03.035 [main] DEBUG org.apache.kafka.common.metrics.Metrics - Added sensor with name bytes-received:
2017-02-15 20:29:03.036 [main] DEBUG org.apache.kafka.common.metrics.Metrics - Added sensor with name select-time:
2017-02-15 20:29:03.036 [main] DEBUG org.apache.kafka.common.metrics.Metrics - Added sensor with name io-time:
2017-02-15 20:29:03.044 [main] DEBUG org.apache.kafka.common.metrics.Metrics - Added sensor with name batch-size
2017-02-15 20:29:03.045 [main] DEBUG org.apache.kafka.common.metrics.Metrics - Added sensor with name compression-rate
2017-02-15 20:29:03.045 [main] DEBUG org.apache.kafka.common.metrics.Metrics - Added sensor with name queue-time
2017-02-15 20:29:03.045 [main] DEBUG org.apache.kafka.common.metrics.Metrics - Added sensor with name request-time
2017-02-15 20:29:03.046 [main] DEBUG org.apache.kafka.common.metrics.Metrics - Added sensor with name produce-throttle-time
2017-02-15 20:29:03.046 [main] DEBUG org.apache.kafka.common.metrics.Metrics - Added sensor with name records-per-request
2017-02-15 20:29:03.046 [main] DEBUG org.apache.kafka.common.metrics.Metrics - Added sensor with name record-retries
2017-02-15 20:29:03.046 [main] DEBUG org.apache.kafka.common.metrics.Metrics - Added sensor with name errors
2017-02-15 20:29:03.047 [main] DEBUG org.apache.kafka.common.metrics.Metrics - Added sensor with name record-size-max
2017-02-15 20:29:03.049 [kafka-producer-network-thread | producer-1] DEBUG org.apache.kafka.clients.producer.internals.Sender - Starting Kafka producer I/O thread.
2017-02-15 20:29:03.053 [main] INFO  org.apache.kafka.common.utils.AppInfoParser - Kafka version : 0.10.1.0
2017-02-15 20:29:03.054 [main] INFO  org.apache.kafka.common.utils.AppInfoParser - Kafka commitId : 3402a74efb23d1d4
2017-02-15 20:29:03.054 [main] DEBUG org.apache.kafka.clients.producer.KafkaProducer - Kafka producer started
2017-02-15 20:29:03.109 [kafka-producer-network-thread | producer-1] DEBUG org.apache.kafka.clients.NetworkClient - Initialize connection to node -1 for sending metadata request
2017-02-15 20:29:03.109 [kafka-producer-network-thread | producer-1] DEBUG org.apache.kafka.clients.NetworkClient - Initiating connection to node -1 at 10.1.131.18:9092.
2017-02-15 20:29:03.152 [kafka-producer-network-thread | producer-1] DEBUG org.apache.kafka.common.metrics.Metrics - Added sensor with name node--1.bytes-sent
2017-02-15 20:29:03.152 [kafka-producer-network-thread | producer-1] DEBUG org.apache.kafka.common.metrics.Metrics - Added sensor with name node--1.bytes-received
2017-02-15 20:29:03.153 [kafka-producer-network-thread | producer-1] DEBUG org.apache.kafka.common.metrics.Metrics - Added sensor with name node--1.latency
2017-02-15 20:29:03.153 [kafka-producer-network-thread | producer-1] DEBUG org.apache.kafka.common.network.Selector - Created socket with SO_RCVBUF = 32768, SO_SNDBUF = 131072, SO_TIMEOUT = 0 to node -1
2017-02-15 20:29:03.154 [kafka-producer-network-thread | producer-1] DEBUG org.apache.kafka.clients.NetworkClient - Completed connection to node -1
2017-02-15 20:29:03.271 [kafka-producer-network-thread | producer-1] DEBUG org.apache.kafka.clients.NetworkClient - Sending metadata request {topics=[file_syn]} to node -1
2017-02-15 20:29:03.347 [kafka-producer-network-thread | producer-1] DEBUG org.apache.kafka.clients.Metadata - Updated cluster metadata version 2 to Cluster(id = 5ynpwwfGT3KEdCwLvR2Jog, nodes = [10.1.131.18:9092 (id: 0 rack: null)], partitions = [Partition(topic = file_syn, partition = 0, leader = 0, replicas = [0,], isr = [0,])])
2017-02-15 20:29:03.360 [kafka-producer-network-thread | producer-1] DEBUG org.apache.kafka.clients.NetworkClient - Initiating connection to node 0 at 10.1.131.18:9092.
2017-02-15 20:29:03.401 [kafka-producer-network-thread | producer-1] DEBUG org.apache.kafka.common.metrics.Metrics - Added sensor with name node-0.bytes-sent
2017-02-15 20:29:03.402 [kafka-producer-network-thread | producer-1] DEBUG org.apache.kafka.common.metrics.Metrics - Added sensor with name node-0.bytes-received
2017-02-15 20:29:03.402 [kafka-producer-network-thread | producer-1] DEBUG org.apache.kafka.common.metrics.Metrics - Added sensor with name node-0.latency
2017-02-15 20:29:03.402 [kafka-producer-network-thread | producer-1] DEBUG org.apache.kafka.common.network.Selector - Created socket with SO_RCVBUF = 32768, SO_SNDBUF = 131072, SO_TIMEOUT = 0 to node 0
2017-02-15 20:29:03.402 [kafka-producer-network-thread | producer-1] DEBUG org.apache.kafka.clients.NetworkClient - Completed connection to node 0
2017-02-15 20:29:03.402 [kafka-producer-network-thread | producer-1] DEBUG org.apache.kafka.common.metrics.Metrics - Added sensor with name topic.file_syn.records-per-batch
2017-02-15 20:29:03.403 [kafka-producer-network-thread | producer-1] DEBUG org.apache.kafka.common.metrics.Metrics - Added sensor with name topic.file_syn.bytes
2017-02-15 20:29:03.403 [kafka-producer-network-thread | producer-1] DEBUG org.apache.kafka.common.metrics.Metrics - Added sensor with name topic.file_syn.compression-rate
2017-02-15 20:29:03.403 [kafka-producer-network-thread | producer-1] DEBUG org.apache.kafka.common.metrics.Metrics - Added sensor with name topic.file_syn.record-retries
2017-02-15 20:29:03.403 [kafka-producer-network-thread | producer-1] DEBUG org.apache.kafka.common.metrics.Metrics - Added sensor with name topic.file_syn.record-errors
2017-02-15 20:29:11.211 [main] INFO  org.apache.kafka.clients.producer.ProducerConfig - ProducerConfig values: 
	acks = 1
	batch.size = 16384
	block.on.buffer.full = false
	bootstrap.servers = [10.1.131.18:9092]
	buffer.memory = 33554432
	client.id = 
	compression.type = none
	connections.max.idle.ms = 540000
	interceptor.classes = null
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 0
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.fetch.timeout.ms = 60000
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	receive.buffer.bytes = 32768
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 0
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	timeout.ms = 30000
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer

2017-02-15 20:29:11.267 [main] INFO  org.apache.kafka.clients.producer.ProducerConfig - ProducerConfig values: 
	acks = 1
	batch.size = 16384
	block.on.buffer.full = false
	bootstrap.servers = [10.1.131.18:9092]
	buffer.memory = 33554432
	client.id = producer-1
	compression.type = none
	connections.max.idle.ms = 540000
	interceptor.classes = null
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 0
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.fetch.timeout.ms = 60000
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	receive.buffer.bytes = 32768
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 0
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	timeout.ms = 30000
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer

2017-02-15 20:29:11.279 [main] DEBUG org.apache.kafka.common.metrics.Metrics - Added sensor with name bufferpool-wait-time
2017-02-15 20:29:11.284 [main] DEBUG org.apache.kafka.common.metrics.Metrics - Added sensor with name buffer-exhausted-records
2017-02-15 20:29:11.287 [main] DEBUG org.apache.kafka.clients.Metadata - Updated cluster metadata version 1 to Cluster(id = null, nodes = [10.1.131.18:9092 (id: -1 rack: null)], partitions = [])
2017-02-15 20:29:11.312 [main] DEBUG org.apache.kafka.common.metrics.Metrics - Added sensor with name connections-closed:
2017-02-15 20:29:11.312 [main] DEBUG org.apache.kafka.common.metrics.Metrics - Added sensor with name connections-created:
2017-02-15 20:29:11.313 [main] DEBUG org.apache.kafka.common.metrics.Metrics - Added sensor with name bytes-sent-received:
2017-02-15 20:29:11.313 [main] DEBUG org.apache.kafka.common.metrics.Metrics - Added sensor with name bytes-sent:
2017-02-15 20:29:11.315 [main] DEBUG org.apache.kafka.common.metrics.Metrics - Added sensor with name bytes-received:
2017-02-15 20:29:11.315 [main] DEBUG org.apache.kafka.common.metrics.Metrics - Added sensor with name select-time:
2017-02-15 20:29:11.315 [main] DEBUG org.apache.kafka.common.metrics.Metrics - Added sensor with name io-time:
2017-02-15 20:29:11.323 [main] DEBUG org.apache.kafka.common.metrics.Metrics - Added sensor with name batch-size
2017-02-15 20:29:11.323 [main] DEBUG org.apache.kafka.common.metrics.Metrics - Added sensor with name compression-rate
2017-02-15 20:29:11.324 [main] DEBUG org.apache.kafka.common.metrics.Metrics - Added sensor with name queue-time
2017-02-15 20:29:11.324 [main] DEBUG org.apache.kafka.common.metrics.Metrics - Added sensor with name request-time
2017-02-15 20:29:11.324 [main] DEBUG org.apache.kafka.common.metrics.Metrics - Added sensor with name produce-throttle-time
2017-02-15 20:29:11.325 [main] DEBUG org.apache.kafka.common.metrics.Metrics - Added sensor with name records-per-request
2017-02-15 20:29:11.325 [main] DEBUG org.apache.kafka.common.metrics.Metrics - Added sensor with name record-retries
2017-02-15 20:29:11.325 [main] DEBUG org.apache.kafka.common.metrics.Metrics - Added sensor with name errors
2017-02-15 20:29:11.325 [main] DEBUG org.apache.kafka.common.metrics.Metrics - Added sensor with name record-size-max
2017-02-15 20:29:11.328 [kafka-producer-network-thread | producer-1] DEBUG org.apache.kafka.clients.producer.internals.Sender - Starting Kafka producer I/O thread.
2017-02-15 20:29:11.331 [main] INFO  org.apache.kafka.common.utils.AppInfoParser - Kafka version : 0.10.1.0
2017-02-15 20:29:11.332 [main] INFO  org.apache.kafka.common.utils.AppInfoParser - Kafka commitId : 3402a74efb23d1d4
2017-02-15 20:29:11.332 [main] DEBUG org.apache.kafka.clients.producer.KafkaProducer - Kafka producer started
2017-02-15 20:29:11.387 [kafka-producer-network-thread | producer-1] DEBUG org.apache.kafka.clients.NetworkClient - Initialize connection to node -1 for sending metadata request
2017-02-15 20:29:11.388 [kafka-producer-network-thread | producer-1] DEBUG org.apache.kafka.clients.NetworkClient - Initiating connection to node -1 at 10.1.131.18:9092.
2017-02-15 20:29:11.430 [kafka-producer-network-thread | producer-1] DEBUG org.apache.kafka.common.metrics.Metrics - Added sensor with name node--1.bytes-sent
2017-02-15 20:29:11.431 [kafka-producer-network-thread | producer-1] DEBUG org.apache.kafka.common.metrics.Metrics - Added sensor with name node--1.bytes-received
2017-02-15 20:29:11.431 [kafka-producer-network-thread | producer-1] DEBUG org.apache.kafka.common.metrics.Metrics - Added sensor with name node--1.latency
2017-02-15 20:29:11.432 [kafka-producer-network-thread | producer-1] DEBUG org.apache.kafka.common.network.Selector - Created socket with SO_RCVBUF = 32768, SO_SNDBUF = 131072, SO_TIMEOUT = 0 to node -1
2017-02-15 20:29:11.432 [kafka-producer-network-thread | producer-1] DEBUG org.apache.kafka.clients.NetworkClient - Completed connection to node -1
2017-02-15 20:29:11.539 [kafka-producer-network-thread | producer-1] DEBUG org.apache.kafka.clients.NetworkClient - Sending metadata request {topics=[cache]} to node -1
2017-02-15 20:29:11.615 [kafka-producer-network-thread | producer-1] DEBUG org.apache.kafka.clients.Metadata - Updated cluster metadata version 2 to Cluster(id = 5ynpwwfGT3KEdCwLvR2Jog, nodes = [10.1.131.18:9092 (id: 0 rack: null)], partitions = [Partition(topic = cache, partition = 0, leader = 0, replicas = [0,], isr = [0,])])
2017-02-15 20:29:11.635 [kafka-producer-network-thread | producer-1] DEBUG org.apache.kafka.clients.NetworkClient - Initiating connection to node 0 at 10.1.131.18:9092.
2017-02-15 20:29:11.674 [kafka-producer-network-thread | producer-1] DEBUG org.apache.kafka.common.metrics.Metrics - Added sensor with name node-0.bytes-sent
2017-02-15 20:29:11.675 [kafka-producer-network-thread | producer-1] DEBUG org.apache.kafka.common.metrics.Metrics - Added sensor with name node-0.bytes-received
2017-02-15 20:29:11.675 [kafka-producer-network-thread | producer-1] DEBUG org.apache.kafka.common.metrics.Metrics - Added sensor with name node-0.latency
2017-02-15 20:29:11.676 [kafka-producer-network-thread | producer-1] DEBUG org.apache.kafka.common.network.Selector - Created socket with SO_RCVBUF = 32768, SO_SNDBUF = 131072, SO_TIMEOUT = 0 to node 0
2017-02-15 20:29:11.676 [kafka-producer-network-thread | producer-1] DEBUG org.apache.kafka.clients.NetworkClient - Completed connection to node 0
2017-02-15 20:29:11.676 [kafka-producer-network-thread | producer-1] DEBUG org.apache.kafka.common.metrics.Metrics - Added sensor with name topic.cache.records-per-batch
2017-02-15 20:29:11.676 [kafka-producer-network-thread | producer-1] DEBUG org.apache.kafka.common.metrics.Metrics - Added sensor with name topic.cache.bytes
2017-02-15 20:29:11.677 [kafka-producer-network-thread | producer-1] DEBUG org.apache.kafka.common.metrics.Metrics - Added sensor with name topic.cache.compression-rate
2017-02-15 20:29:11.677 [kafka-producer-network-thread | producer-1] DEBUG org.apache.kafka.common.metrics.Metrics - Added sensor with name topic.cache.record-retries
2017-02-15 20:29:11.677 [kafka-producer-network-thread | producer-1] DEBUG org.apache.kafka.common.metrics.Metrics - Added sensor with name topic.cache.record-errors
2017-02-15 20:43:45.302 [main] INFO  org.apache.kafka.clients.producer.ProducerConfig - ProducerConfig values: 
	acks = 1
	batch.size = 16384
	block.on.buffer.full = false
	bootstrap.servers = [10.1.131.18:9092]
	buffer.memory = 33554432
	client.id = 
	compression.type = none
	connections.max.idle.ms = 540000
	interceptor.classes = null
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 0
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.fetch.timeout.ms = 60000
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	receive.buffer.bytes = 32768
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 0
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	timeout.ms = 30000
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer

2017-02-15 20:43:45.370 [main] INFO  org.apache.kafka.clients.producer.ProducerConfig - ProducerConfig values: 
	acks = 1
	batch.size = 16384
	block.on.buffer.full = false
	bootstrap.servers = [10.1.131.18:9092]
	buffer.memory = 33554432
	client.id = producer-1
	compression.type = none
	connections.max.idle.ms = 540000
	interceptor.classes = null
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 0
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.fetch.timeout.ms = 60000
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	receive.buffer.bytes = 32768
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 0
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	timeout.ms = 30000
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer

2017-02-15 20:43:45.386 [main] DEBUG org.apache.kafka.common.metrics.Metrics - Added sensor with name bufferpool-wait-time
2017-02-15 20:43:45.394 [main] DEBUG org.apache.kafka.common.metrics.Metrics - Added sensor with name buffer-exhausted-records
2017-02-15 20:43:45.398 [main] DEBUG org.apache.kafka.clients.Metadata - Updated cluster metadata version 1 to Cluster(id = null, nodes = [10.1.131.18:9092 (id: -1 rack: null)], partitions = [])
2017-02-15 20:43:45.426 [main] DEBUG org.apache.kafka.common.metrics.Metrics - Added sensor with name connections-closed:
2017-02-15 20:43:45.427 [main] DEBUG org.apache.kafka.common.metrics.Metrics - Added sensor with name connections-created:
2017-02-15 20:43:45.427 [main] DEBUG org.apache.kafka.common.metrics.Metrics - Added sensor with name bytes-sent-received:
2017-02-15 20:43:45.427 [main] DEBUG org.apache.kafka.common.metrics.Metrics - Added sensor with name bytes-sent:
2017-02-15 20:43:45.429 [main] DEBUG org.apache.kafka.common.metrics.Metrics - Added sensor with name bytes-received:
2017-02-15 20:43:45.430 [main] DEBUG org.apache.kafka.common.metrics.Metrics - Added sensor with name select-time:
2017-02-15 20:43:45.430 [main] DEBUG org.apache.kafka.common.metrics.Metrics - Added sensor with name io-time:
2017-02-15 20:43:45.438 [main] DEBUG org.apache.kafka.common.metrics.Metrics - Added sensor with name batch-size
2017-02-15 20:43:45.439 [main] DEBUG org.apache.kafka.common.metrics.Metrics - Added sensor with name compression-rate
2017-02-15 20:43:45.439 [main] DEBUG org.apache.kafka.common.metrics.Metrics - Added sensor with name queue-time
2017-02-15 20:43:45.440 [main] DEBUG org.apache.kafka.common.metrics.Metrics - Added sensor with name request-time
2017-02-15 20:43:45.440 [main] DEBUG org.apache.kafka.common.metrics.Metrics - Added sensor with name produce-throttle-time
2017-02-15 20:43:45.440 [main] DEBUG org.apache.kafka.common.metrics.Metrics - Added sensor with name records-per-request
2017-02-15 20:43:45.441 [main] DEBUG org.apache.kafka.common.metrics.Metrics - Added sensor with name record-retries
2017-02-15 20:43:45.441 [main] DEBUG org.apache.kafka.common.metrics.Metrics - Added sensor with name errors
2017-02-15 20:43:45.441 [main] DEBUG org.apache.kafka.common.metrics.Metrics - Added sensor with name record-size-max
2017-02-15 20:43:45.444 [kafka-producer-network-thread | producer-1] DEBUG org.apache.kafka.clients.producer.internals.Sender - Starting Kafka producer I/O thread.
2017-02-15 20:43:45.448 [main] INFO  org.apache.kafka.common.utils.AppInfoParser - Kafka version : 0.10.1.0
2017-02-15 20:43:45.448 [main] INFO  org.apache.kafka.common.utils.AppInfoParser - Kafka commitId : 3402a74efb23d1d4
2017-02-15 20:43:45.449 [main] DEBUG org.apache.kafka.clients.producer.KafkaProducer - Kafka producer started
2017-02-15 20:43:45.498 [kafka-producer-network-thread | producer-1] DEBUG org.apache.kafka.clients.NetworkClient - Initialize connection to node -1 for sending metadata request
2017-02-15 20:43:45.498 [kafka-producer-network-thread | producer-1] DEBUG org.apache.kafka.clients.NetworkClient - Initiating connection to node -1 at 10.1.131.18:9092.
2017-02-15 20:43:45.543 [kafka-producer-network-thread | producer-1] DEBUG org.apache.kafka.common.metrics.Metrics - Added sensor with name node--1.bytes-sent
2017-02-15 20:43:45.544 [kafka-producer-network-thread | producer-1] DEBUG org.apache.kafka.common.metrics.Metrics - Added sensor with name node--1.bytes-received
2017-02-15 20:43:45.544 [kafka-producer-network-thread | producer-1] DEBUG org.apache.kafka.common.metrics.Metrics - Added sensor with name node--1.latency
2017-02-15 20:43:45.545 [kafka-producer-network-thread | producer-1] DEBUG org.apache.kafka.common.network.Selector - Created socket with SO_RCVBUF = 32768, SO_SNDBUF = 131072, SO_TIMEOUT = 0 to node -1
2017-02-15 20:43:45.545 [kafka-producer-network-thread | producer-1] DEBUG org.apache.kafka.clients.NetworkClient - Completed connection to node -1
2017-02-15 20:43:45.681 [kafka-producer-network-thread | producer-1] DEBUG org.apache.kafka.clients.NetworkClient - Sending metadata request {topics=[file_syn2]} to node -1
2017-02-15 20:43:45.752 [kafka-producer-network-thread | producer-1] DEBUG org.apache.kafka.clients.Metadata - Updated cluster metadata version 2 to Cluster(id = 5ynpwwfGT3KEdCwLvR2Jog, nodes = [10.1.131.18:9092 (id: 0 rack: null)], partitions = [Partition(topic = file_syn2, partition = 0, leader = 0, replicas = [0,], isr = [0,])])
2017-02-15 20:43:45.767 [kafka-producer-network-thread | producer-1] DEBUG org.apache.kafka.clients.NetworkClient - Initiating connection to node 0 at 10.1.131.18:9092.
2017-02-15 20:43:45.812 [kafka-producer-network-thread | producer-1] DEBUG org.apache.kafka.common.metrics.Metrics - Added sensor with name node-0.bytes-sent
2017-02-15 20:43:45.813 [kafka-producer-network-thread | producer-1] DEBUG org.apache.kafka.common.metrics.Metrics - Added sensor with name node-0.bytes-received
2017-02-15 20:43:45.813 [kafka-producer-network-thread | producer-1] DEBUG org.apache.kafka.common.metrics.Metrics - Added sensor with name node-0.latency
2017-02-15 20:43:45.813 [kafka-producer-network-thread | producer-1] DEBUG org.apache.kafka.common.network.Selector - Created socket with SO_RCVBUF = 32768, SO_SNDBUF = 131072, SO_TIMEOUT = 0 to node 0
2017-02-15 20:43:45.813 [kafka-producer-network-thread | producer-1] DEBUG org.apache.kafka.clients.NetworkClient - Completed connection to node 0
2017-02-15 20:43:45.814 [kafka-producer-network-thread | producer-1] DEBUG org.apache.kafka.common.metrics.Metrics - Added sensor with name topic.file_syn2.records-per-batch
2017-02-15 20:43:45.814 [kafka-producer-network-thread | producer-1] DEBUG org.apache.kafka.common.metrics.Metrics - Added sensor with name topic.file_syn2.bytes
2017-02-15 20:43:45.814 [kafka-producer-network-thread | producer-1] DEBUG org.apache.kafka.common.metrics.Metrics - Added sensor with name topic.file_syn2.compression-rate
2017-02-15 20:43:45.814 [kafka-producer-network-thread | producer-1] DEBUG org.apache.kafka.common.metrics.Metrics - Added sensor with name topic.file_syn2.record-retries
2017-02-15 20:43:45.814 [kafka-producer-network-thread | producer-1] DEBUG org.apache.kafka.common.metrics.Metrics - Added sensor with name topic.file_syn2.record-errors
2017-02-15 20:48:26.535 [main] INFO  org.apache.kafka.clients.producer.ProducerConfig - ProducerConfig values: 
	acks = 1
	batch.size = 16384
	block.on.buffer.full = false
	bootstrap.servers = [10.1.131.18:9092]
	buffer.memory = 33554432
	client.id = 
	compression.type = none
	connections.max.idle.ms = 540000
	interceptor.classes = null
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 0
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.fetch.timeout.ms = 60000
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	receive.buffer.bytes = 32768
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 0
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	timeout.ms = 30000
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer

2017-02-15 20:48:26.588 [main] INFO  org.apache.kafka.clients.producer.ProducerConfig - ProducerConfig values: 
	acks = 1
	batch.size = 16384
	block.on.buffer.full = false
	bootstrap.servers = [10.1.131.18:9092]
	buffer.memory = 33554432
	client.id = producer-1
	compression.type = none
	connections.max.idle.ms = 540000
	interceptor.classes = null
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 0
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.fetch.timeout.ms = 60000
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	receive.buffer.bytes = 32768
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 0
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	timeout.ms = 30000
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer

2017-02-15 20:48:26.599 [main] DEBUG org.apache.kafka.common.metrics.Metrics - Added sensor with name bufferpool-wait-time
2017-02-15 20:48:26.607 [main] DEBUG org.apache.kafka.common.metrics.Metrics - Added sensor with name buffer-exhausted-records
2017-02-15 20:48:26.610 [main] DEBUG org.apache.kafka.clients.Metadata - Updated cluster metadata version 1 to Cluster(id = null, nodes = [10.1.131.18:9092 (id: -1 rack: null)], partitions = [])
2017-02-15 20:48:26.634 [main] DEBUG org.apache.kafka.common.metrics.Metrics - Added sensor with name connections-closed:
2017-02-15 20:48:26.635 [main] DEBUG org.apache.kafka.common.metrics.Metrics - Added sensor with name connections-created:
2017-02-15 20:48:26.635 [main] DEBUG org.apache.kafka.common.metrics.Metrics - Added sensor with name bytes-sent-received:
2017-02-15 20:48:26.635 [main] DEBUG org.apache.kafka.common.metrics.Metrics - Added sensor with name bytes-sent:
2017-02-15 20:48:26.637 [main] DEBUG org.apache.kafka.common.metrics.Metrics - Added sensor with name bytes-received:
2017-02-15 20:48:26.638 [main] DEBUG org.apache.kafka.common.metrics.Metrics - Added sensor with name select-time:
2017-02-15 20:48:26.638 [main] DEBUG org.apache.kafka.common.metrics.Metrics - Added sensor with name io-time:
2017-02-15 20:48:26.645 [main] DEBUG org.apache.kafka.common.metrics.Metrics - Added sensor with name batch-size
2017-02-15 20:48:26.646 [main] DEBUG org.apache.kafka.common.metrics.Metrics - Added sensor with name compression-rate
2017-02-15 20:48:26.646 [main] DEBUG org.apache.kafka.common.metrics.Metrics - Added sensor with name queue-time
2017-02-15 20:48:26.646 [main] DEBUG org.apache.kafka.common.metrics.Metrics - Added sensor with name request-time
2017-02-15 20:48:26.646 [main] DEBUG org.apache.kafka.common.metrics.Metrics - Added sensor with name produce-throttle-time
2017-02-15 20:48:26.647 [main] DEBUG org.apache.kafka.common.metrics.Metrics - Added sensor with name records-per-request
2017-02-15 20:48:26.647 [main] DEBUG org.apache.kafka.common.metrics.Metrics - Added sensor with name record-retries
2017-02-15 20:48:26.647 [main] DEBUG org.apache.kafka.common.metrics.Metrics - Added sensor with name errors
2017-02-15 20:48:26.647 [main] DEBUG org.apache.kafka.common.metrics.Metrics - Added sensor with name record-size-max
2017-02-15 20:48:26.650 [kafka-producer-network-thread | producer-1] DEBUG org.apache.kafka.clients.producer.internals.Sender - Starting Kafka producer I/O thread.
2017-02-15 20:48:26.653 [main] INFO  org.apache.kafka.common.utils.AppInfoParser - Kafka version : 0.10.1.0
2017-02-15 20:48:26.654 [main] INFO  org.apache.kafka.common.utils.AppInfoParser - Kafka commitId : 3402a74efb23d1d4
2017-02-15 20:48:26.655 [main] DEBUG org.apache.kafka.clients.producer.KafkaProducer - Kafka producer started
2017-02-15 20:48:26.710 [kafka-producer-network-thread | producer-1] DEBUG org.apache.kafka.clients.NetworkClient - Initialize connection to node -1 for sending metadata request
2017-02-15 20:48:26.711 [kafka-producer-network-thread | producer-1] DEBUG org.apache.kafka.clients.NetworkClient - Initiating connection to node -1 at 10.1.131.18:9092.
2017-02-15 20:48:26.907 [kafka-producer-network-thread | producer-1] DEBUG org.apache.kafka.common.metrics.Metrics - Added sensor with name node--1.bytes-sent
2017-02-15 20:48:26.908 [kafka-producer-network-thread | producer-1] DEBUG org.apache.kafka.common.metrics.Metrics - Added sensor with name node--1.bytes-received
2017-02-15 20:48:26.908 [kafka-producer-network-thread | producer-1] DEBUG org.apache.kafka.common.metrics.Metrics - Added sensor with name node--1.latency
2017-02-15 20:48:26.909 [kafka-producer-network-thread | producer-1] DEBUG org.apache.kafka.common.network.Selector - Created socket with SO_RCVBUF = 32768, SO_SNDBUF = 131072, SO_TIMEOUT = 0 to node -1
2017-02-15 20:48:26.909 [kafka-producer-network-thread | producer-1] DEBUG org.apache.kafka.clients.NetworkClient - Completed connection to node -1
2017-02-15 20:48:26.954 [kafka-producer-network-thread | producer-1] DEBUG org.apache.kafka.clients.NetworkClient - Sending metadata request {topics=[file_syn2]} to node -1
2017-02-15 20:48:27.099 [kafka-producer-network-thread | producer-1] DEBUG org.apache.kafka.clients.Metadata - Updated cluster metadata version 2 to Cluster(id = 5ynpwwfGT3KEdCwLvR2Jog, nodes = [10.1.131.18:9092 (id: 0 rack: null)], partitions = [Partition(topic = file_syn2, partition = 0, leader = 0, replicas = [0,], isr = [0,])])
2017-02-15 20:48:27.112 [kafka-producer-network-thread | producer-1] DEBUG org.apache.kafka.clients.NetworkClient - Initiating connection to node 0 at 10.1.131.18:9092.
2017-02-15 20:48:27.232 [kafka-producer-network-thread | producer-1] DEBUG org.apache.kafka.common.metrics.Metrics - Added sensor with name node-0.bytes-sent
2017-02-15 20:48:27.232 [kafka-producer-network-thread | producer-1] DEBUG org.apache.kafka.common.metrics.Metrics - Added sensor with name node-0.bytes-received
2017-02-15 20:48:27.233 [kafka-producer-network-thread | producer-1] DEBUG org.apache.kafka.common.metrics.Metrics - Added sensor with name node-0.latency
2017-02-15 20:48:27.233 [kafka-producer-network-thread | producer-1] DEBUG org.apache.kafka.common.network.Selector - Created socket with SO_RCVBUF = 32768, SO_SNDBUF = 131072, SO_TIMEOUT = 0 to node 0
2017-02-15 20:48:27.233 [kafka-producer-network-thread | producer-1] DEBUG org.apache.kafka.clients.NetworkClient - Completed connection to node 0
2017-02-15 20:48:27.233 [kafka-producer-network-thread | producer-1] DEBUG org.apache.kafka.common.metrics.Metrics - Added sensor with name topic.file_syn2.records-per-batch
2017-02-15 20:48:27.234 [kafka-producer-network-thread | producer-1] DEBUG org.apache.kafka.common.metrics.Metrics - Added sensor with name topic.file_syn2.bytes
2017-02-15 20:48:27.234 [kafka-producer-network-thread | producer-1] DEBUG org.apache.kafka.common.metrics.Metrics - Added sensor with name topic.file_syn2.compression-rate
2017-02-15 20:48:27.234 [kafka-producer-network-thread | producer-1] DEBUG org.apache.kafka.common.metrics.Metrics - Added sensor with name topic.file_syn2.record-retries
2017-02-15 20:48:27.234 [kafka-producer-network-thread | producer-1] DEBUG org.apache.kafka.common.metrics.Metrics - Added sensor with name topic.file_syn2.record-errors
2017-02-15 20:48:58.223 [main] INFO  org.apache.kafka.clients.producer.ProducerConfig - ProducerConfig values: 
	acks = 1
	batch.size = 16384
	block.on.buffer.full = false
	bootstrap.servers = [10.1.131.18:9092]
	buffer.memory = 33554432
	client.id = 
	compression.type = none
	connections.max.idle.ms = 540000
	interceptor.classes = null
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 0
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.fetch.timeout.ms = 60000
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	receive.buffer.bytes = 32768
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 0
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	timeout.ms = 30000
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer

2017-02-15 20:48:58.280 [main] INFO  org.apache.kafka.clients.producer.ProducerConfig - ProducerConfig values: 
	acks = 1
	batch.size = 16384
	block.on.buffer.full = false
	bootstrap.servers = [10.1.131.18:9092]
	buffer.memory = 33554432
	client.id = producer-1
	compression.type = none
	connections.max.idle.ms = 540000
	interceptor.classes = null
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 0
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.fetch.timeout.ms = 60000
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	receive.buffer.bytes = 32768
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 0
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	timeout.ms = 30000
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer

2017-02-15 20:48:58.298 [main] DEBUG org.apache.kafka.common.metrics.Metrics - Added sensor with name bufferpool-wait-time
2017-02-15 20:48:58.303 [main] DEBUG org.apache.kafka.common.metrics.Metrics - Added sensor with name buffer-exhausted-records
2017-02-15 20:48:58.306 [main] DEBUG org.apache.kafka.clients.Metadata - Updated cluster metadata version 1 to Cluster(id = null, nodes = [10.1.131.18:9092 (id: -1 rack: null)], partitions = [])
2017-02-15 20:48:58.331 [main] DEBUG org.apache.kafka.common.metrics.Metrics - Added sensor with name connections-closed:
2017-02-15 20:48:58.331 [main] DEBUG org.apache.kafka.common.metrics.Metrics - Added sensor with name connections-created:
2017-02-15 20:48:58.331 [main] DEBUG org.apache.kafka.common.metrics.Metrics - Added sensor with name bytes-sent-received:
2017-02-15 20:48:58.331 [main] DEBUG org.apache.kafka.common.metrics.Metrics - Added sensor with name bytes-sent:
2017-02-15 20:48:58.333 [main] DEBUG org.apache.kafka.common.metrics.Metrics - Added sensor with name bytes-received:
2017-02-15 20:48:58.334 [main] DEBUG org.apache.kafka.common.metrics.Metrics - Added sensor with name select-time:
2017-02-15 20:48:58.334 [main] DEBUG org.apache.kafka.common.metrics.Metrics - Added sensor with name io-time:
2017-02-15 20:48:58.341 [main] DEBUG org.apache.kafka.common.metrics.Metrics - Added sensor with name batch-size
2017-02-15 20:48:58.341 [main] DEBUG org.apache.kafka.common.metrics.Metrics - Added sensor with name compression-rate
2017-02-15 20:48:58.341 [main] DEBUG org.apache.kafka.common.metrics.Metrics - Added sensor with name queue-time
2017-02-15 20:48:58.342 [main] DEBUG org.apache.kafka.common.metrics.Metrics - Added sensor with name request-time
2017-02-15 20:48:58.342 [main] DEBUG org.apache.kafka.common.metrics.Metrics - Added sensor with name produce-throttle-time
2017-02-15 20:48:58.342 [main] DEBUG org.apache.kafka.common.metrics.Metrics - Added sensor with name records-per-request
2017-02-15 20:48:58.342 [main] DEBUG org.apache.kafka.common.metrics.Metrics - Added sensor with name record-retries
2017-02-15 20:48:58.342 [main] DEBUG org.apache.kafka.common.metrics.Metrics - Added sensor with name errors
2017-02-15 20:48:58.343 [main] DEBUG org.apache.kafka.common.metrics.Metrics - Added sensor with name record-size-max
2017-02-15 20:48:58.345 [kafka-producer-network-thread | producer-1] DEBUG org.apache.kafka.clients.producer.internals.Sender - Starting Kafka producer I/O thread.
2017-02-15 20:48:58.349 [main] INFO  org.apache.kafka.common.utils.AppInfoParser - Kafka version : 0.10.1.0
2017-02-15 20:48:58.349 [main] INFO  org.apache.kafka.common.utils.AppInfoParser - Kafka commitId : 3402a74efb23d1d4
2017-02-15 20:48:58.350 [main] DEBUG org.apache.kafka.clients.producer.KafkaProducer - Kafka producer started
2017-02-15 20:48:58.406 [kafka-producer-network-thread | producer-1] DEBUG org.apache.kafka.clients.NetworkClient - Initialize connection to node -1 for sending metadata request
2017-02-15 20:48:58.406 [kafka-producer-network-thread | producer-1] DEBUG org.apache.kafka.clients.NetworkClient - Initiating connection to node -1 at 10.1.131.18:9092.
2017-02-15 20:48:58.451 [kafka-producer-network-thread | producer-1] DEBUG org.apache.kafka.common.metrics.Metrics - Added sensor with name node--1.bytes-sent
2017-02-15 20:48:58.452 [kafka-producer-network-thread | producer-1] DEBUG org.apache.kafka.common.metrics.Metrics - Added sensor with name node--1.bytes-received
2017-02-15 20:48:58.452 [kafka-producer-network-thread | producer-1] DEBUG org.apache.kafka.common.metrics.Metrics - Added sensor with name node--1.latency
2017-02-15 20:48:58.452 [kafka-producer-network-thread | producer-1] DEBUG org.apache.kafka.common.network.Selector - Created socket with SO_RCVBUF = 32768, SO_SNDBUF = 131072, SO_TIMEOUT = 0 to node -1
2017-02-15 20:48:58.453 [kafka-producer-network-thread | producer-1] DEBUG org.apache.kafka.clients.NetworkClient - Completed connection to node -1
2017-02-15 20:48:58.552 [kafka-producer-network-thread | producer-1] DEBUG org.apache.kafka.clients.NetworkClient - Sending metadata request {topics=[file_syn2]} to node -1
2017-02-15 20:48:58.624 [kafka-producer-network-thread | producer-1] DEBUG org.apache.kafka.clients.Metadata - Updated cluster metadata version 2 to Cluster(id = 5ynpwwfGT3KEdCwLvR2Jog, nodes = [10.1.131.18:9092 (id: 0 rack: null)], partitions = [Partition(topic = file_syn2, partition = 0, leader = 0, replicas = [0,], isr = [0,])])
2017-02-15 20:48:58.638 [kafka-producer-network-thread | producer-1] DEBUG org.apache.kafka.clients.NetworkClient - Initiating connection to node 0 at 10.1.131.18:9092.
2017-02-15 20:48:58.681 [kafka-producer-network-thread | producer-1] DEBUG org.apache.kafka.common.metrics.Metrics - Added sensor with name node-0.bytes-sent
2017-02-15 20:48:58.682 [kafka-producer-network-thread | producer-1] DEBUG org.apache.kafka.common.metrics.Metrics - Added sensor with name node-0.bytes-received
2017-02-15 20:48:58.682 [kafka-producer-network-thread | producer-1] DEBUG org.apache.kafka.common.metrics.Metrics - Added sensor with name node-0.latency
2017-02-15 20:48:58.682 [kafka-producer-network-thread | producer-1] DEBUG org.apache.kafka.common.network.Selector - Created socket with SO_RCVBUF = 32768, SO_SNDBUF = 131072, SO_TIMEOUT = 0 to node 0
2017-02-15 20:48:58.682 [kafka-producer-network-thread | producer-1] DEBUG org.apache.kafka.clients.NetworkClient - Completed connection to node 0
2017-02-15 20:48:58.683 [kafka-producer-network-thread | producer-1] DEBUG org.apache.kafka.common.metrics.Metrics - Added sensor with name topic.file_syn2.records-per-batch
2017-02-15 20:48:58.683 [kafka-producer-network-thread | producer-1] DEBUG org.apache.kafka.common.metrics.Metrics - Added sensor with name topic.file_syn2.bytes
2017-02-15 20:48:58.683 [kafka-producer-network-thread | producer-1] DEBUG org.apache.kafka.common.metrics.Metrics - Added sensor with name topic.file_syn2.compression-rate
2017-02-15 20:48:58.683 [kafka-producer-network-thread | producer-1] DEBUG org.apache.kafka.common.metrics.Metrics - Added sensor with name topic.file_syn2.record-retries
2017-02-15 20:48:58.684 [kafka-producer-network-thread | producer-1] DEBUG org.apache.kafka.common.metrics.Metrics - Added sensor with name topic.file_syn2.record-errors
2017-02-15 20:50:51.147 [main] INFO  org.apache.kafka.clients.producer.ProducerConfig - ProducerConfig values: 
	acks = 1
	batch.size = 16384
	block.on.buffer.full = false
	bootstrap.servers = [10.1.131.18:9092]
	buffer.memory = 33554432
	client.id = 
	compression.type = none
	connections.max.idle.ms = 540000
	interceptor.classes = null
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 0
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.fetch.timeout.ms = 60000
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	receive.buffer.bytes = 32768
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 0
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	timeout.ms = 30000
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer

2017-02-15 20:50:51.206 [main] INFO  org.apache.kafka.clients.producer.ProducerConfig - ProducerConfig values: 
	acks = 1
	batch.size = 16384
	block.on.buffer.full = false
	bootstrap.servers = [10.1.131.18:9092]
	buffer.memory = 33554432
	client.id = producer-1
	compression.type = none
	connections.max.idle.ms = 540000
	interceptor.classes = null
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 0
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.fetch.timeout.ms = 60000
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	receive.buffer.bytes = 32768
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 0
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	timeout.ms = 30000
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer

2017-02-15 20:50:51.226 [main] DEBUG org.apache.kafka.common.metrics.Metrics - Added sensor with name bufferpool-wait-time
2017-02-15 20:50:51.236 [main] DEBUG org.apache.kafka.common.metrics.Metrics - Added sensor with name buffer-exhausted-records
2017-02-15 20:50:51.239 [main] DEBUG org.apache.kafka.clients.Metadata - Updated cluster metadata version 1 to Cluster(id = null, nodes = [10.1.131.18:9092 (id: -1 rack: null)], partitions = [])
2017-02-15 20:50:51.263 [main] DEBUG org.apache.kafka.common.metrics.Metrics - Added sensor with name connections-closed:
2017-02-15 20:50:51.264 [main] DEBUG org.apache.kafka.common.metrics.Metrics - Added sensor with name connections-created:
2017-02-15 20:50:51.265 [main] DEBUG org.apache.kafka.common.metrics.Metrics - Added sensor with name bytes-sent-received:
2017-02-15 20:50:51.265 [main] DEBUG org.apache.kafka.common.metrics.Metrics - Added sensor with name bytes-sent:
2017-02-15 20:50:51.267 [main] DEBUG org.apache.kafka.common.metrics.Metrics - Added sensor with name bytes-received:
2017-02-15 20:50:51.268 [main] DEBUG org.apache.kafka.common.metrics.Metrics - Added sensor with name select-time:
2017-02-15 20:50:51.268 [main] DEBUG org.apache.kafka.common.metrics.Metrics - Added sensor with name io-time:
2017-02-15 20:50:51.274 [main] DEBUG org.apache.kafka.common.metrics.Metrics - Added sensor with name batch-size
2017-02-15 20:50:51.275 [main] DEBUG org.apache.kafka.common.metrics.Metrics - Added sensor with name compression-rate
2017-02-15 20:50:51.275 [main] DEBUG org.apache.kafka.common.metrics.Metrics - Added sensor with name queue-time
2017-02-15 20:50:51.275 [main] DEBUG org.apache.kafka.common.metrics.Metrics - Added sensor with name request-time
2017-02-15 20:50:51.276 [main] DEBUG org.apache.kafka.common.metrics.Metrics - Added sensor with name produce-throttle-time
2017-02-15 20:50:51.276 [main] DEBUG org.apache.kafka.common.metrics.Metrics - Added sensor with name records-per-request
2017-02-15 20:50:51.277 [main] DEBUG org.apache.kafka.common.metrics.Metrics - Added sensor with name record-retries
2017-02-15 20:50:51.277 [main] DEBUG org.apache.kafka.common.metrics.Metrics - Added sensor with name errors
2017-02-15 20:50:51.277 [main] DEBUG org.apache.kafka.common.metrics.Metrics - Added sensor with name record-size-max
2017-02-15 20:50:51.280 [kafka-producer-network-thread | producer-1] DEBUG org.apache.kafka.clients.producer.internals.Sender - Starting Kafka producer I/O thread.
2017-02-15 20:50:51.285 [main] INFO  org.apache.kafka.common.utils.AppInfoParser - Kafka version : 0.10.1.0
2017-02-15 20:50:51.285 [main] INFO  org.apache.kafka.common.utils.AppInfoParser - Kafka commitId : 3402a74efb23d1d4
2017-02-15 20:50:51.286 [main] DEBUG org.apache.kafka.clients.producer.KafkaProducer - Kafka producer started
2017-02-15 20:50:51.338 [kafka-producer-network-thread | producer-1] DEBUG org.apache.kafka.clients.NetworkClient - Initialize connection to node -1 for sending metadata request
2017-02-15 20:50:51.338 [kafka-producer-network-thread | producer-1] DEBUG org.apache.kafka.clients.NetworkClient - Initiating connection to node -1 at 10.1.131.18:9092.
2017-02-15 20:50:51.606 [kafka-producer-network-thread | producer-1] DEBUG org.apache.kafka.common.metrics.Metrics - Added sensor with name node--1.bytes-sent
2017-02-15 20:50:51.607 [kafka-producer-network-thread | producer-1] DEBUG org.apache.kafka.common.metrics.Metrics - Added sensor with name node--1.bytes-received
2017-02-15 20:50:51.607 [kafka-producer-network-thread | producer-1] DEBUG org.apache.kafka.common.metrics.Metrics - Added sensor with name node--1.latency
2017-02-15 20:50:51.607 [kafka-producer-network-thread | producer-1] DEBUG org.apache.kafka.common.network.Selector - Created socket with SO_RCVBUF = 32768, SO_SNDBUF = 131072, SO_TIMEOUT = 0 to node -1
2017-02-15 20:50:51.608 [kafka-producer-network-thread | producer-1] DEBUG org.apache.kafka.clients.NetworkClient - Completed connection to node -1
2017-02-15 20:50:51.690 [kafka-producer-network-thread | producer-1] DEBUG org.apache.kafka.clients.NetworkClient - Sending metadata request {topics=[file_syn2]} to node -1
2017-02-15 20:50:51.806 [kafka-producer-network-thread | producer-1] DEBUG org.apache.kafka.clients.Metadata - Updated cluster metadata version 2 to Cluster(id = 5ynpwwfGT3KEdCwLvR2Jog, nodes = [10.1.131.18:9092 (id: 0 rack: null)], partitions = [Partition(topic = file_syn2, partition = 0, leader = 0, replicas = [0,], isr = [0,])])
2017-02-15 20:50:51.822 [kafka-producer-network-thread | producer-1] DEBUG org.apache.kafka.clients.NetworkClient - Initiating connection to node 0 at 10.1.131.18:9092.
2017-02-15 20:50:52.052 [kafka-producer-network-thread | producer-1] DEBUG org.apache.kafka.common.metrics.Metrics - Added sensor with name node-0.bytes-sent
2017-02-15 20:50:52.052 [kafka-producer-network-thread | producer-1] DEBUG org.apache.kafka.common.metrics.Metrics - Added sensor with name node-0.bytes-received
2017-02-15 20:50:52.053 [kafka-producer-network-thread | producer-1] DEBUG org.apache.kafka.common.metrics.Metrics - Added sensor with name node-0.latency
2017-02-15 20:50:52.053 [kafka-producer-network-thread | producer-1] DEBUG org.apache.kafka.common.network.Selector - Created socket with SO_RCVBUF = 32768, SO_SNDBUF = 131072, SO_TIMEOUT = 0 to node 0
2017-02-15 20:50:52.053 [kafka-producer-network-thread | producer-1] DEBUG org.apache.kafka.clients.NetworkClient - Completed connection to node 0
2017-02-15 20:50:52.053 [kafka-producer-network-thread | producer-1] DEBUG org.apache.kafka.common.metrics.Metrics - Added sensor with name topic.file_syn2.records-per-batch
2017-02-15 20:50:52.054 [kafka-producer-network-thread | producer-1] DEBUG org.apache.kafka.common.metrics.Metrics - Added sensor with name topic.file_syn2.bytes
2017-02-15 20:50:52.054 [kafka-producer-network-thread | producer-1] DEBUG org.apache.kafka.common.metrics.Metrics - Added sensor with name topic.file_syn2.compression-rate
2017-02-15 20:50:52.054 [kafka-producer-network-thread | producer-1] DEBUG org.apache.kafka.common.metrics.Metrics - Added sensor with name topic.file_syn2.record-retries
2017-02-15 20:50:52.054 [kafka-producer-network-thread | producer-1] DEBUG org.apache.kafka.common.metrics.Metrics - Added sensor with name topic.file_syn2.record-errors
2017-02-15 20:52:47.505 [main] INFO  org.apache.kafka.clients.producer.ProducerConfig - ProducerConfig values: 
	acks = 1
	batch.size = 16384
	block.on.buffer.full = false
	bootstrap.servers = [10.1.131.18:9092]
	buffer.memory = 33554432
	client.id = 
	compression.type = none
	connections.max.idle.ms = 540000
	interceptor.classes = null
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 0
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.fetch.timeout.ms = 60000
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	receive.buffer.bytes = 32768
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 0
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	timeout.ms = 30000
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer

2017-02-15 20:52:47.563 [main] INFO  org.apache.kafka.clients.producer.ProducerConfig - ProducerConfig values: 
	acks = 1
	batch.size = 16384
	block.on.buffer.full = false
	bootstrap.servers = [10.1.131.18:9092]
	buffer.memory = 33554432
	client.id = producer-1
	compression.type = none
	connections.max.idle.ms = 540000
	interceptor.classes = null
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 0
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.fetch.timeout.ms = 60000
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	receive.buffer.bytes = 32768
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 0
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	timeout.ms = 30000
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer

2017-02-15 20:52:47.577 [main] DEBUG org.apache.kafka.common.metrics.Metrics - Added sensor with name bufferpool-wait-time
2017-02-15 20:52:47.586 [main] DEBUG org.apache.kafka.common.metrics.Metrics - Added sensor with name buffer-exhausted-records
2017-02-15 20:52:47.589 [main] DEBUG org.apache.kafka.clients.Metadata - Updated cluster metadata version 1 to Cluster(id = null, nodes = [10.1.131.18:9092 (id: -1 rack: null)], partitions = [])
2017-02-15 20:52:47.614 [main] DEBUG org.apache.kafka.common.metrics.Metrics - Added sensor with name connections-closed:
2017-02-15 20:52:47.614 [main] DEBUG org.apache.kafka.common.metrics.Metrics - Added sensor with name connections-created:
2017-02-15 20:52:47.615 [main] DEBUG org.apache.kafka.common.metrics.Metrics - Added sensor with name bytes-sent-received:
2017-02-15 20:52:47.615 [main] DEBUG org.apache.kafka.common.metrics.Metrics - Added sensor with name bytes-sent:
2017-02-15 20:52:47.617 [main] DEBUG org.apache.kafka.common.metrics.Metrics - Added sensor with name bytes-received:
2017-02-15 20:52:47.617 [main] DEBUG org.apache.kafka.common.metrics.Metrics - Added sensor with name select-time:
2017-02-15 20:52:47.617 [main] DEBUG org.apache.kafka.common.metrics.Metrics - Added sensor with name io-time:
2017-02-15 20:52:47.625 [main] DEBUG org.apache.kafka.common.metrics.Metrics - Added sensor with name batch-size
2017-02-15 20:52:47.626 [main] DEBUG org.apache.kafka.common.metrics.Metrics - Added sensor with name compression-rate
2017-02-15 20:52:47.626 [main] DEBUG org.apache.kafka.common.metrics.Metrics - Added sensor with name queue-time
2017-02-15 20:52:47.626 [main] DEBUG org.apache.kafka.common.metrics.Metrics - Added sensor with name request-time
2017-02-15 20:52:47.626 [main] DEBUG org.apache.kafka.common.metrics.Metrics - Added sensor with name produce-throttle-time
2017-02-15 20:52:47.627 [main] DEBUG org.apache.kafka.common.metrics.Metrics - Added sensor with name records-per-request
2017-02-15 20:52:47.627 [main] DEBUG org.apache.kafka.common.metrics.Metrics - Added sensor with name record-retries
2017-02-15 20:52:47.627 [main] DEBUG org.apache.kafka.common.metrics.Metrics - Added sensor with name errors
2017-02-15 20:52:47.628 [main] DEBUG org.apache.kafka.common.metrics.Metrics - Added sensor with name record-size-max
2017-02-15 20:52:47.630 [kafka-producer-network-thread | producer-1] DEBUG org.apache.kafka.clients.producer.internals.Sender - Starting Kafka producer I/O thread.
2017-02-15 20:52:47.634 [main] INFO  org.apache.kafka.common.utils.AppInfoParser - Kafka version : 0.10.1.0
2017-02-15 20:52:47.634 [main] INFO  org.apache.kafka.common.utils.AppInfoParser - Kafka commitId : 3402a74efb23d1d4
2017-02-15 20:52:47.635 [main] DEBUG org.apache.kafka.clients.producer.KafkaProducer - Kafka producer started
2017-02-15 20:52:47.689 [kafka-producer-network-thread | producer-1] DEBUG org.apache.kafka.clients.NetworkClient - Initialize connection to node -1 for sending metadata request
2017-02-15 20:52:47.689 [kafka-producer-network-thread | producer-1] DEBUG org.apache.kafka.clients.NetworkClient - Initiating connection to node -1 at 10.1.131.18:9092.
2017-02-15 20:52:47.732 [kafka-producer-network-thread | producer-1] DEBUG org.apache.kafka.common.metrics.Metrics - Added sensor with name node--1.bytes-sent
2017-02-15 20:52:47.732 [kafka-producer-network-thread | producer-1] DEBUG org.apache.kafka.common.metrics.Metrics - Added sensor with name node--1.bytes-received
2017-02-15 20:52:47.733 [kafka-producer-network-thread | producer-1] DEBUG org.apache.kafka.common.metrics.Metrics - Added sensor with name node--1.latency
2017-02-15 20:52:47.733 [kafka-producer-network-thread | producer-1] DEBUG org.apache.kafka.common.network.Selector - Created socket with SO_RCVBUF = 32768, SO_SNDBUF = 131072, SO_TIMEOUT = 0 to node -1
2017-02-15 20:52:47.733 [kafka-producer-network-thread | producer-1] DEBUG org.apache.kafka.clients.NetworkClient - Completed connection to node -1
2017-02-15 20:52:47.838 [kafka-producer-network-thread | producer-1] DEBUG org.apache.kafka.clients.NetworkClient - Sending metadata request {topics=[file_syn3]} to node -1
2017-02-15 20:52:47.919 [kafka-producer-network-thread | producer-1] DEBUG org.apache.kafka.clients.Metadata - Updated cluster metadata version 2 to Cluster(id = 5ynpwwfGT3KEdCwLvR2Jog, nodes = [10.1.131.18:9092 (id: 0 rack: null)], partitions = [Partition(topic = file_syn3, partition = 0, leader = 0, replicas = [0,], isr = [0,])])
2017-02-15 20:52:47.936 [kafka-producer-network-thread | producer-1] DEBUG org.apache.kafka.clients.NetworkClient - Initiating connection to node 0 at 10.1.131.18:9092.
2017-02-15 20:52:47.975 [kafka-producer-network-thread | producer-1] DEBUG org.apache.kafka.common.metrics.Metrics - Added sensor with name node-0.bytes-sent
2017-02-15 20:52:47.976 [kafka-producer-network-thread | producer-1] DEBUG org.apache.kafka.common.metrics.Metrics - Added sensor with name node-0.bytes-received
2017-02-15 20:52:47.976 [kafka-producer-network-thread | producer-1] DEBUG org.apache.kafka.common.metrics.Metrics - Added sensor with name node-0.latency
2017-02-15 20:52:47.976 [kafka-producer-network-thread | producer-1] DEBUG org.apache.kafka.common.network.Selector - Created socket with SO_RCVBUF = 32768, SO_SNDBUF = 131072, SO_TIMEOUT = 0 to node 0
2017-02-15 20:52:47.977 [kafka-producer-network-thread | producer-1] DEBUG org.apache.kafka.clients.NetworkClient - Completed connection to node 0
2017-02-15 20:52:47.977 [kafka-producer-network-thread | producer-1] DEBUG org.apache.kafka.common.metrics.Metrics - Added sensor with name topic.file_syn3.records-per-batch
2017-02-15 20:52:47.977 [kafka-producer-network-thread | producer-1] DEBUG org.apache.kafka.common.metrics.Metrics - Added sensor with name topic.file_syn3.bytes
2017-02-15 20:52:47.978 [kafka-producer-network-thread | producer-1] DEBUG org.apache.kafka.common.metrics.Metrics - Added sensor with name topic.file_syn3.compression-rate
2017-02-15 20:52:47.978 [kafka-producer-network-thread | producer-1] DEBUG org.apache.kafka.common.metrics.Metrics - Added sensor with name topic.file_syn3.record-retries
2017-02-15 20:52:47.978 [kafka-producer-network-thread | producer-1] DEBUG org.apache.kafka.common.metrics.Metrics - Added sensor with name topic.file_syn3.record-errors
2017-02-15 20:53:02.692 [main] INFO  org.apache.kafka.clients.producer.ProducerConfig - ProducerConfig values: 
	acks = 1
	batch.size = 16384
	block.on.buffer.full = false
	bootstrap.servers = [10.1.131.18:9092]
	buffer.memory = 33554432
	client.id = 
	compression.type = none
	connections.max.idle.ms = 540000
	interceptor.classes = null
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 0
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.fetch.timeout.ms = 60000
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	receive.buffer.bytes = 32768
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 0
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	timeout.ms = 30000
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer

2017-02-15 20:53:02.748 [main] INFO  org.apache.kafka.clients.producer.ProducerConfig - ProducerConfig values: 
	acks = 1
	batch.size = 16384
	block.on.buffer.full = false
	bootstrap.servers = [10.1.131.18:9092]
	buffer.memory = 33554432
	client.id = producer-1
	compression.type = none
	connections.max.idle.ms = 540000
	interceptor.classes = null
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 0
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.fetch.timeout.ms = 60000
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	receive.buffer.bytes = 32768
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 0
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	timeout.ms = 30000
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer

2017-02-15 20:53:02.761 [main] DEBUG org.apache.kafka.common.metrics.Metrics - Added sensor with name bufferpool-wait-time
2017-02-15 20:53:02.768 [main] DEBUG org.apache.kafka.common.metrics.Metrics - Added sensor with name buffer-exhausted-records
2017-02-15 20:53:02.771 [main] DEBUG org.apache.kafka.clients.Metadata - Updated cluster metadata version 1 to Cluster(id = null, nodes = [10.1.131.18:9092 (id: -1 rack: null)], partitions = [])
2017-02-15 20:53:02.797 [main] DEBUG org.apache.kafka.common.metrics.Metrics - Added sensor with name connections-closed:
2017-02-15 20:53:02.797 [main] DEBUG org.apache.kafka.common.metrics.Metrics - Added sensor with name connections-created:
2017-02-15 20:53:02.797 [main] DEBUG org.apache.kafka.common.metrics.Metrics - Added sensor with name bytes-sent-received:
2017-02-15 20:53:02.797 [main] DEBUG org.apache.kafka.common.metrics.Metrics - Added sensor with name bytes-sent:
2017-02-15 20:53:02.799 [main] DEBUG org.apache.kafka.common.metrics.Metrics - Added sensor with name bytes-received:
2017-02-15 20:53:02.799 [main] DEBUG org.apache.kafka.common.metrics.Metrics - Added sensor with name select-time:
2017-02-15 20:53:02.800 [main] DEBUG org.apache.kafka.common.metrics.Metrics - Added sensor with name io-time:
2017-02-15 20:53:02.807 [main] DEBUG org.apache.kafka.common.metrics.Metrics - Added sensor with name batch-size
2017-02-15 20:53:02.808 [main] DEBUG org.apache.kafka.common.metrics.Metrics - Added sensor with name compression-rate
2017-02-15 20:53:02.808 [main] DEBUG org.apache.kafka.common.metrics.Metrics - Added sensor with name queue-time
2017-02-15 20:53:02.808 [main] DEBUG org.apache.kafka.common.metrics.Metrics - Added sensor with name request-time
2017-02-15 20:53:02.808 [main] DEBUG org.apache.kafka.common.metrics.Metrics - Added sensor with name produce-throttle-time
2017-02-15 20:53:02.809 [main] DEBUG org.apache.kafka.common.metrics.Metrics - Added sensor with name records-per-request
2017-02-15 20:53:02.809 [main] DEBUG org.apache.kafka.common.metrics.Metrics - Added sensor with name record-retries
2017-02-15 20:53:02.809 [main] DEBUG org.apache.kafka.common.metrics.Metrics - Added sensor with name errors
2017-02-15 20:53:02.809 [main] DEBUG org.apache.kafka.common.metrics.Metrics - Added sensor with name record-size-max
2017-02-15 20:53:02.812 [kafka-producer-network-thread | producer-1] DEBUG org.apache.kafka.clients.producer.internals.Sender - Starting Kafka producer I/O thread.
2017-02-15 20:53:02.816 [main] INFO  org.apache.kafka.common.utils.AppInfoParser - Kafka version : 0.10.1.0
2017-02-15 20:53:02.816 [main] INFO  org.apache.kafka.common.utils.AppInfoParser - Kafka commitId : 3402a74efb23d1d4
2017-02-15 20:53:02.818 [main] DEBUG org.apache.kafka.clients.producer.KafkaProducer - Kafka producer started
2017-02-15 20:53:02.871 [kafka-producer-network-thread | producer-1] DEBUG org.apache.kafka.clients.NetworkClient - Initialize connection to node -1 for sending metadata request
2017-02-15 20:53:02.872 [kafka-producer-network-thread | producer-1] DEBUG org.apache.kafka.clients.NetworkClient - Initiating connection to node -1 at 10.1.131.18:9092.
2017-02-15 20:53:02.960 [kafka-producer-network-thread | producer-1] DEBUG org.apache.kafka.common.metrics.Metrics - Added sensor with name node--1.bytes-sent
2017-02-15 20:53:02.961 [kafka-producer-network-thread | producer-1] DEBUG org.apache.kafka.common.metrics.Metrics - Added sensor with name node--1.bytes-received
2017-02-15 20:53:02.961 [kafka-producer-network-thread | producer-1] DEBUG org.apache.kafka.common.metrics.Metrics - Added sensor with name node--1.latency
2017-02-15 20:53:02.962 [kafka-producer-network-thread | producer-1] DEBUG org.apache.kafka.common.network.Selector - Created socket with SO_RCVBUF = 32768, SO_SNDBUF = 131072, SO_TIMEOUT = 0 to node -1
2017-02-15 20:53:02.962 [kafka-producer-network-thread | producer-1] DEBUG org.apache.kafka.clients.NetworkClient - Completed connection to node -1
2017-02-15 20:53:03.026 [kafka-producer-network-thread | producer-1] DEBUG org.apache.kafka.clients.NetworkClient - Sending metadata request {topics=[file_syn3]} to node -1
2017-02-15 20:53:03.234 [kafka-producer-network-thread | producer-1] DEBUG org.apache.kafka.clients.Metadata - Updated cluster metadata version 2 to Cluster(id = 5ynpwwfGT3KEdCwLvR2Jog, nodes = [10.1.131.18:9092 (id: 0 rack: null)], partitions = [Partition(topic = file_syn3, partition = 0, leader = 0, replicas = [0,], isr = [0,])])
2017-02-15 20:53:03.248 [kafka-producer-network-thread | producer-1] DEBUG org.apache.kafka.clients.NetworkClient - Initiating connection to node 0 at 10.1.131.18:9092.
2017-02-15 20:53:03.364 [kafka-producer-network-thread | producer-1] DEBUG org.apache.kafka.common.metrics.Metrics - Added sensor with name node-0.bytes-sent
2017-02-15 20:53:03.364 [kafka-producer-network-thread | producer-1] DEBUG org.apache.kafka.common.metrics.Metrics - Added sensor with name node-0.bytes-received
2017-02-15 20:53:03.365 [kafka-producer-network-thread | producer-1] DEBUG org.apache.kafka.common.metrics.Metrics - Added sensor with name node-0.latency
2017-02-15 20:53:03.365 [kafka-producer-network-thread | producer-1] DEBUG org.apache.kafka.common.network.Selector - Created socket with SO_RCVBUF = 32768, SO_SNDBUF = 131072, SO_TIMEOUT = 0 to node 0
2017-02-15 20:53:03.365 [kafka-producer-network-thread | producer-1] DEBUG org.apache.kafka.clients.NetworkClient - Completed connection to node 0
2017-02-15 20:53:03.365 [kafka-producer-network-thread | producer-1] DEBUG org.apache.kafka.common.metrics.Metrics - Added sensor with name topic.file_syn3.records-per-batch
2017-02-15 20:53:03.366 [kafka-producer-network-thread | producer-1] DEBUG org.apache.kafka.common.metrics.Metrics - Added sensor with name topic.file_syn3.bytes
2017-02-15 20:53:03.366 [kafka-producer-network-thread | producer-1] DEBUG org.apache.kafka.common.metrics.Metrics - Added sensor with name topic.file_syn3.compression-rate
2017-02-15 20:53:03.366 [kafka-producer-network-thread | producer-1] DEBUG org.apache.kafka.common.metrics.Metrics - Added sensor with name topic.file_syn3.record-retries
2017-02-15 20:53:03.366 [kafka-producer-network-thread | producer-1] DEBUG org.apache.kafka.common.metrics.Metrics - Added sensor with name topic.file_syn3.record-errors
2017-02-15 20:54:58.660 [main] INFO  org.apache.kafka.clients.producer.ProducerConfig - ProducerConfig values: 
	acks = 1
	batch.size = 16384
	block.on.buffer.full = false
	bootstrap.servers = [10.1.131.18:9092]
	buffer.memory = 33554432
	client.id = 
	compression.type = none
	connections.max.idle.ms = 540000
	interceptor.classes = null
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 0
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.fetch.timeout.ms = 60000
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	receive.buffer.bytes = 32768
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 0
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	timeout.ms = 30000
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer

2017-02-15 20:54:58.716 [main] INFO  org.apache.kafka.clients.producer.ProducerConfig - ProducerConfig values: 
	acks = 1
	batch.size = 16384
	block.on.buffer.full = false
	bootstrap.servers = [10.1.131.18:9092]
	buffer.memory = 33554432
	client.id = producer-1
	compression.type = none
	connections.max.idle.ms = 540000
	interceptor.classes = null
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 0
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.fetch.timeout.ms = 60000
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	receive.buffer.bytes = 32768
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 0
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	timeout.ms = 30000
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer

2017-02-15 20:54:58.732 [main] DEBUG org.apache.kafka.common.metrics.Metrics - Added sensor with name bufferpool-wait-time
2017-02-15 20:54:58.739 [main] DEBUG org.apache.kafka.common.metrics.Metrics - Added sensor with name buffer-exhausted-records
2017-02-15 20:54:58.743 [main] DEBUG org.apache.kafka.clients.Metadata - Updated cluster metadata version 1 to Cluster(id = null, nodes = [10.1.131.18:9092 (id: -1 rack: null)], partitions = [])
2017-02-15 20:54:58.769 [main] DEBUG org.apache.kafka.common.metrics.Metrics - Added sensor with name connections-closed:
2017-02-15 20:54:58.769 [main] DEBUG org.apache.kafka.common.metrics.Metrics - Added sensor with name connections-created:
2017-02-15 20:54:58.770 [main] DEBUG org.apache.kafka.common.metrics.Metrics - Added sensor with name bytes-sent-received:
2017-02-15 20:54:58.770 [main] DEBUG org.apache.kafka.common.metrics.Metrics - Added sensor with name bytes-sent:
2017-02-15 20:54:58.772 [main] DEBUG org.apache.kafka.common.metrics.Metrics - Added sensor with name bytes-received:
2017-02-15 20:54:58.773 [main] DEBUG org.apache.kafka.common.metrics.Metrics - Added sensor with name select-time:
2017-02-15 20:54:58.773 [main] DEBUG org.apache.kafka.common.metrics.Metrics - Added sensor with name io-time:
2017-02-15 20:54:58.781 [main] DEBUG org.apache.kafka.common.metrics.Metrics - Added sensor with name batch-size
2017-02-15 20:54:58.781 [main] DEBUG org.apache.kafka.common.metrics.Metrics - Added sensor with name compression-rate
2017-02-15 20:54:58.781 [main] DEBUG org.apache.kafka.common.metrics.Metrics - Added sensor with name queue-time
2017-02-15 20:54:58.782 [main] DEBUG org.apache.kafka.common.metrics.Metrics - Added sensor with name request-time
2017-02-15 20:54:58.782 [main] DEBUG org.apache.kafka.common.metrics.Metrics - Added sensor with name produce-throttle-time
2017-02-15 20:54:58.782 [main] DEBUG org.apache.kafka.common.metrics.Metrics - Added sensor with name records-per-request
2017-02-15 20:54:58.782 [main] DEBUG org.apache.kafka.common.metrics.Metrics - Added sensor with name record-retries
2017-02-15 20:54:58.783 [main] DEBUG org.apache.kafka.common.metrics.Metrics - Added sensor with name errors
2017-02-15 20:54:58.783 [main] DEBUG org.apache.kafka.common.metrics.Metrics - Added sensor with name record-size-max
2017-02-15 20:54:58.786 [kafka-producer-network-thread | producer-1] DEBUG org.apache.kafka.clients.producer.internals.Sender - Starting Kafka producer I/O thread.
2017-02-15 20:54:58.790 [main] INFO  org.apache.kafka.common.utils.AppInfoParser - Kafka version : 0.10.1.0
2017-02-15 20:54:58.790 [main] INFO  org.apache.kafka.common.utils.AppInfoParser - Kafka commitId : 3402a74efb23d1d4
2017-02-15 20:54:58.791 [main] DEBUG org.apache.kafka.clients.producer.KafkaProducer - Kafka producer started
2017-02-15 20:54:58.844 [kafka-producer-network-thread | producer-1] DEBUG org.apache.kafka.clients.NetworkClient - Initialize connection to node -1 for sending metadata request
2017-02-15 20:54:58.844 [kafka-producer-network-thread | producer-1] DEBUG org.apache.kafka.clients.NetworkClient - Initiating connection to node -1 at 10.1.131.18:9092.
2017-02-15 20:54:58.886 [kafka-producer-network-thread | producer-1] DEBUG org.apache.kafka.common.metrics.Metrics - Added sensor with name node--1.bytes-sent
2017-02-15 20:54:58.887 [kafka-producer-network-thread | producer-1] DEBUG org.apache.kafka.common.metrics.Metrics - Added sensor with name node--1.bytes-received
2017-02-15 20:54:58.887 [kafka-producer-network-thread | producer-1] DEBUG org.apache.kafka.common.metrics.Metrics - Added sensor with name node--1.latency
2017-02-15 20:54:58.888 [kafka-producer-network-thread | producer-1] DEBUG org.apache.kafka.common.network.Selector - Created socket with SO_RCVBUF = 32768, SO_SNDBUF = 131072, SO_TIMEOUT = 0 to node -1
2017-02-15 20:54:58.888 [kafka-producer-network-thread | producer-1] DEBUG org.apache.kafka.clients.NetworkClient - Completed connection to node -1
2017-02-15 20:54:59.007 [kafka-producer-network-thread | producer-1] DEBUG org.apache.kafka.clients.NetworkClient - Sending metadata request {topics=[file_syn3]} to node -1
2017-02-15 20:54:59.083 [kafka-producer-network-thread | producer-1] DEBUG org.apache.kafka.clients.Metadata - Updated cluster metadata version 2 to Cluster(id = 5ynpwwfGT3KEdCwLvR2Jog, nodes = [10.1.131.18:9092 (id: 0 rack: null)], partitions = [Partition(topic = file_syn3, partition = 0, leader = 0, replicas = [0,], isr = [0,])])
2017-02-15 20:54:59.098 [kafka-producer-network-thread | producer-1] DEBUG org.apache.kafka.clients.NetworkClient - Initiating connection to node 0 at 10.1.131.18:9092.
2017-02-15 20:54:59.138 [kafka-producer-network-thread | producer-1] DEBUG org.apache.kafka.common.metrics.Metrics - Added sensor with name node-0.bytes-sent
2017-02-15 20:54:59.138 [kafka-producer-network-thread | producer-1] DEBUG org.apache.kafka.common.metrics.Metrics - Added sensor with name node-0.bytes-received
2017-02-15 20:54:59.138 [kafka-producer-network-thread | producer-1] DEBUG org.apache.kafka.common.metrics.Metrics - Added sensor with name node-0.latency
2017-02-15 20:54:59.139 [kafka-producer-network-thread | producer-1] DEBUG org.apache.kafka.common.network.Selector - Created socket with SO_RCVBUF = 32768, SO_SNDBUF = 131072, SO_TIMEOUT = 0 to node 0
2017-02-15 20:54:59.139 [kafka-producer-network-thread | producer-1] DEBUG org.apache.kafka.clients.NetworkClient - Completed connection to node 0
2017-02-15 20:54:59.139 [kafka-producer-network-thread | producer-1] DEBUG org.apache.kafka.common.metrics.Metrics - Added sensor with name topic.file_syn3.records-per-batch
2017-02-15 20:54:59.140 [kafka-producer-network-thread | producer-1] DEBUG org.apache.kafka.common.metrics.Metrics - Added sensor with name topic.file_syn3.bytes
2017-02-15 20:54:59.140 [kafka-producer-network-thread | producer-1] DEBUG org.apache.kafka.common.metrics.Metrics - Added sensor with name topic.file_syn3.compression-rate
2017-02-15 20:54:59.140 [kafka-producer-network-thread | producer-1] DEBUG org.apache.kafka.common.metrics.Metrics - Added sensor with name topic.file_syn3.record-retries
2017-02-15 20:54:59.140 [kafka-producer-network-thread | producer-1] DEBUG org.apache.kafka.common.metrics.Metrics - Added sensor with name topic.file_syn3.record-errors
2017-02-15 20:55:06.263 [main] INFO  org.apache.kafka.clients.producer.ProducerConfig - ProducerConfig values: 
	acks = 1
	batch.size = 16384
	block.on.buffer.full = false
	bootstrap.servers = [10.1.131.18:9092]
	buffer.memory = 33554432
	client.id = 
	compression.type = none
	connections.max.idle.ms = 540000
	interceptor.classes = null
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 0
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.fetch.timeout.ms = 60000
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	receive.buffer.bytes = 32768
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 0
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	timeout.ms = 30000
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer

2017-02-15 20:55:06.324 [main] INFO  org.apache.kafka.clients.producer.ProducerConfig - ProducerConfig values: 
	acks = 1
	batch.size = 16384
	block.on.buffer.full = false
	bootstrap.servers = [10.1.131.18:9092]
	buffer.memory = 33554432
	client.id = producer-1
	compression.type = none
	connections.max.idle.ms = 540000
	interceptor.classes = null
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 0
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.fetch.timeout.ms = 60000
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	receive.buffer.bytes = 32768
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 0
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	timeout.ms = 30000
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer

2017-02-15 20:55:06.340 [main] DEBUG org.apache.kafka.common.metrics.Metrics - Added sensor with name bufferpool-wait-time
2017-02-15 20:55:06.346 [main] DEBUG org.apache.kafka.common.metrics.Metrics - Added sensor with name buffer-exhausted-records
2017-02-15 20:55:06.349 [main] DEBUG org.apache.kafka.clients.Metadata - Updated cluster metadata version 1 to Cluster(id = null, nodes = [10.1.131.18:9092 (id: -1 rack: null)], partitions = [])
2017-02-15 20:55:06.374 [main] DEBUG org.apache.kafka.common.metrics.Metrics - Added sensor with name connections-closed:
2017-02-15 20:55:06.375 [main] DEBUG org.apache.kafka.common.metrics.Metrics - Added sensor with name connections-created:
2017-02-15 20:55:06.375 [main] DEBUG org.apache.kafka.common.metrics.Metrics - Added sensor with name bytes-sent-received:
2017-02-15 20:55:06.375 [main] DEBUG org.apache.kafka.common.metrics.Metrics - Added sensor with name bytes-sent:
2017-02-15 20:55:06.377 [main] DEBUG org.apache.kafka.common.metrics.Metrics - Added sensor with name bytes-received:
2017-02-15 20:55:06.377 [main] DEBUG org.apache.kafka.common.metrics.Metrics - Added sensor with name select-time:
2017-02-15 20:55:06.378 [main] DEBUG org.apache.kafka.common.metrics.Metrics - Added sensor with name io-time:
2017-02-15 20:55:06.385 [main] DEBUG org.apache.kafka.common.metrics.Metrics - Added sensor with name batch-size
2017-02-15 20:55:06.385 [main] DEBUG org.apache.kafka.common.metrics.Metrics - Added sensor with name compression-rate
2017-02-15 20:55:06.385 [main] DEBUG org.apache.kafka.common.metrics.Metrics - Added sensor with name queue-time
2017-02-15 20:55:06.386 [main] DEBUG org.apache.kafka.common.metrics.Metrics - Added sensor with name request-time
2017-02-15 20:55:06.386 [main] DEBUG org.apache.kafka.common.metrics.Metrics - Added sensor with name produce-throttle-time
2017-02-15 20:55:06.386 [main] DEBUG org.apache.kafka.common.metrics.Metrics - Added sensor with name records-per-request
2017-02-15 20:55:06.386 [main] DEBUG org.apache.kafka.common.metrics.Metrics - Added sensor with name record-retries
2017-02-15 20:55:06.387 [main] DEBUG org.apache.kafka.common.metrics.Metrics - Added sensor with name errors
2017-02-15 20:55:06.387 [main] DEBUG org.apache.kafka.common.metrics.Metrics - Added sensor with name record-size-max
2017-02-15 20:55:06.389 [kafka-producer-network-thread | producer-1] DEBUG org.apache.kafka.clients.producer.internals.Sender - Starting Kafka producer I/O thread.
2017-02-15 20:55:06.395 [main] INFO  org.apache.kafka.common.utils.AppInfoParser - Kafka version : 0.10.1.0
2017-02-15 20:55:06.396 [main] INFO  org.apache.kafka.common.utils.AppInfoParser - Kafka commitId : 3402a74efb23d1d4
2017-02-15 20:55:06.397 [main] DEBUG org.apache.kafka.clients.producer.KafkaProducer - Kafka producer started
2017-02-15 20:55:06.449 [kafka-producer-network-thread | producer-1] DEBUG org.apache.kafka.clients.NetworkClient - Initialize connection to node -1 for sending metadata request
2017-02-15 20:55:06.450 [kafka-producer-network-thread | producer-1] DEBUG org.apache.kafka.clients.NetworkClient - Initiating connection to node -1 at 10.1.131.18:9092.
2017-02-15 20:55:06.495 [kafka-producer-network-thread | producer-1] DEBUG org.apache.kafka.common.metrics.Metrics - Added sensor with name node--1.bytes-sent
2017-02-15 20:55:06.496 [kafka-producer-network-thread | producer-1] DEBUG org.apache.kafka.common.metrics.Metrics - Added sensor with name node--1.bytes-received
2017-02-15 20:55:06.496 [kafka-producer-network-thread | producer-1] DEBUG org.apache.kafka.common.metrics.Metrics - Added sensor with name node--1.latency
2017-02-15 20:55:06.497 [kafka-producer-network-thread | producer-1] DEBUG org.apache.kafka.common.network.Selector - Created socket with SO_RCVBUF = 32768, SO_SNDBUF = 131072, SO_TIMEOUT = 0 to node -1
2017-02-15 20:55:06.498 [kafka-producer-network-thread | producer-1] DEBUG org.apache.kafka.clients.NetworkClient - Completed connection to node -1
2017-02-15 20:55:06.601 [kafka-producer-network-thread | producer-1] DEBUG org.apache.kafka.clients.NetworkClient - Sending metadata request {topics=[file_syn3]} to node -1
2017-02-15 20:55:06.686 [kafka-producer-network-thread | producer-1] DEBUG org.apache.kafka.clients.Metadata - Updated cluster metadata version 2 to Cluster(id = 5ynpwwfGT3KEdCwLvR2Jog, nodes = [10.1.131.18:9092 (id: 0 rack: null)], partitions = [Partition(topic = file_syn3, partition = 0, leader = 0, replicas = [0,], isr = [0,])])
2017-02-15 20:55:06.702 [kafka-producer-network-thread | producer-1] DEBUG org.apache.kafka.clients.NetworkClient - Initiating connection to node 0 at 10.1.131.18:9092.
2017-02-15 20:55:06.742 [kafka-producer-network-thread | producer-1] DEBUG org.apache.kafka.common.metrics.Metrics - Added sensor with name node-0.bytes-sent
2017-02-15 20:55:06.743 [kafka-producer-network-thread | producer-1] DEBUG org.apache.kafka.common.metrics.Metrics - Added sensor with name node-0.bytes-received
2017-02-15 20:55:06.743 [kafka-producer-network-thread | producer-1] DEBUG org.apache.kafka.common.metrics.Metrics - Added sensor with name node-0.latency
2017-02-15 20:55:06.744 [kafka-producer-network-thread | producer-1] DEBUG org.apache.kafka.common.network.Selector - Created socket with SO_RCVBUF = 32768, SO_SNDBUF = 131072, SO_TIMEOUT = 0 to node 0
2017-02-15 20:55:06.744 [kafka-producer-network-thread | producer-1] DEBUG org.apache.kafka.clients.NetworkClient - Completed connection to node 0
2017-02-15 20:55:06.744 [kafka-producer-network-thread | producer-1] DEBUG org.apache.kafka.common.metrics.Metrics - Added sensor with name topic.file_syn3.records-per-batch
2017-02-15 20:55:06.744 [kafka-producer-network-thread | producer-1] DEBUG org.apache.kafka.common.metrics.Metrics - Added sensor with name topic.file_syn3.bytes
2017-02-15 20:55:06.744 [kafka-producer-network-thread | producer-1] DEBUG org.apache.kafka.common.metrics.Metrics - Added sensor with name topic.file_syn3.compression-rate
2017-02-15 20:55:06.745 [kafka-producer-network-thread | producer-1] DEBUG org.apache.kafka.common.metrics.Metrics - Added sensor with name topic.file_syn3.record-retries
2017-02-15 20:55:06.745 [kafka-producer-network-thread | producer-1] DEBUG org.apache.kafka.common.metrics.Metrics - Added sensor with name topic.file_syn3.record-errors
2017-02-15 20:55:16.067 [main] INFO  org.apache.kafka.clients.producer.ProducerConfig - ProducerConfig values: 
	acks = 1
	batch.size = 16384
	block.on.buffer.full = false
	bootstrap.servers = [10.1.131.18:9092]
	buffer.memory = 33554432
	client.id = 
	compression.type = none
	connections.max.idle.ms = 540000
	interceptor.classes = null
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 0
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.fetch.timeout.ms = 60000
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	receive.buffer.bytes = 32768
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 0
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	timeout.ms = 30000
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer

2017-02-15 20:55:16.124 [main] INFO  org.apache.kafka.clients.producer.ProducerConfig - ProducerConfig values: 
	acks = 1
	batch.size = 16384
	block.on.buffer.full = false
	bootstrap.servers = [10.1.131.18:9092]
	buffer.memory = 33554432
	client.id = producer-1
	compression.type = none
	connections.max.idle.ms = 540000
	interceptor.classes = null
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 0
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.fetch.timeout.ms = 60000
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	receive.buffer.bytes = 32768
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 0
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	timeout.ms = 30000
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer

2017-02-15 20:55:16.138 [main] DEBUG org.apache.kafka.common.metrics.Metrics - Added sensor with name bufferpool-wait-time
2017-02-15 20:55:16.144 [main] DEBUG org.apache.kafka.common.metrics.Metrics - Added sensor with name buffer-exhausted-records
2017-02-15 20:55:16.147 [main] DEBUG org.apache.kafka.clients.Metadata - Updated cluster metadata version 1 to Cluster(id = null, nodes = [10.1.131.18:9092 (id: -1 rack: null)], partitions = [])
2017-02-15 20:55:16.173 [main] DEBUG org.apache.kafka.common.metrics.Metrics - Added sensor with name connections-closed:
2017-02-15 20:55:16.174 [main] DEBUG org.apache.kafka.common.metrics.Metrics - Added sensor with name connections-created:
2017-02-15 20:55:16.174 [main] DEBUG org.apache.kafka.common.metrics.Metrics - Added sensor with name bytes-sent-received:
2017-02-15 20:55:16.174 [main] DEBUG org.apache.kafka.common.metrics.Metrics - Added sensor with name bytes-sent:
2017-02-15 20:55:16.176 [main] DEBUG org.apache.kafka.common.metrics.Metrics - Added sensor with name bytes-received:
2017-02-15 20:55:16.176 [main] DEBUG org.apache.kafka.common.metrics.Metrics - Added sensor with name select-time:
2017-02-15 20:55:16.176 [main] DEBUG org.apache.kafka.common.metrics.Metrics - Added sensor with name io-time:
2017-02-15 20:55:16.184 [main] DEBUG org.apache.kafka.common.metrics.Metrics - Added sensor with name batch-size
2017-02-15 20:55:16.184 [main] DEBUG org.apache.kafka.common.metrics.Metrics - Added sensor with name compression-rate
2017-02-15 20:55:16.184 [main] DEBUG org.apache.kafka.common.metrics.Metrics - Added sensor with name queue-time
2017-02-15 20:55:16.185 [main] DEBUG org.apache.kafka.common.metrics.Metrics - Added sensor with name request-time
2017-02-15 20:55:16.185 [main] DEBUG org.apache.kafka.common.metrics.Metrics - Added sensor with name produce-throttle-time
2017-02-15 20:55:16.185 [main] DEBUG org.apache.kafka.common.metrics.Metrics - Added sensor with name records-per-request
2017-02-15 20:55:16.186 [main] DEBUG org.apache.kafka.common.metrics.Metrics - Added sensor with name record-retries
2017-02-15 20:55:16.186 [main] DEBUG org.apache.kafka.common.metrics.Metrics - Added sensor with name errors
2017-02-15 20:55:16.187 [main] DEBUG org.apache.kafka.common.metrics.Metrics - Added sensor with name record-size-max
2017-02-15 20:55:16.191 [kafka-producer-network-thread | producer-1] DEBUG org.apache.kafka.clients.producer.internals.Sender - Starting Kafka producer I/O thread.
2017-02-15 20:55:16.199 [main] INFO  org.apache.kafka.common.utils.AppInfoParser - Kafka version : 0.10.1.0
2017-02-15 20:55:16.199 [main] INFO  org.apache.kafka.common.utils.AppInfoParser - Kafka commitId : 3402a74efb23d1d4
2017-02-15 20:55:16.200 [main] DEBUG org.apache.kafka.clients.producer.KafkaProducer - Kafka producer started
2017-02-15 20:55:16.247 [kafka-producer-network-thread | producer-1] DEBUG org.apache.kafka.clients.NetworkClient - Initialize connection to node -1 for sending metadata request
2017-02-15 20:55:16.247 [kafka-producer-network-thread | producer-1] DEBUG org.apache.kafka.clients.NetworkClient - Initiating connection to node -1 at 10.1.131.18:9092.
2017-02-15 20:55:16.291 [kafka-producer-network-thread | producer-1] DEBUG org.apache.kafka.common.metrics.Metrics - Added sensor with name node--1.bytes-sent
2017-02-15 20:55:16.291 [kafka-producer-network-thread | producer-1] DEBUG org.apache.kafka.common.metrics.Metrics - Added sensor with name node--1.bytes-received
2017-02-15 20:55:16.291 [kafka-producer-network-thread | producer-1] DEBUG org.apache.kafka.common.metrics.Metrics - Added sensor with name node--1.latency
2017-02-15 20:55:16.292 [kafka-producer-network-thread | producer-1] DEBUG org.apache.kafka.common.network.Selector - Created socket with SO_RCVBUF = 32768, SO_SNDBUF = 131072, SO_TIMEOUT = 0 to node -1
2017-02-15 20:55:16.292 [kafka-producer-network-thread | producer-1] DEBUG org.apache.kafka.clients.NetworkClient - Completed connection to node -1
2017-02-15 20:55:16.401 [kafka-producer-network-thread | producer-1] DEBUG org.apache.kafka.clients.NetworkClient - Sending metadata request {topics=[file_syn3]} to node -1
2017-02-15 20:55:16.478 [kafka-producer-network-thread | producer-1] DEBUG org.apache.kafka.clients.Metadata - Updated cluster metadata version 2 to Cluster(id = 5ynpwwfGT3KEdCwLvR2Jog, nodes = [10.1.131.18:9092 (id: 0 rack: null)], partitions = [Partition(topic = file_syn3, partition = 0, leader = 0, replicas = [0,], isr = [0,])])
2017-02-15 20:55:16.493 [kafka-producer-network-thread | producer-1] DEBUG org.apache.kafka.clients.NetworkClient - Initiating connection to node 0 at 10.1.131.18:9092.
2017-02-15 20:55:16.534 [kafka-producer-network-thread | producer-1] DEBUG org.apache.kafka.common.metrics.Metrics - Added sensor with name node-0.bytes-sent
2017-02-15 20:55:16.534 [kafka-producer-network-thread | producer-1] DEBUG org.apache.kafka.common.metrics.Metrics - Added sensor with name node-0.bytes-received
2017-02-15 20:55:16.534 [kafka-producer-network-thread | producer-1] DEBUG org.apache.kafka.common.metrics.Metrics - Added sensor with name node-0.latency
2017-02-15 20:55:16.535 [kafka-producer-network-thread | producer-1] DEBUG org.apache.kafka.common.network.Selector - Created socket with SO_RCVBUF = 32768, SO_SNDBUF = 131072, SO_TIMEOUT = 0 to node 0
2017-02-15 20:55:16.535 [kafka-producer-network-thread | producer-1] DEBUG org.apache.kafka.clients.NetworkClient - Completed connection to node 0
2017-02-15 20:55:16.535 [kafka-producer-network-thread | producer-1] DEBUG org.apache.kafka.common.metrics.Metrics - Added sensor with name topic.file_syn3.records-per-batch
2017-02-15 20:55:16.536 [kafka-producer-network-thread | producer-1] DEBUG org.apache.kafka.common.metrics.Metrics - Added sensor with name topic.file_syn3.bytes
2017-02-15 20:55:16.536 [kafka-producer-network-thread | producer-1] DEBUG org.apache.kafka.common.metrics.Metrics - Added sensor with name topic.file_syn3.compression-rate
2017-02-15 20:55:16.536 [kafka-producer-network-thread | producer-1] DEBUG org.apache.kafka.common.metrics.Metrics - Added sensor with name topic.file_syn3.record-retries
2017-02-15 20:55:16.536 [kafka-producer-network-thread | producer-1] DEBUG org.apache.kafka.common.metrics.Metrics - Added sensor with name topic.file_syn3.record-errors
2017-02-15 20:55:40.784 [main] INFO  org.apache.kafka.clients.producer.ProducerConfig - ProducerConfig values: 
	acks = 1
	batch.size = 16384
	block.on.buffer.full = false
	bootstrap.servers = [10.1.131.18:9092]
	buffer.memory = 33554432
	client.id = 
	compression.type = none
	connections.max.idle.ms = 540000
	interceptor.classes = null
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 0
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.fetch.timeout.ms = 60000
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	receive.buffer.bytes = 32768
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 0
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	timeout.ms = 30000
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer

2017-02-15 20:55:40.840 [main] INFO  org.apache.kafka.clients.producer.ProducerConfig - ProducerConfig values: 
	acks = 1
	batch.size = 16384
	block.on.buffer.full = false
	bootstrap.servers = [10.1.131.18:9092]
	buffer.memory = 33554432
	client.id = producer-1
	compression.type = none
	connections.max.idle.ms = 540000
	interceptor.classes = null
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 0
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.fetch.timeout.ms = 60000
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	receive.buffer.bytes = 32768
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 0
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	timeout.ms = 30000
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer

2017-02-15 20:55:40.853 [main] DEBUG org.apache.kafka.common.metrics.Metrics - Added sensor with name bufferpool-wait-time
2017-02-15 20:55:40.861 [main] DEBUG org.apache.kafka.common.metrics.Metrics - Added sensor with name buffer-exhausted-records
2017-02-15 20:55:40.865 [main] DEBUG org.apache.kafka.clients.Metadata - Updated cluster metadata version 1 to Cluster(id = null, nodes = [10.1.131.18:9092 (id: -1 rack: null)], partitions = [])
2017-02-15 20:55:40.890 [main] DEBUG org.apache.kafka.common.metrics.Metrics - Added sensor with name connections-closed:
2017-02-15 20:55:40.890 [main] DEBUG org.apache.kafka.common.metrics.Metrics - Added sensor with name connections-created:
2017-02-15 20:55:40.891 [main] DEBUG org.apache.kafka.common.metrics.Metrics - Added sensor with name bytes-sent-received:
2017-02-15 20:55:40.891 [main] DEBUG org.apache.kafka.common.metrics.Metrics - Added sensor with name bytes-sent:
2017-02-15 20:55:40.893 [main] DEBUG org.apache.kafka.common.metrics.Metrics - Added sensor with name bytes-received:
2017-02-15 20:55:40.894 [main] DEBUG org.apache.kafka.common.metrics.Metrics - Added sensor with name select-time:
2017-02-15 20:55:40.895 [main] DEBUG org.apache.kafka.common.metrics.Metrics - Added sensor with name io-time:
2017-02-15 20:55:40.902 [main] DEBUG org.apache.kafka.common.metrics.Metrics - Added sensor with name batch-size
2017-02-15 20:55:40.902 [main] DEBUG org.apache.kafka.common.metrics.Metrics - Added sensor with name compression-rate
2017-02-15 20:55:40.903 [main] DEBUG org.apache.kafka.common.metrics.Metrics - Added sensor with name queue-time
2017-02-15 20:55:40.903 [main] DEBUG org.apache.kafka.common.metrics.Metrics - Added sensor with name request-time
2017-02-15 20:55:40.903 [main] DEBUG org.apache.kafka.common.metrics.Metrics - Added sensor with name produce-throttle-time
2017-02-15 20:55:40.904 [main] DEBUG org.apache.kafka.common.metrics.Metrics - Added sensor with name records-per-request
2017-02-15 20:55:40.904 [main] DEBUG org.apache.kafka.common.metrics.Metrics - Added sensor with name record-retries
2017-02-15 20:55:40.904 [main] DEBUG org.apache.kafka.common.metrics.Metrics - Added sensor with name errors
2017-02-15 20:55:40.905 [main] DEBUG org.apache.kafka.common.metrics.Metrics - Added sensor with name record-size-max
2017-02-15 20:55:40.907 [kafka-producer-network-thread | producer-1] DEBUG org.apache.kafka.clients.producer.internals.Sender - Starting Kafka producer I/O thread.
2017-02-15 20:55:40.912 [main] INFO  org.apache.kafka.common.utils.AppInfoParser - Kafka version : 0.10.1.0
2017-02-15 20:55:40.912 [main] INFO  org.apache.kafka.common.utils.AppInfoParser - Kafka commitId : 3402a74efb23d1d4
2017-02-15 20:55:40.913 [main] DEBUG org.apache.kafka.clients.producer.KafkaProducer - Kafka producer started
2017-02-15 20:55:40.965 [kafka-producer-network-thread | producer-1] DEBUG org.apache.kafka.clients.NetworkClient - Initialize connection to node -1 for sending metadata request
2017-02-15 20:55:40.965 [kafka-producer-network-thread | producer-1] DEBUG org.apache.kafka.clients.NetworkClient - Initiating connection to node -1 at 10.1.131.18:9092.
2017-02-15 20:55:41.006 [kafka-producer-network-thread | producer-1] DEBUG org.apache.kafka.common.metrics.Metrics - Added sensor with name node--1.bytes-sent
2017-02-15 20:55:41.007 [kafka-producer-network-thread | producer-1] DEBUG org.apache.kafka.common.metrics.Metrics - Added sensor with name node--1.bytes-received
2017-02-15 20:55:41.007 [kafka-producer-network-thread | producer-1] DEBUG org.apache.kafka.common.metrics.Metrics - Added sensor with name node--1.latency
2017-02-15 20:55:41.008 [kafka-producer-network-thread | producer-1] DEBUG org.apache.kafka.common.network.Selector - Created socket with SO_RCVBUF = 32768, SO_SNDBUF = 131072, SO_TIMEOUT = 0 to node -1
2017-02-15 20:55:41.008 [kafka-producer-network-thread | producer-1] DEBUG org.apache.kafka.clients.NetworkClient - Completed connection to node -1
2017-02-15 20:55:41.116 [kafka-producer-network-thread | producer-1] DEBUG org.apache.kafka.clients.NetworkClient - Sending metadata request {topics=[file_syn3]} to node -1
2017-02-15 20:55:41.192 [kafka-producer-network-thread | producer-1] DEBUG org.apache.kafka.clients.Metadata - Updated cluster metadata version 2 to Cluster(id = 5ynpwwfGT3KEdCwLvR2Jog, nodes = [10.1.131.18:9092 (id: 0 rack: null)], partitions = [Partition(topic = file_syn3, partition = 0, leader = 0, replicas = [0,], isr = [0,])])
2017-02-15 20:55:41.211 [kafka-producer-network-thread | producer-1] DEBUG org.apache.kafka.clients.NetworkClient - Initiating connection to node 0 at 10.1.131.18:9092.
2017-02-15 20:55:41.256 [kafka-producer-network-thread | producer-1] DEBUG org.apache.kafka.common.metrics.Metrics - Added sensor with name node-0.bytes-sent
2017-02-15 20:55:41.257 [kafka-producer-network-thread | producer-1] DEBUG org.apache.kafka.common.metrics.Metrics - Added sensor with name node-0.bytes-received
2017-02-15 20:55:41.257 [kafka-producer-network-thread | producer-1] DEBUG org.apache.kafka.common.metrics.Metrics - Added sensor with name node-0.latency
2017-02-15 20:55:41.257 [kafka-producer-network-thread | producer-1] DEBUG org.apache.kafka.common.network.Selector - Created socket with SO_RCVBUF = 32768, SO_SNDBUF = 131072, SO_TIMEOUT = 0 to node 0
2017-02-15 20:55:41.257 [kafka-producer-network-thread | producer-1] DEBUG org.apache.kafka.clients.NetworkClient - Completed connection to node 0
2017-02-15 20:55:41.258 [kafka-producer-network-thread | producer-1] DEBUG org.apache.kafka.common.metrics.Metrics - Added sensor with name topic.file_syn3.records-per-batch
2017-02-15 20:55:41.258 [kafka-producer-network-thread | producer-1] DEBUG org.apache.kafka.common.metrics.Metrics - Added sensor with name topic.file_syn3.bytes
2017-02-15 20:55:41.258 [kafka-producer-network-thread | producer-1] DEBUG org.apache.kafka.common.metrics.Metrics - Added sensor with name topic.file_syn3.compression-rate
2017-02-15 20:55:41.258 [kafka-producer-network-thread | producer-1] DEBUG org.apache.kafka.common.metrics.Metrics - Added sensor with name topic.file_syn3.record-retries
2017-02-15 20:55:41.259 [kafka-producer-network-thread | producer-1] DEBUG org.apache.kafka.common.metrics.Metrics - Added sensor with name topic.file_syn3.record-errors
2017-02-15 20:56:23.219 [main] INFO  org.apache.kafka.clients.producer.ProducerConfig - ProducerConfig values: 
	acks = 1
	batch.size = 16384
	block.on.buffer.full = false
	bootstrap.servers = [10.1.131.18:9092]
	buffer.memory = 33554432
	client.id = 
	compression.type = none
	connections.max.idle.ms = 540000
	interceptor.classes = null
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 0
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.fetch.timeout.ms = 60000
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	receive.buffer.bytes = 32768
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 0
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	timeout.ms = 30000
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer

2017-02-15 20:56:23.299 [main] INFO  org.apache.kafka.clients.producer.ProducerConfig - ProducerConfig values: 
	acks = 1
	batch.size = 16384
	block.on.buffer.full = false
	bootstrap.servers = [10.1.131.18:9092]
	buffer.memory = 33554432
	client.id = producer-1
	compression.type = none
	connections.max.idle.ms = 540000
	interceptor.classes = null
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 0
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.fetch.timeout.ms = 60000
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	receive.buffer.bytes = 32768
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 0
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	timeout.ms = 30000
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer

2017-02-15 20:56:23.314 [main] DEBUG org.apache.kafka.common.metrics.Metrics - Added sensor with name bufferpool-wait-time
2017-02-15 20:56:23.321 [main] DEBUG org.apache.kafka.common.metrics.Metrics - Added sensor with name buffer-exhausted-records
2017-02-15 20:56:23.325 [main] DEBUG org.apache.kafka.clients.Metadata - Updated cluster metadata version 1 to Cluster(id = null, nodes = [10.1.131.18:9092 (id: -1 rack: null)], partitions = [])
2017-02-15 20:56:23.349 [main] DEBUG org.apache.kafka.common.metrics.Metrics - Added sensor with name connections-closed:
2017-02-15 20:56:23.349 [main] DEBUG org.apache.kafka.common.metrics.Metrics - Added sensor with name connections-created:
2017-02-15 20:56:23.349 [main] DEBUG org.apache.kafka.common.metrics.Metrics - Added sensor with name bytes-sent-received:
2017-02-15 20:56:23.349 [main] DEBUG org.apache.kafka.common.metrics.Metrics - Added sensor with name bytes-sent:
2017-02-15 20:56:23.351 [main] DEBUG org.apache.kafka.common.metrics.Metrics - Added sensor with name bytes-received:
2017-02-15 20:56:23.352 [main] DEBUG org.apache.kafka.common.metrics.Metrics - Added sensor with name select-time:
2017-02-15 20:56:23.352 [main] DEBUG org.apache.kafka.common.metrics.Metrics - Added sensor with name io-time:
2017-02-15 20:56:23.359 [main] DEBUG org.apache.kafka.common.metrics.Metrics - Added sensor with name batch-size
2017-02-15 20:56:23.359 [main] DEBUG org.apache.kafka.common.metrics.Metrics - Added sensor with name compression-rate
2017-02-15 20:56:23.360 [main] DEBUG org.apache.kafka.common.metrics.Metrics - Added sensor with name queue-time
2017-02-15 20:56:23.360 [main] DEBUG org.apache.kafka.common.metrics.Metrics - Added sensor with name request-time
2017-02-15 20:56:23.360 [main] DEBUG org.apache.kafka.common.metrics.Metrics - Added sensor with name produce-throttle-time
2017-02-15 20:56:23.361 [main] DEBUG org.apache.kafka.common.metrics.Metrics - Added sensor with name records-per-request
2017-02-15 20:56:23.361 [main] DEBUG org.apache.kafka.common.metrics.Metrics - Added sensor with name record-retries
2017-02-15 20:56:23.361 [main] DEBUG org.apache.kafka.common.metrics.Metrics - Added sensor with name errors
2017-02-15 20:56:23.362 [main] DEBUG org.apache.kafka.common.metrics.Metrics - Added sensor with name record-size-max
2017-02-15 20:56:23.364 [kafka-producer-network-thread | producer-1] DEBUG org.apache.kafka.clients.producer.internals.Sender - Starting Kafka producer I/O thread.
2017-02-15 20:56:23.368 [main] INFO  org.apache.kafka.common.utils.AppInfoParser - Kafka version : 0.10.1.0
2017-02-15 20:56:23.368 [main] INFO  org.apache.kafka.common.utils.AppInfoParser - Kafka commitId : 3402a74efb23d1d4
2017-02-15 20:56:23.369 [main] DEBUG org.apache.kafka.clients.producer.KafkaProducer - Kafka producer started
2017-02-15 20:56:23.424 [kafka-producer-network-thread | producer-1] DEBUG org.apache.kafka.clients.NetworkClient - Initialize connection to node -1 for sending metadata request
2017-02-15 20:56:23.424 [kafka-producer-network-thread | producer-1] DEBUG org.apache.kafka.clients.NetworkClient - Initiating connection to node -1 at 10.1.131.18:9092.
2017-02-15 20:56:23.467 [kafka-producer-network-thread | producer-1] DEBUG org.apache.kafka.common.metrics.Metrics - Added sensor with name node--1.bytes-sent
2017-02-15 20:56:23.468 [kafka-producer-network-thread | producer-1] DEBUG org.apache.kafka.common.metrics.Metrics - Added sensor with name node--1.bytes-received
2017-02-15 20:56:23.468 [kafka-producer-network-thread | producer-1] DEBUG org.apache.kafka.common.metrics.Metrics - Added sensor with name node--1.latency
2017-02-15 20:56:23.469 [kafka-producer-network-thread | producer-1] DEBUG org.apache.kafka.common.network.Selector - Created socket with SO_RCVBUF = 32768, SO_SNDBUF = 131072, SO_TIMEOUT = 0 to node -1
2017-02-15 20:56:23.469 [kafka-producer-network-thread | producer-1] DEBUG org.apache.kafka.clients.NetworkClient - Completed connection to node -1
2017-02-15 20:56:23.572 [kafka-producer-network-thread | producer-1] DEBUG org.apache.kafka.clients.NetworkClient - Sending metadata request {topics=[file_syn3]} to node -1
2017-02-15 20:56:23.656 [kafka-producer-network-thread | producer-1] DEBUG org.apache.kafka.clients.Metadata - Updated cluster metadata version 2 to Cluster(id = 5ynpwwfGT3KEdCwLvR2Jog, nodes = [10.1.131.18:9092 (id: 0 rack: null)], partitions = [Partition(topic = file_syn3, partition = 0, leader = 0, replicas = [0,], isr = [0,])])
2017-02-15 20:56:23.673 [kafka-producer-network-thread | producer-1] DEBUG org.apache.kafka.clients.NetworkClient - Initiating connection to node 0 at 10.1.131.18:9092.
2017-02-15 20:56:23.716 [kafka-producer-network-thread | producer-1] DEBUG org.apache.kafka.common.metrics.Metrics - Added sensor with name node-0.bytes-sent
2017-02-15 20:56:23.716 [kafka-producer-network-thread | producer-1] DEBUG org.apache.kafka.common.metrics.Metrics - Added sensor with name node-0.bytes-received
2017-02-15 20:56:23.717 [kafka-producer-network-thread | producer-1] DEBUG org.apache.kafka.common.metrics.Metrics - Added sensor with name node-0.latency
2017-02-15 20:56:23.717 [kafka-producer-network-thread | producer-1] DEBUG org.apache.kafka.common.network.Selector - Created socket with SO_RCVBUF = 32768, SO_SNDBUF = 131072, SO_TIMEOUT = 0 to node 0
2017-02-15 20:56:23.718 [kafka-producer-network-thread | producer-1] DEBUG org.apache.kafka.clients.NetworkClient - Completed connection to node 0
2017-02-15 20:56:23.718 [kafka-producer-network-thread | producer-1] DEBUG org.apache.kafka.common.metrics.Metrics - Added sensor with name topic.file_syn3.records-per-batch
2017-02-15 20:56:23.719 [kafka-producer-network-thread | producer-1] DEBUG org.apache.kafka.common.metrics.Metrics - Added sensor with name topic.file_syn3.bytes
2017-02-15 20:56:23.719 [kafka-producer-network-thread | producer-1] DEBUG org.apache.kafka.common.metrics.Metrics - Added sensor with name topic.file_syn3.compression-rate
2017-02-15 20:56:23.719 [kafka-producer-network-thread | producer-1] DEBUG org.apache.kafka.common.metrics.Metrics - Added sensor with name topic.file_syn3.record-retries
2017-02-15 20:56:23.720 [kafka-producer-network-thread | producer-1] DEBUG org.apache.kafka.common.metrics.Metrics - Added sensor with name topic.file_syn3.record-errors
2017-02-15 20:57:51.946 [main] INFO  org.apache.kafka.clients.producer.ProducerConfig - ProducerConfig values: 
	acks = 1
	batch.size = 16384
	block.on.buffer.full = false
	bootstrap.servers = [10.1.131.18:9092]
	buffer.memory = 33554432
	client.id = 
	compression.type = none
	connections.max.idle.ms = 540000
	interceptor.classes = null
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 0
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.fetch.timeout.ms = 60000
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	receive.buffer.bytes = 32768
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 0
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	timeout.ms = 30000
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer

2017-02-15 20:57:52.004 [main] INFO  org.apache.kafka.clients.producer.ProducerConfig - ProducerConfig values: 
	acks = 1
	batch.size = 16384
	block.on.buffer.full = false
	bootstrap.servers = [10.1.131.18:9092]
	buffer.memory = 33554432
	client.id = producer-1
	compression.type = none
	connections.max.idle.ms = 540000
	interceptor.classes = null
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 0
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.fetch.timeout.ms = 60000
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	receive.buffer.bytes = 32768
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 0
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	timeout.ms = 30000
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer

2017-02-15 20:57:52.019 [main] DEBUG org.apache.kafka.common.metrics.Metrics - Added sensor with name bufferpool-wait-time
2017-02-15 20:57:52.024 [main] DEBUG org.apache.kafka.common.metrics.Metrics - Added sensor with name buffer-exhausted-records
2017-02-15 20:57:52.028 [main] DEBUG org.apache.kafka.clients.Metadata - Updated cluster metadata version 1 to Cluster(id = null, nodes = [10.1.131.18:9092 (id: -1 rack: null)], partitions = [])
2017-02-15 20:57:52.053 [main] DEBUG org.apache.kafka.common.metrics.Metrics - Added sensor with name connections-closed:
2017-02-15 20:57:52.053 [main] DEBUG org.apache.kafka.common.metrics.Metrics - Added sensor with name connections-created:
2017-02-15 20:57:52.054 [main] DEBUG org.apache.kafka.common.metrics.Metrics - Added sensor with name bytes-sent-received:
2017-02-15 20:57:52.054 [main] DEBUG org.apache.kafka.common.metrics.Metrics - Added sensor with name bytes-sent:
2017-02-15 20:57:52.056 [main] DEBUG org.apache.kafka.common.metrics.Metrics - Added sensor with name bytes-received:
2017-02-15 20:57:52.056 [main] DEBUG org.apache.kafka.common.metrics.Metrics - Added sensor with name select-time:
2017-02-15 20:57:52.056 [main] DEBUG org.apache.kafka.common.metrics.Metrics - Added sensor with name io-time:
2017-02-15 20:57:52.063 [main] DEBUG org.apache.kafka.common.metrics.Metrics - Added sensor with name batch-size
2017-02-15 20:57:52.064 [main] DEBUG org.apache.kafka.common.metrics.Metrics - Added sensor with name compression-rate
2017-02-15 20:57:52.064 [main] DEBUG org.apache.kafka.common.metrics.Metrics - Added sensor with name queue-time
2017-02-15 20:57:52.064 [main] DEBUG org.apache.kafka.common.metrics.Metrics - Added sensor with name request-time
2017-02-15 20:57:52.065 [main] DEBUG org.apache.kafka.common.metrics.Metrics - Added sensor with name produce-throttle-time
2017-02-15 20:57:52.065 [main] DEBUG org.apache.kafka.common.metrics.Metrics - Added sensor with name records-per-request
2017-02-15 20:57:52.065 [main] DEBUG org.apache.kafka.common.metrics.Metrics - Added sensor with name record-retries
2017-02-15 20:57:52.065 [main] DEBUG org.apache.kafka.common.metrics.Metrics - Added sensor with name errors
2017-02-15 20:57:52.066 [main] DEBUG org.apache.kafka.common.metrics.Metrics - Added sensor with name record-size-max
2017-02-15 20:57:52.069 [kafka-producer-network-thread | producer-1] DEBUG org.apache.kafka.clients.producer.internals.Sender - Starting Kafka producer I/O thread.
2017-02-15 20:57:52.073 [main] INFO  org.apache.kafka.common.utils.AppInfoParser - Kafka version : 0.10.1.0
2017-02-15 20:57:52.074 [main] INFO  org.apache.kafka.common.utils.AppInfoParser - Kafka commitId : 3402a74efb23d1d4
2017-02-15 20:57:52.074 [main] DEBUG org.apache.kafka.clients.producer.KafkaProducer - Kafka producer started
2017-02-15 20:57:52.128 [kafka-producer-network-thread | producer-1] DEBUG org.apache.kafka.clients.NetworkClient - Initialize connection to node -1 for sending metadata request
2017-02-15 20:57:52.128 [kafka-producer-network-thread | producer-1] DEBUG org.apache.kafka.clients.NetworkClient - Initiating connection to node -1 at 10.1.131.18:9092.
2017-02-15 20:57:52.169 [kafka-producer-network-thread | producer-1] DEBUG org.apache.kafka.common.metrics.Metrics - Added sensor with name node--1.bytes-sent
2017-02-15 20:57:52.170 [kafka-producer-network-thread | producer-1] DEBUG org.apache.kafka.common.metrics.Metrics - Added sensor with name node--1.bytes-received
2017-02-15 20:57:52.170 [kafka-producer-network-thread | producer-1] DEBUG org.apache.kafka.common.metrics.Metrics - Added sensor with name node--1.latency
2017-02-15 20:57:52.171 [kafka-producer-network-thread | producer-1] DEBUG org.apache.kafka.common.network.Selector - Created socket with SO_RCVBUF = 32768, SO_SNDBUF = 131072, SO_TIMEOUT = 0 to node -1
2017-02-15 20:57:52.171 [kafka-producer-network-thread | producer-1] DEBUG org.apache.kafka.clients.NetworkClient - Completed connection to node -1
2017-02-15 20:57:52.276 [kafka-producer-network-thread | producer-1] DEBUG org.apache.kafka.clients.NetworkClient - Sending metadata request {topics=[file_syn3]} to node -1
2017-02-15 20:57:52.344 [kafka-producer-network-thread | producer-1] DEBUG org.apache.kafka.clients.Metadata - Updated cluster metadata version 2 to Cluster(id = 5ynpwwfGT3KEdCwLvR2Jog, nodes = [10.1.131.18:9092 (id: 0 rack: null)], partitions = [Partition(topic = file_syn3, partition = 0, leader = 0, replicas = [0,], isr = [0,])])
2017-02-15 20:57:52.358 [kafka-producer-network-thread | producer-1] DEBUG org.apache.kafka.clients.NetworkClient - Initiating connection to node 0 at 10.1.131.18:9092.
2017-02-15 20:57:52.399 [kafka-producer-network-thread | producer-1] DEBUG org.apache.kafka.common.metrics.Metrics - Added sensor with name node-0.bytes-sent
2017-02-15 20:57:52.400 [kafka-producer-network-thread | producer-1] DEBUG org.apache.kafka.common.metrics.Metrics - Added sensor with name node-0.bytes-received
2017-02-15 20:57:52.400 [kafka-producer-network-thread | producer-1] DEBUG org.apache.kafka.common.metrics.Metrics - Added sensor with name node-0.latency
2017-02-15 20:57:52.401 [kafka-producer-network-thread | producer-1] DEBUG org.apache.kafka.common.network.Selector - Created socket with SO_RCVBUF = 32768, SO_SNDBUF = 131072, SO_TIMEOUT = 0 to node 0
2017-02-15 20:57:52.401 [kafka-producer-network-thread | producer-1] DEBUG org.apache.kafka.clients.NetworkClient - Completed connection to node 0
2017-02-15 20:57:52.401 [kafka-producer-network-thread | producer-1] DEBUG org.apache.kafka.common.metrics.Metrics - Added sensor with name topic.file_syn3.records-per-batch
2017-02-15 20:57:52.402 [kafka-producer-network-thread | producer-1] DEBUG org.apache.kafka.common.metrics.Metrics - Added sensor with name topic.file_syn3.bytes
2017-02-15 20:57:52.402 [kafka-producer-network-thread | producer-1] DEBUG org.apache.kafka.common.metrics.Metrics - Added sensor with name topic.file_syn3.compression-rate
2017-02-15 20:57:52.402 [kafka-producer-network-thread | producer-1] DEBUG org.apache.kafka.common.metrics.Metrics - Added sensor with name topic.file_syn3.record-retries
2017-02-15 20:57:52.402 [kafka-producer-network-thread | producer-1] DEBUG org.apache.kafka.common.metrics.Metrics - Added sensor with name topic.file_syn3.record-errors
2017-02-15 20:58:41.406 [main] INFO  org.apache.kafka.clients.producer.ProducerConfig - ProducerConfig values: 
	acks = 1
	batch.size = 16384
	block.on.buffer.full = false
	bootstrap.servers = [10.1.131.18:9092]
	buffer.memory = 33554432
	client.id = 
	compression.type = none
	connections.max.idle.ms = 540000
	interceptor.classes = null
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 0
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.fetch.timeout.ms = 60000
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	receive.buffer.bytes = 32768
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 0
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	timeout.ms = 30000
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer

2017-02-15 20:58:41.462 [main] INFO  org.apache.kafka.clients.producer.ProducerConfig - ProducerConfig values: 
	acks = 1
	batch.size = 16384
	block.on.buffer.full = false
	bootstrap.servers = [10.1.131.18:9092]
	buffer.memory = 33554432
	client.id = producer-1
	compression.type = none
	connections.max.idle.ms = 540000
	interceptor.classes = null
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 0
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.fetch.timeout.ms = 60000
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	receive.buffer.bytes = 32768
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 0
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	timeout.ms = 30000
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer

2017-02-15 20:58:41.473 [main] DEBUG org.apache.kafka.common.metrics.Metrics - Added sensor with name bufferpool-wait-time
2017-02-15 20:58:41.481 [main] DEBUG org.apache.kafka.common.metrics.Metrics - Added sensor with name buffer-exhausted-records
2017-02-15 20:58:41.485 [main] DEBUG org.apache.kafka.clients.Metadata - Updated cluster metadata version 1 to Cluster(id = null, nodes = [10.1.131.18:9092 (id: -1 rack: null)], partitions = [])
2017-02-15 20:58:41.510 [main] DEBUG org.apache.kafka.common.metrics.Metrics - Added sensor with name connections-closed:
2017-02-15 20:58:41.510 [main] DEBUG org.apache.kafka.common.metrics.Metrics - Added sensor with name connections-created:
2017-02-15 20:58:41.510 [main] DEBUG org.apache.kafka.common.metrics.Metrics - Added sensor with name bytes-sent-received:
2017-02-15 20:58:41.511 [main] DEBUG org.apache.kafka.common.metrics.Metrics - Added sensor with name bytes-sent:
2017-02-15 20:58:41.513 [main] DEBUG org.apache.kafka.common.metrics.Metrics - Added sensor with name bytes-received:
2017-02-15 20:58:41.513 [main] DEBUG org.apache.kafka.common.metrics.Metrics - Added sensor with name select-time:
2017-02-15 20:58:41.513 [main] DEBUG org.apache.kafka.common.metrics.Metrics - Added sensor with name io-time:
2017-02-15 20:58:41.520 [main] DEBUG org.apache.kafka.common.metrics.Metrics - Added sensor with name batch-size
2017-02-15 20:58:41.520 [main] DEBUG org.apache.kafka.common.metrics.Metrics - Added sensor with name compression-rate
2017-02-15 20:58:41.521 [main] DEBUG org.apache.kafka.common.metrics.Metrics - Added sensor with name queue-time
2017-02-15 20:58:41.521 [main] DEBUG org.apache.kafka.common.metrics.Metrics - Added sensor with name request-time
2017-02-15 20:58:41.521 [main] DEBUG org.apache.kafka.common.metrics.Metrics - Added sensor with name produce-throttle-time
2017-02-15 20:58:41.522 [main] DEBUG org.apache.kafka.common.metrics.Metrics - Added sensor with name records-per-request
2017-02-15 20:58:41.522 [main] DEBUG org.apache.kafka.common.metrics.Metrics - Added sensor with name record-retries
2017-02-15 20:58:41.522 [main] DEBUG org.apache.kafka.common.metrics.Metrics - Added sensor with name errors
2017-02-15 20:58:41.523 [main] DEBUG org.apache.kafka.common.metrics.Metrics - Added sensor with name record-size-max
2017-02-15 20:58:41.527 [kafka-producer-network-thread | producer-1] DEBUG org.apache.kafka.clients.producer.internals.Sender - Starting Kafka producer I/O thread.
2017-02-15 20:58:41.531 [main] INFO  org.apache.kafka.common.utils.AppInfoParser - Kafka version : 0.10.1.0
2017-02-15 20:58:41.531 [main] INFO  org.apache.kafka.common.utils.AppInfoParser - Kafka commitId : 3402a74efb23d1d4
2017-02-15 20:58:41.532 [main] DEBUG org.apache.kafka.clients.producer.KafkaProducer - Kafka producer started
2017-02-15 20:58:41.584 [kafka-producer-network-thread | producer-1] DEBUG org.apache.kafka.clients.NetworkClient - Initialize connection to node -1 for sending metadata request
2017-02-15 20:58:41.584 [kafka-producer-network-thread | producer-1] DEBUG org.apache.kafka.clients.NetworkClient - Initiating connection to node -1 at 10.1.131.18:9092.
2017-02-15 20:58:41.628 [kafka-producer-network-thread | producer-1] DEBUG org.apache.kafka.common.metrics.Metrics - Added sensor with name node--1.bytes-sent
2017-02-15 20:58:41.628 [kafka-producer-network-thread | producer-1] DEBUG org.apache.kafka.common.metrics.Metrics - Added sensor with name node--1.bytes-received
2017-02-15 20:58:41.628 [kafka-producer-network-thread | producer-1] DEBUG org.apache.kafka.common.metrics.Metrics - Added sensor with name node--1.latency
2017-02-15 20:58:41.629 [kafka-producer-network-thread | producer-1] DEBUG org.apache.kafka.common.network.Selector - Created socket with SO_RCVBUF = 32768, SO_SNDBUF = 131072, SO_TIMEOUT = 0 to node -1
2017-02-15 20:58:41.629 [kafka-producer-network-thread | producer-1] DEBUG org.apache.kafka.clients.NetworkClient - Completed connection to node -1
2017-02-15 20:58:41.735 [kafka-producer-network-thread | producer-1] DEBUG org.apache.kafka.clients.NetworkClient - Sending metadata request {topics=[file_syn3]} to node -1
2017-02-15 20:58:41.804 [kafka-producer-network-thread | producer-1] DEBUG org.apache.kafka.clients.Metadata - Updated cluster metadata version 2 to Cluster(id = 5ynpwwfGT3KEdCwLvR2Jog, nodes = [10.1.131.18:9092 (id: 0 rack: null)], partitions = [Partition(topic = file_syn3, partition = 0, leader = 0, replicas = [0,], isr = [0,])])
2017-02-15 20:58:41.818 [kafka-producer-network-thread | producer-1] DEBUG org.apache.kafka.clients.NetworkClient - Initiating connection to node 0 at 10.1.131.18:9092.
2017-02-15 20:58:41.859 [kafka-producer-network-thread | producer-1] DEBUG org.apache.kafka.common.metrics.Metrics - Added sensor with name node-0.bytes-sent
2017-02-15 20:58:41.859 [kafka-producer-network-thread | producer-1] DEBUG org.apache.kafka.common.metrics.Metrics - Added sensor with name node-0.bytes-received
2017-02-15 20:58:41.860 [kafka-producer-network-thread | producer-1] DEBUG org.apache.kafka.common.metrics.Metrics - Added sensor with name node-0.latency
2017-02-15 20:58:41.860 [kafka-producer-network-thread | producer-1] DEBUG org.apache.kafka.common.network.Selector - Created socket with SO_RCVBUF = 32768, SO_SNDBUF = 131072, SO_TIMEOUT = 0 to node 0
2017-02-15 20:58:41.860 [kafka-producer-network-thread | producer-1] DEBUG org.apache.kafka.clients.NetworkClient - Completed connection to node 0
2017-02-15 20:58:41.861 [kafka-producer-network-thread | producer-1] DEBUG org.apache.kafka.common.metrics.Metrics - Added sensor with name topic.file_syn3.records-per-batch
2017-02-15 20:58:41.861 [kafka-producer-network-thread | producer-1] DEBUG org.apache.kafka.common.metrics.Metrics - Added sensor with name topic.file_syn3.bytes
2017-02-15 20:58:41.861 [kafka-producer-network-thread | producer-1] DEBUG org.apache.kafka.common.metrics.Metrics - Added sensor with name topic.file_syn3.compression-rate
2017-02-15 20:58:41.861 [kafka-producer-network-thread | producer-1] DEBUG org.apache.kafka.common.metrics.Metrics - Added sensor with name topic.file_syn3.record-retries
2017-02-15 20:58:41.861 [kafka-producer-network-thread | producer-1] DEBUG org.apache.kafka.common.metrics.Metrics - Added sensor with name topic.file_syn3.record-errors
2017-02-15 20:59:41.718 [main] INFO  org.apache.kafka.clients.producer.ProducerConfig - ProducerConfig values: 
	acks = 1
	batch.size = 16384
	block.on.buffer.full = false
	bootstrap.servers = [10.1.131.18:9092]
	buffer.memory = 33554432
	client.id = 
	compression.type = none
	connections.max.idle.ms = 540000
	interceptor.classes = null
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 0
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.fetch.timeout.ms = 60000
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	receive.buffer.bytes = 32768
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 0
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	timeout.ms = 30000
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer

2017-02-15 20:59:41.772 [main] INFO  org.apache.kafka.clients.producer.ProducerConfig - ProducerConfig values: 
	acks = 1
	batch.size = 16384
	block.on.buffer.full = false
	bootstrap.servers = [10.1.131.18:9092]
	buffer.memory = 33554432
	client.id = producer-1
	compression.type = none
	connections.max.idle.ms = 540000
	interceptor.classes = null
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 0
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.fetch.timeout.ms = 60000
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	receive.buffer.bytes = 32768
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 0
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	timeout.ms = 30000
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer

2017-02-15 20:59:41.785 [main] DEBUG org.apache.kafka.common.metrics.Metrics - Added sensor with name bufferpool-wait-time
2017-02-15 20:59:41.793 [main] DEBUG org.apache.kafka.common.metrics.Metrics - Added sensor with name buffer-exhausted-records
2017-02-15 20:59:41.798 [main] DEBUG org.apache.kafka.clients.Metadata - Updated cluster metadata version 1 to Cluster(id = null, nodes = [10.1.131.18:9092 (id: -1 rack: null)], partitions = [])
2017-02-15 20:59:41.824 [main] DEBUG org.apache.kafka.common.metrics.Metrics - Added sensor with name connections-closed:
2017-02-15 20:59:41.824 [main] DEBUG org.apache.kafka.common.metrics.Metrics - Added sensor with name connections-created:
2017-02-15 20:59:41.825 [main] DEBUG org.apache.kafka.common.metrics.Metrics - Added sensor with name bytes-sent-received:
2017-02-15 20:59:41.825 [main] DEBUG org.apache.kafka.common.metrics.Metrics - Added sensor with name bytes-sent:
2017-02-15 20:59:41.827 [main] DEBUG org.apache.kafka.common.metrics.Metrics - Added sensor with name bytes-received:
2017-02-15 20:59:41.827 [main] DEBUG org.apache.kafka.common.metrics.Metrics - Added sensor with name select-time:
2017-02-15 20:59:41.827 [main] DEBUG org.apache.kafka.common.metrics.Metrics - Added sensor with name io-time:
2017-02-15 20:59:41.834 [main] DEBUG org.apache.kafka.common.metrics.Metrics - Added sensor with name batch-size
2017-02-15 20:59:41.835 [main] DEBUG org.apache.kafka.common.metrics.Metrics - Added sensor with name compression-rate
2017-02-15 20:59:41.835 [main] DEBUG org.apache.kafka.common.metrics.Metrics - Added sensor with name queue-time
2017-02-15 20:59:41.835 [main] DEBUG org.apache.kafka.common.metrics.Metrics - Added sensor with name request-time
2017-02-15 20:59:41.837 [main] DEBUG org.apache.kafka.common.metrics.Metrics - Added sensor with name produce-throttle-time
2017-02-15 20:59:41.837 [main] DEBUG org.apache.kafka.common.metrics.Metrics - Added sensor with name records-per-request
2017-02-15 20:59:41.837 [main] DEBUG org.apache.kafka.common.metrics.Metrics - Added sensor with name record-retries
2017-02-15 20:59:41.837 [main] DEBUG org.apache.kafka.common.metrics.Metrics - Added sensor with name errors
2017-02-15 20:59:41.837 [main] DEBUG org.apache.kafka.common.metrics.Metrics - Added sensor with name record-size-max
2017-02-15 20:59:41.839 [kafka-producer-network-thread | producer-1] DEBUG org.apache.kafka.clients.producer.internals.Sender - Starting Kafka producer I/O thread.
2017-02-15 20:59:41.844 [main] INFO  org.apache.kafka.common.utils.AppInfoParser - Kafka version : 0.10.1.0
2017-02-15 20:59:41.844 [main] INFO  org.apache.kafka.common.utils.AppInfoParser - Kafka commitId : 3402a74efb23d1d4
2017-02-15 20:59:41.845 [main] DEBUG org.apache.kafka.clients.producer.KafkaProducer - Kafka producer started
2017-02-15 20:59:41.979 [kafka-producer-network-thread | producer-1] DEBUG org.apache.kafka.clients.NetworkClient - Initialize connection to node -1 for sending metadata request
2017-02-15 20:59:41.980 [kafka-producer-network-thread | producer-1] DEBUG org.apache.kafka.clients.NetworkClient - Initiating connection to node -1 at 10.1.131.18:9092.
2017-02-15 20:59:42.023 [kafka-producer-network-thread | producer-1] DEBUG org.apache.kafka.common.metrics.Metrics - Added sensor with name node--1.bytes-sent
2017-02-15 20:59:42.024 [kafka-producer-network-thread | producer-1] DEBUG org.apache.kafka.common.metrics.Metrics - Added sensor with name node--1.bytes-received
2017-02-15 20:59:42.024 [kafka-producer-network-thread | producer-1] DEBUG org.apache.kafka.common.metrics.Metrics - Added sensor with name node--1.latency
2017-02-15 20:59:42.025 [kafka-producer-network-thread | producer-1] DEBUG org.apache.kafka.common.network.Selector - Created socket with SO_RCVBUF = 32768, SO_SNDBUF = 131072, SO_TIMEOUT = 0 to node -1
2017-02-15 20:59:42.025 [kafka-producer-network-thread | producer-1] DEBUG org.apache.kafka.clients.NetworkClient - Completed connection to node -1
2017-02-15 20:59:42.120 [kafka-producer-network-thread | producer-1] DEBUG org.apache.kafka.clients.NetworkClient - Sending metadata request {topics=[file_syn3]} to node -1
2017-02-15 20:59:42.194 [kafka-producer-network-thread | producer-1] DEBUG org.apache.kafka.clients.Metadata - Updated cluster metadata version 2 to Cluster(id = 5ynpwwfGT3KEdCwLvR2Jog, nodes = [10.1.131.18:9092 (id: 0 rack: null)], partitions = [Partition(topic = file_syn3, partition = 0, leader = 0, replicas = [0,], isr = [0,])])
2017-02-15 20:59:42.213 [kafka-producer-network-thread | producer-1] DEBUG org.apache.kafka.clients.NetworkClient - Initiating connection to node 0 at 10.1.131.18:9092.
2017-02-15 20:59:42.254 [kafka-producer-network-thread | producer-1] DEBUG org.apache.kafka.common.metrics.Metrics - Added sensor with name node-0.bytes-sent
2017-02-15 20:59:42.254 [kafka-producer-network-thread | producer-1] DEBUG org.apache.kafka.common.metrics.Metrics - Added sensor with name node-0.bytes-received
2017-02-15 20:59:42.254 [kafka-producer-network-thread | producer-1] DEBUG org.apache.kafka.common.metrics.Metrics - Added sensor with name node-0.latency
2017-02-15 20:59:42.255 [kafka-producer-network-thread | producer-1] DEBUG org.apache.kafka.common.network.Selector - Created socket with SO_RCVBUF = 32768, SO_SNDBUF = 131072, SO_TIMEOUT = 0 to node 0
2017-02-15 20:59:42.255 [kafka-producer-network-thread | producer-1] DEBUG org.apache.kafka.clients.NetworkClient - Completed connection to node 0
2017-02-15 20:59:42.255 [kafka-producer-network-thread | producer-1] DEBUG org.apache.kafka.common.metrics.Metrics - Added sensor with name topic.file_syn3.records-per-batch
2017-02-15 20:59:42.255 [kafka-producer-network-thread | producer-1] DEBUG org.apache.kafka.common.metrics.Metrics - Added sensor with name topic.file_syn3.bytes
2017-02-15 20:59:42.256 [kafka-producer-network-thread | producer-1] DEBUG org.apache.kafka.common.metrics.Metrics - Added sensor with name topic.file_syn3.compression-rate
2017-02-15 20:59:42.256 [kafka-producer-network-thread | producer-1] DEBUG org.apache.kafka.common.metrics.Metrics - Added sensor with name topic.file_syn3.record-retries
2017-02-15 20:59:42.256 [kafka-producer-network-thread | producer-1] DEBUG org.apache.kafka.common.metrics.Metrics - Added sensor with name topic.file_syn3.record-errors
2017-02-15 21:02:14.709 [main] INFO  org.apache.kafka.clients.producer.ProducerConfig - ProducerConfig values: 
	acks = 1
	batch.size = 16384
	block.on.buffer.full = false
	bootstrap.servers = [10.1.131.18:9092]
	buffer.memory = 33554432
	client.id = 
	compression.type = none
	connections.max.idle.ms = 540000
	interceptor.classes = null
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 0
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.fetch.timeout.ms = 60000
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	receive.buffer.bytes = 32768
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 0
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	timeout.ms = 30000
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer

2017-02-15 21:02:14.772 [main] INFO  org.apache.kafka.clients.producer.ProducerConfig - ProducerConfig values: 
	acks = 1
	batch.size = 16384
	block.on.buffer.full = false
	bootstrap.servers = [10.1.131.18:9092]
	buffer.memory = 33554432
	client.id = producer-1
	compression.type = none
	connections.max.idle.ms = 540000
	interceptor.classes = null
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 0
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.fetch.timeout.ms = 60000
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	receive.buffer.bytes = 32768
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 0
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	timeout.ms = 30000
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer

2017-02-15 21:02:14.785 [main] DEBUG org.apache.kafka.common.metrics.Metrics - Added sensor with name bufferpool-wait-time
2017-02-15 21:02:14.791 [main] DEBUG org.apache.kafka.common.metrics.Metrics - Added sensor with name buffer-exhausted-records
2017-02-15 21:02:14.793 [main] DEBUG org.apache.kafka.clients.Metadata - Updated cluster metadata version 1 to Cluster(id = null, nodes = [10.1.131.18:9092 (id: -1 rack: null)], partitions = [])
2017-02-15 21:02:14.817 [main] DEBUG org.apache.kafka.common.metrics.Metrics - Added sensor with name connections-closed:
2017-02-15 21:02:14.817 [main] DEBUG org.apache.kafka.common.metrics.Metrics - Added sensor with name connections-created:
2017-02-15 21:02:14.818 [main] DEBUG org.apache.kafka.common.metrics.Metrics - Added sensor with name bytes-sent-received:
2017-02-15 21:02:14.818 [main] DEBUG org.apache.kafka.common.metrics.Metrics - Added sensor with name bytes-sent:
2017-02-15 21:02:14.820 [main] DEBUG org.apache.kafka.common.metrics.Metrics - Added sensor with name bytes-received:
2017-02-15 21:02:14.820 [main] DEBUG org.apache.kafka.common.metrics.Metrics - Added sensor with name select-time:
2017-02-15 21:02:14.820 [main] DEBUG org.apache.kafka.common.metrics.Metrics - Added sensor with name io-time:
2017-02-15 21:02:14.827 [main] DEBUG org.apache.kafka.common.metrics.Metrics - Added sensor with name batch-size
2017-02-15 21:02:14.828 [main] DEBUG org.apache.kafka.common.metrics.Metrics - Added sensor with name compression-rate
2017-02-15 21:02:14.828 [main] DEBUG org.apache.kafka.common.metrics.Metrics - Added sensor with name queue-time
2017-02-15 21:02:14.828 [main] DEBUG org.apache.kafka.common.metrics.Metrics - Added sensor with name request-time
2017-02-15 21:02:14.829 [main] DEBUG org.apache.kafka.common.metrics.Metrics - Added sensor with name produce-throttle-time
2017-02-15 21:02:14.829 [main] DEBUG org.apache.kafka.common.metrics.Metrics - Added sensor with name records-per-request
2017-02-15 21:02:14.829 [main] DEBUG org.apache.kafka.common.metrics.Metrics - Added sensor with name record-retries
2017-02-15 21:02:14.830 [main] DEBUG org.apache.kafka.common.metrics.Metrics - Added sensor with name errors
2017-02-15 21:02:14.830 [main] DEBUG org.apache.kafka.common.metrics.Metrics - Added sensor with name record-size-max
2017-02-15 21:02:14.834 [kafka-producer-network-thread | producer-1] DEBUG org.apache.kafka.clients.producer.internals.Sender - Starting Kafka producer I/O thread.
2017-02-15 21:02:14.839 [main] INFO  org.apache.kafka.common.utils.AppInfoParser - Kafka version : 0.10.1.0
2017-02-15 21:02:14.839 [main] INFO  org.apache.kafka.common.utils.AppInfoParser - Kafka commitId : 3402a74efb23d1d4
2017-02-15 21:02:14.840 [main] DEBUG org.apache.kafka.clients.producer.KafkaProducer - Kafka producer started
2017-02-15 21:02:44.556 [kafka-producer-network-thread | producer-1] DEBUG org.apache.kafka.clients.NetworkClient - Initialize connection to node -1 for sending metadata request
2017-02-15 21:02:44.557 [kafka-producer-network-thread | producer-1] DEBUG org.apache.kafka.clients.NetworkClient - Initiating connection to node -1 at 10.1.131.18:9092.
2017-02-15 21:02:44.602 [kafka-producer-network-thread | producer-1] DEBUG org.apache.kafka.common.metrics.Metrics - Added sensor with name node--1.bytes-sent
2017-02-15 21:02:44.602 [kafka-producer-network-thread | producer-1] DEBUG org.apache.kafka.common.metrics.Metrics - Added sensor with name node--1.bytes-received
2017-02-15 21:02:44.602 [kafka-producer-network-thread | producer-1] DEBUG org.apache.kafka.common.metrics.Metrics - Added sensor with name node--1.latency
2017-02-15 21:02:44.603 [kafka-producer-network-thread | producer-1] DEBUG org.apache.kafka.common.network.Selector - Created socket with SO_RCVBUF = 32768, SO_SNDBUF = 131072, SO_TIMEOUT = 0 to node -1
2017-02-15 21:02:44.603 [kafka-producer-network-thread | producer-1] DEBUG org.apache.kafka.clients.NetworkClient - Completed connection to node -1
2017-02-15 21:02:44.700 [kafka-producer-network-thread | producer-1] DEBUG org.apache.kafka.clients.NetworkClient - Sending metadata request {topics=[file_syn3]} to node -1
2017-02-15 21:02:44.776 [kafka-producer-network-thread | producer-1] DEBUG org.apache.kafka.clients.Metadata - Updated cluster metadata version 2 to Cluster(id = 5ynpwwfGT3KEdCwLvR2Jog, nodes = [10.1.131.18:9092 (id: 0 rack: null)], partitions = [Partition(topic = file_syn3, partition = 0, leader = 0, replicas = [0,], isr = [0,])])
2017-02-15 21:02:44.811 [main] DEBUG org.apache.kafka.clients.producer.KafkaProducer - Exception occurred during message send:
org.apache.kafka.common.errors.RecordTooLargeException: The message is 9259147 bytes when serialized which is larger than the maximum request size you have configured with the max.request.size configuration.
2017-02-15 21:07:20.922 [main] INFO  org.apache.kafka.clients.producer.ProducerConfig - ProducerConfig values: 
	acks = 1
	batch.size = 16384
	block.on.buffer.full = false
	bootstrap.servers = [10.1.131.18:9092]
	buffer.memory = 33554432
	client.id = 
	compression.type = none
	connections.max.idle.ms = 540000
	interceptor.classes = null
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 0
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1000000000
	metadata.fetch.timeout.ms = 60000
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	receive.buffer.bytes = 32768
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 0
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	timeout.ms = 30000
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer

2017-02-15 21:07:20.981 [main] INFO  org.apache.kafka.clients.producer.ProducerConfig - ProducerConfig values: 
	acks = 1
	batch.size = 16384
	block.on.buffer.full = false
	bootstrap.servers = [10.1.131.18:9092]
	buffer.memory = 33554432
	client.id = producer-1
	compression.type = none
	connections.max.idle.ms = 540000
	interceptor.classes = null
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 0
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1000000000
	metadata.fetch.timeout.ms = 60000
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	receive.buffer.bytes = 32768
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 0
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	timeout.ms = 30000
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer

2017-02-15 21:07:20.997 [main] DEBUG org.apache.kafka.common.metrics.Metrics - Added sensor with name bufferpool-wait-time
2017-02-15 21:07:21.005 [main] DEBUG org.apache.kafka.common.metrics.Metrics - Added sensor with name buffer-exhausted-records
2017-02-15 21:07:21.010 [main] DEBUG org.apache.kafka.clients.Metadata - Updated cluster metadata version 1 to Cluster(id = null, nodes = [10.1.131.18:9092 (id: -1 rack: null)], partitions = [])
2017-02-15 21:07:21.036 [main] DEBUG org.apache.kafka.common.metrics.Metrics - Added sensor with name connections-closed:
2017-02-15 21:07:21.036 [main] DEBUG org.apache.kafka.common.metrics.Metrics - Added sensor with name connections-created:
2017-02-15 21:07:21.036 [main] DEBUG org.apache.kafka.common.metrics.Metrics - Added sensor with name bytes-sent-received:
2017-02-15 21:07:21.036 [main] DEBUG org.apache.kafka.common.metrics.Metrics - Added sensor with name bytes-sent:
2017-02-15 21:07:21.038 [main] DEBUG org.apache.kafka.common.metrics.Metrics - Added sensor with name bytes-received:
2017-02-15 21:07:21.038 [main] DEBUG org.apache.kafka.common.metrics.Metrics - Added sensor with name select-time:
2017-02-15 21:07:21.039 [main] DEBUG org.apache.kafka.common.metrics.Metrics - Added sensor with name io-time:
2017-02-15 21:07:21.046 [main] DEBUG org.apache.kafka.common.metrics.Metrics - Added sensor with name batch-size
2017-02-15 21:07:21.046 [main] DEBUG org.apache.kafka.common.metrics.Metrics - Added sensor with name compression-rate
2017-02-15 21:07:21.046 [main] DEBUG org.apache.kafka.common.metrics.Metrics - Added sensor with name queue-time
2017-02-15 21:07:21.047 [main] DEBUG org.apache.kafka.common.metrics.Metrics - Added sensor with name request-time
2017-02-15 21:07:21.047 [main] DEBUG org.apache.kafka.common.metrics.Metrics - Added sensor with name produce-throttle-time
2017-02-15 21:07:21.047 [main] DEBUG org.apache.kafka.common.metrics.Metrics - Added sensor with name records-per-request
2017-02-15 21:07:21.048 [main] DEBUG org.apache.kafka.common.metrics.Metrics - Added sensor with name record-retries
2017-02-15 21:07:21.048 [main] DEBUG org.apache.kafka.common.metrics.Metrics - Added sensor with name errors
2017-02-15 21:07:21.048 [main] DEBUG org.apache.kafka.common.metrics.Metrics - Added sensor with name record-size-max
2017-02-15 21:07:21.051 [kafka-producer-network-thread | producer-1] DEBUG org.apache.kafka.clients.producer.internals.Sender - Starting Kafka producer I/O thread.
2017-02-15 21:07:21.057 [main] INFO  org.apache.kafka.common.utils.AppInfoParser - Kafka version : 0.10.1.0
2017-02-15 21:07:21.058 [main] INFO  org.apache.kafka.common.utils.AppInfoParser - Kafka commitId : 3402a74efb23d1d4
2017-02-15 21:07:21.059 [main] DEBUG org.apache.kafka.clients.producer.KafkaProducer - Kafka producer started
2017-02-15 21:07:29.509 [kafka-producer-network-thread | producer-1] DEBUG org.apache.kafka.clients.NetworkClient - Initialize connection to node -1 for sending metadata request
2017-02-15 21:07:29.510 [kafka-producer-network-thread | producer-1] DEBUG org.apache.kafka.clients.NetworkClient - Initiating connection to node -1 at 10.1.131.18:9092.
2017-02-15 21:07:29.550 [kafka-producer-network-thread | producer-1] DEBUG org.apache.kafka.common.metrics.Metrics - Added sensor with name node--1.bytes-sent
2017-02-15 21:07:29.551 [kafka-producer-network-thread | producer-1] DEBUG org.apache.kafka.common.metrics.Metrics - Added sensor with name node--1.bytes-received
2017-02-15 21:07:29.551 [kafka-producer-network-thread | producer-1] DEBUG org.apache.kafka.common.metrics.Metrics - Added sensor with name node--1.latency
2017-02-15 21:07:29.551 [kafka-producer-network-thread | producer-1] DEBUG org.apache.kafka.common.network.Selector - Created socket with SO_RCVBUF = 32768, SO_SNDBUF = 131072, SO_TIMEOUT = 0 to node -1
2017-02-15 21:07:29.552 [kafka-producer-network-thread | producer-1] DEBUG org.apache.kafka.clients.NetworkClient - Completed connection to node -1
2017-02-15 21:07:29.663 [kafka-producer-network-thread | producer-1] DEBUG org.apache.kafka.clients.NetworkClient - Sending metadata request {topics=[file_syn3]} to node -1
2017-02-15 21:07:29.735 [kafka-producer-network-thread | producer-1] DEBUG org.apache.kafka.clients.Metadata - Updated cluster metadata version 2 to Cluster(id = 5ynpwwfGT3KEdCwLvR2Jog, nodes = [10.1.131.18:9092 (id: 0 rack: null)], partitions = [Partition(topic = file_syn3, partition = 0, leader = 0, replicas = [0,], isr = [0,])])
2017-02-15 21:07:30.191 [kafka-producer-network-thread | producer-1] DEBUG org.apache.kafka.clients.NetworkClient - Initiating connection to node 0 at 10.1.131.18:9092.
2017-02-15 21:07:30.269 [kafka-producer-network-thread | producer-1] DEBUG org.apache.kafka.common.metrics.Metrics - Added sensor with name node-0.bytes-sent
2017-02-15 21:07:30.270 [kafka-producer-network-thread | producer-1] DEBUG org.apache.kafka.common.metrics.Metrics - Added sensor with name node-0.bytes-received
2017-02-15 21:07:30.270 [kafka-producer-network-thread | producer-1] DEBUG org.apache.kafka.common.metrics.Metrics - Added sensor with name node-0.latency
2017-02-15 21:07:30.271 [kafka-producer-network-thread | producer-1] DEBUG org.apache.kafka.common.network.Selector - Created socket with SO_RCVBUF = 32768, SO_SNDBUF = 131072, SO_TIMEOUT = 0 to node 0
2017-02-15 21:07:30.271 [kafka-producer-network-thread | producer-1] DEBUG org.apache.kafka.clients.NetworkClient - Completed connection to node 0
2017-02-15 21:07:30.271 [kafka-producer-network-thread | producer-1] DEBUG org.apache.kafka.common.metrics.Metrics - Added sensor with name topic.file_syn3.records-per-batch
2017-02-15 21:07:30.272 [kafka-producer-network-thread | producer-1] DEBUG org.apache.kafka.common.metrics.Metrics - Added sensor with name topic.file_syn3.bytes
2017-02-15 21:07:30.272 [kafka-producer-network-thread | producer-1] DEBUG org.apache.kafka.common.metrics.Metrics - Added sensor with name topic.file_syn3.compression-rate
2017-02-15 21:07:30.272 [kafka-producer-network-thread | producer-1] DEBUG org.apache.kafka.common.metrics.Metrics - Added sensor with name topic.file_syn3.record-retries
2017-02-15 21:07:30.272 [kafka-producer-network-thread | producer-1] DEBUG org.apache.kafka.common.metrics.Metrics - Added sensor with name topic.file_syn3.record-errors
2017-02-15 21:09:55.222 [main] INFO  org.apache.kafka.clients.producer.ProducerConfig - ProducerConfig values: 
	acks = 1
	batch.size = 16384
	block.on.buffer.full = false
	bootstrap.servers = [10.1.131.18:9092]
	buffer.memory = 33554432
	client.id = 
	compression.type = none
	connections.max.idle.ms = 540000
	interceptor.classes = null
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 0
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1000000000
	metadata.fetch.timeout.ms = 60000
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	receive.buffer.bytes = 32768
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 0
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	timeout.ms = 30000
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer

2017-02-15 21:09:55.301 [main] INFO  org.apache.kafka.clients.producer.ProducerConfig - ProducerConfig values: 
	acks = 1
	batch.size = 16384
	block.on.buffer.full = false
	bootstrap.servers = [10.1.131.18:9092]
	buffer.memory = 33554432
	client.id = producer-1
	compression.type = none
	connections.max.idle.ms = 540000
	interceptor.classes = null
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 0
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1000000000
	metadata.fetch.timeout.ms = 60000
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	receive.buffer.bytes = 32768
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 0
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	timeout.ms = 30000
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer

2017-02-15 21:09:55.314 [main] DEBUG org.apache.kafka.common.metrics.Metrics - Added sensor with name bufferpool-wait-time
2017-02-15 21:09:55.320 [main] DEBUG org.apache.kafka.common.metrics.Metrics - Added sensor with name buffer-exhausted-records
2017-02-15 21:09:55.323 [main] DEBUG org.apache.kafka.clients.Metadata - Updated cluster metadata version 1 to Cluster(id = null, nodes = [10.1.131.18:9092 (id: -1 rack: null)], partitions = [])
2017-02-15 21:09:55.349 [main] DEBUG org.apache.kafka.common.metrics.Metrics - Added sensor with name connections-closed:
2017-02-15 21:09:55.350 [main] DEBUG org.apache.kafka.common.metrics.Metrics - Added sensor with name connections-created:
2017-02-15 21:09:55.350 [main] DEBUG org.apache.kafka.common.metrics.Metrics - Added sensor with name bytes-sent-received:
2017-02-15 21:09:55.350 [main] DEBUG org.apache.kafka.common.metrics.Metrics - Added sensor with name bytes-sent:
2017-02-15 21:09:55.351 [main] DEBUG org.apache.kafka.common.metrics.Metrics - Added sensor with name bytes-received:
2017-02-15 21:09:55.352 [main] DEBUG org.apache.kafka.common.metrics.Metrics - Added sensor with name select-time:
2017-02-15 21:09:55.352 [main] DEBUG org.apache.kafka.common.metrics.Metrics - Added sensor with name io-time:
2017-02-15 21:09:55.359 [main] DEBUG org.apache.kafka.common.metrics.Metrics - Added sensor with name batch-size
2017-02-15 21:09:55.360 [main] DEBUG org.apache.kafka.common.metrics.Metrics - Added sensor with name compression-rate
2017-02-15 21:09:55.360 [main] DEBUG org.apache.kafka.common.metrics.Metrics - Added sensor with name queue-time
2017-02-15 21:09:55.360 [main] DEBUG org.apache.kafka.common.metrics.Metrics - Added sensor with name request-time
2017-02-15 21:09:55.360 [main] DEBUG org.apache.kafka.common.metrics.Metrics - Added sensor with name produce-throttle-time
2017-02-15 21:09:55.361 [main] DEBUG org.apache.kafka.common.metrics.Metrics - Added sensor with name records-per-request
2017-02-15 21:09:55.361 [main] DEBUG org.apache.kafka.common.metrics.Metrics - Added sensor with name record-retries
2017-02-15 21:09:55.361 [main] DEBUG org.apache.kafka.common.metrics.Metrics - Added sensor with name errors
2017-02-15 21:09:55.362 [main] DEBUG org.apache.kafka.common.metrics.Metrics - Added sensor with name record-size-max
2017-02-15 21:09:55.365 [kafka-producer-network-thread | producer-1] DEBUG org.apache.kafka.clients.producer.internals.Sender - Starting Kafka producer I/O thread.
2017-02-15 21:09:55.370 [main] INFO  org.apache.kafka.common.utils.AppInfoParser - Kafka version : 0.10.1.0
2017-02-15 21:09:55.371 [main] INFO  org.apache.kafka.common.utils.AppInfoParser - Kafka commitId : 3402a74efb23d1d4
2017-02-15 21:09:55.372 [main] DEBUG org.apache.kafka.clients.producer.KafkaProducer - Kafka producer started
2017-02-15 21:10:05.079 [kafka-producer-network-thread | producer-1] DEBUG org.apache.kafka.clients.NetworkClient - Initialize connection to node -1 for sending metadata request
2017-02-15 21:10:05.080 [kafka-producer-network-thread | producer-1] DEBUG org.apache.kafka.clients.NetworkClient - Initiating connection to node -1 at 10.1.131.18:9092.
2017-02-15 21:10:05.126 [kafka-producer-network-thread | producer-1] DEBUG org.apache.kafka.common.metrics.Metrics - Added sensor with name node--1.bytes-sent
2017-02-15 21:10:05.127 [kafka-producer-network-thread | producer-1] DEBUG org.apache.kafka.common.metrics.Metrics - Added sensor with name node--1.bytes-received
2017-02-15 21:10:05.127 [kafka-producer-network-thread | producer-1] DEBUG org.apache.kafka.common.metrics.Metrics - Added sensor with name node--1.latency
2017-02-15 21:10:05.128 [kafka-producer-network-thread | producer-1] DEBUG org.apache.kafka.common.network.Selector - Created socket with SO_RCVBUF = 32768, SO_SNDBUF = 131072, SO_TIMEOUT = 0 to node -1
2017-02-15 21:10:05.128 [kafka-producer-network-thread | producer-1] DEBUG org.apache.kafka.clients.NetworkClient - Completed connection to node -1
2017-02-15 21:10:05.236 [kafka-producer-network-thread | producer-1] DEBUG org.apache.kafka.clients.NetworkClient - Sending metadata request {topics=[file_syn3]} to node -1
2017-02-15 21:10:05.324 [kafka-producer-network-thread | producer-1] DEBUG org.apache.kafka.clients.Metadata - Updated cluster metadata version 2 to Cluster(id = 5ynpwwfGT3KEdCwLvR2Jog, nodes = [10.1.131.18:9092 (id: 0 rack: null)], partitions = [Partition(topic = file_syn3, partition = 0, leader = 0, replicas = [0,], isr = [0,])])
2017-02-15 21:10:05.712 [kafka-producer-network-thread | producer-1] DEBUG org.apache.kafka.clients.NetworkClient - Initiating connection to node 0 at 10.1.131.18:9092.
2017-02-15 21:10:05.751 [kafka-producer-network-thread | producer-1] DEBUG org.apache.kafka.common.metrics.Metrics - Added sensor with name node-0.bytes-sent
2017-02-15 21:10:05.752 [kafka-producer-network-thread | producer-1] DEBUG org.apache.kafka.common.metrics.Metrics - Added sensor with name node-0.bytes-received
2017-02-15 21:10:05.753 [kafka-producer-network-thread | producer-1] DEBUG org.apache.kafka.common.metrics.Metrics - Added sensor with name node-0.latency
2017-02-15 21:10:05.753 [kafka-producer-network-thread | producer-1] DEBUG org.apache.kafka.common.network.Selector - Created socket with SO_RCVBUF = 32768, SO_SNDBUF = 131072, SO_TIMEOUT = 0 to node 0
2017-02-15 21:10:05.753 [kafka-producer-network-thread | producer-1] DEBUG org.apache.kafka.clients.NetworkClient - Completed connection to node 0
2017-02-15 21:10:05.754 [kafka-producer-network-thread | producer-1] DEBUG org.apache.kafka.common.metrics.Metrics - Added sensor with name topic.file_syn3.records-per-batch
2017-02-15 21:10:05.754 [kafka-producer-network-thread | producer-1] DEBUG org.apache.kafka.common.metrics.Metrics - Added sensor with name topic.file_syn3.bytes
2017-02-15 21:10:05.754 [kafka-producer-network-thread | producer-1] DEBUG org.apache.kafka.common.metrics.Metrics - Added sensor with name topic.file_syn3.compression-rate
2017-02-15 21:10:05.754 [kafka-producer-network-thread | producer-1] DEBUG org.apache.kafka.common.metrics.Metrics - Added sensor with name topic.file_syn3.record-retries
2017-02-15 21:10:05.755 [kafka-producer-network-thread | producer-1] DEBUG org.apache.kafka.common.metrics.Metrics - Added sensor with name topic.file_syn3.record-errors
2017-02-15 21:11:22.324 [main] INFO  org.apache.kafka.clients.producer.ProducerConfig - ProducerConfig values: 
	acks = 1
	batch.size = 16384
	block.on.buffer.full = false
	bootstrap.servers = [10.1.131.18:9092]
	buffer.memory = 33554432
	client.id = 
	compression.type = none
	connections.max.idle.ms = 540000
	interceptor.classes = null
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 0
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1000000000
	metadata.fetch.timeout.ms = 60000
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	receive.buffer.bytes = 32768
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 0
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	timeout.ms = 30000
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer

2017-02-15 21:11:22.397 [main] INFO  org.apache.kafka.clients.producer.ProducerConfig - ProducerConfig values: 
	acks = 1
	batch.size = 16384
	block.on.buffer.full = false
	bootstrap.servers = [10.1.131.18:9092]
	buffer.memory = 33554432
	client.id = producer-1
	compression.type = none
	connections.max.idle.ms = 540000
	interceptor.classes = null
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 0
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1000000000
	metadata.fetch.timeout.ms = 60000
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	receive.buffer.bytes = 32768
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 0
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	timeout.ms = 30000
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer

2017-02-15 21:11:22.413 [main] DEBUG org.apache.kafka.common.metrics.Metrics - Added sensor with name bufferpool-wait-time
2017-02-15 21:11:22.419 [main] DEBUG org.apache.kafka.common.metrics.Metrics - Added sensor with name buffer-exhausted-records
2017-02-15 21:11:22.423 [main] DEBUG org.apache.kafka.clients.Metadata - Updated cluster metadata version 1 to Cluster(id = null, nodes = [10.1.131.18:9092 (id: -1 rack: null)], partitions = [])
2017-02-15 21:11:22.450 [main] DEBUG org.apache.kafka.common.metrics.Metrics - Added sensor with name connections-closed:
2017-02-15 21:11:22.451 [main] DEBUG org.apache.kafka.common.metrics.Metrics - Added sensor with name connections-created:
2017-02-15 21:11:22.451 [main] DEBUG org.apache.kafka.common.metrics.Metrics - Added sensor with name bytes-sent-received:
2017-02-15 21:11:22.451 [main] DEBUG org.apache.kafka.common.metrics.Metrics - Added sensor with name bytes-sent:
2017-02-15 21:11:22.454 [main] DEBUG org.apache.kafka.common.metrics.Metrics - Added sensor with name bytes-received:
2017-02-15 21:11:22.454 [main] DEBUG org.apache.kafka.common.metrics.Metrics - Added sensor with name select-time:
2017-02-15 21:11:22.454 [main] DEBUG org.apache.kafka.common.metrics.Metrics - Added sensor with name io-time:
2017-02-15 21:11:22.464 [main] DEBUG org.apache.kafka.common.metrics.Metrics - Added sensor with name batch-size
2017-02-15 21:11:22.464 [main] DEBUG org.apache.kafka.common.metrics.Metrics - Added sensor with name compression-rate
2017-02-15 21:11:22.465 [main] DEBUG org.apache.kafka.common.metrics.Metrics - Added sensor with name queue-time
2017-02-15 21:11:22.465 [main] DEBUG org.apache.kafka.common.metrics.Metrics - Added sensor with name request-time
2017-02-15 21:11:22.465 [main] DEBUG org.apache.kafka.common.metrics.Metrics - Added sensor with name produce-throttle-time
2017-02-15 21:11:22.465 [main] DEBUG org.apache.kafka.common.metrics.Metrics - Added sensor with name records-per-request
2017-02-15 21:11:22.466 [main] DEBUG org.apache.kafka.common.metrics.Metrics - Added sensor with name record-retries
2017-02-15 21:11:22.466 [main] DEBUG org.apache.kafka.common.metrics.Metrics - Added sensor with name errors
2017-02-15 21:11:22.466 [main] DEBUG org.apache.kafka.common.metrics.Metrics - Added sensor with name record-size-max
2017-02-15 21:11:22.469 [kafka-producer-network-thread | producer-1] DEBUG org.apache.kafka.clients.producer.internals.Sender - Starting Kafka producer I/O thread.
2017-02-15 21:11:22.476 [main] INFO  org.apache.kafka.common.utils.AppInfoParser - Kafka version : 0.10.1.0
2017-02-15 21:11:22.477 [main] INFO  org.apache.kafka.common.utils.AppInfoParser - Kafka commitId : 3402a74efb23d1d4
2017-02-15 21:11:22.478 [main] DEBUG org.apache.kafka.clients.producer.KafkaProducer - Kafka producer started
2017-02-15 21:11:25.416 [kafka-producer-network-thread | producer-1] DEBUG org.apache.kafka.clients.NetworkClient - Initialize connection to node -1 for sending metadata request
2017-02-15 21:11:25.416 [kafka-producer-network-thread | producer-1] DEBUG org.apache.kafka.clients.NetworkClient - Initiating connection to node -1 at 10.1.131.18:9092.
2017-02-15 21:11:25.459 [kafka-producer-network-thread | producer-1] DEBUG org.apache.kafka.common.metrics.Metrics - Added sensor with name node--1.bytes-sent
2017-02-15 21:11:25.459 [kafka-producer-network-thread | producer-1] DEBUG org.apache.kafka.common.metrics.Metrics - Added sensor with name node--1.bytes-received
2017-02-15 21:11:25.459 [kafka-producer-network-thread | producer-1] DEBUG org.apache.kafka.common.metrics.Metrics - Added sensor with name node--1.latency
2017-02-15 21:11:25.460 [kafka-producer-network-thread | producer-1] DEBUG org.apache.kafka.common.network.Selector - Created socket with SO_RCVBUF = 32768, SO_SNDBUF = 131072, SO_TIMEOUT = 0 to node -1
2017-02-15 21:11:25.460 [kafka-producer-network-thread | producer-1] DEBUG org.apache.kafka.clients.NetworkClient - Completed connection to node -1
2017-02-15 21:11:25.561 [kafka-producer-network-thread | producer-1] DEBUG org.apache.kafka.clients.NetworkClient - Sending metadata request {topics=[file_syn3]} to node -1
2017-02-15 21:11:25.638 [kafka-producer-network-thread | producer-1] DEBUG org.apache.kafka.clients.Metadata - Updated cluster metadata version 2 to Cluster(id = 5ynpwwfGT3KEdCwLvR2Jog, nodes = [10.1.131.18:9092 (id: 0 rack: null)], partitions = [Partition(topic = file_syn3, partition = 0, leader = 0, replicas = [0,], isr = [0,])])
2017-02-15 21:11:25.694 [kafka-producer-network-thread | producer-1] DEBUG org.apache.kafka.clients.NetworkClient - Initiating connection to node 0 at 10.1.131.18:9092.
2017-02-15 21:11:25.740 [kafka-producer-network-thread | producer-1] DEBUG org.apache.kafka.common.metrics.Metrics - Added sensor with name node-0.bytes-sent
2017-02-15 21:11:25.741 [kafka-producer-network-thread | producer-1] DEBUG org.apache.kafka.common.metrics.Metrics - Added sensor with name node-0.bytes-received
2017-02-15 21:11:25.742 [kafka-producer-network-thread | producer-1] DEBUG org.apache.kafka.common.metrics.Metrics - Added sensor with name node-0.latency
2017-02-15 21:11:25.742 [kafka-producer-network-thread | producer-1] DEBUG org.apache.kafka.common.network.Selector - Created socket with SO_RCVBUF = 32768, SO_SNDBUF = 131072, SO_TIMEOUT = 0 to node 0
2017-02-15 21:11:25.742 [kafka-producer-network-thread | producer-1] DEBUG org.apache.kafka.clients.NetworkClient - Completed connection to node 0
2017-02-15 21:11:25.742 [kafka-producer-network-thread | producer-1] DEBUG org.apache.kafka.common.metrics.Metrics - Added sensor with name topic.file_syn3.records-per-batch
2017-02-15 21:11:25.743 [kafka-producer-network-thread | producer-1] DEBUG org.apache.kafka.common.metrics.Metrics - Added sensor with name topic.file_syn3.bytes
2017-02-15 21:11:25.743 [kafka-producer-network-thread | producer-1] DEBUG org.apache.kafka.common.metrics.Metrics - Added sensor with name topic.file_syn3.compression-rate
2017-02-15 21:11:25.743 [kafka-producer-network-thread | producer-1] DEBUG org.apache.kafka.common.metrics.Metrics - Added sensor with name topic.file_syn3.record-retries
2017-02-15 21:11:25.744 [kafka-producer-network-thread | producer-1] DEBUG org.apache.kafka.common.metrics.Metrics - Added sensor with name topic.file_syn3.record-errors
2017-02-15 21:15:11.766 [main] INFO  org.apache.kafka.clients.producer.ProducerConfig - ProducerConfig values: 
	acks = 1
	batch.size = 16384
	block.on.buffer.full = false
	bootstrap.servers = [10.1.131.18:9092]
	buffer.memory = 33554432
	client.id = 
	compression.type = none
	connections.max.idle.ms = 540000
	interceptor.classes = null
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 0
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1000000000
	metadata.fetch.timeout.ms = 60000
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	receive.buffer.bytes = 32768
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 0
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	timeout.ms = 30000
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer

2017-02-15 21:15:11.831 [main] INFO  org.apache.kafka.clients.producer.ProducerConfig - ProducerConfig values: 
	acks = 1
	batch.size = 16384
	block.on.buffer.full = false
	bootstrap.servers = [10.1.131.18:9092]
	buffer.memory = 33554432
	client.id = producer-1
	compression.type = none
	connections.max.idle.ms = 540000
	interceptor.classes = null
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 0
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1000000000
	metadata.fetch.timeout.ms = 60000
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	receive.buffer.bytes = 32768
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 0
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	timeout.ms = 30000
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer

2017-02-15 21:15:11.845 [main] DEBUG org.apache.kafka.common.metrics.Metrics - Added sensor with name bufferpool-wait-time
2017-02-15 21:15:11.851 [main] DEBUG org.apache.kafka.common.metrics.Metrics - Added sensor with name buffer-exhausted-records
2017-02-15 21:15:11.854 [main] DEBUG org.apache.kafka.clients.Metadata - Updated cluster metadata version 1 to Cluster(id = null, nodes = [10.1.131.18:9092 (id: -1 rack: null)], partitions = [])
2017-02-15 21:15:11.878 [main] DEBUG org.apache.kafka.common.metrics.Metrics - Added sensor with name connections-closed:
2017-02-15 21:15:11.878 [main] DEBUG org.apache.kafka.common.metrics.Metrics - Added sensor with name connections-created:
2017-02-15 21:15:11.878 [main] DEBUG org.apache.kafka.common.metrics.Metrics - Added sensor with name bytes-sent-received:
2017-02-15 21:15:11.879 [main] DEBUG org.apache.kafka.common.metrics.Metrics - Added sensor with name bytes-sent:
2017-02-15 21:15:11.880 [main] DEBUG org.apache.kafka.common.metrics.Metrics - Added sensor with name bytes-received:
2017-02-15 21:15:11.881 [main] DEBUG org.apache.kafka.common.metrics.Metrics - Added sensor with name select-time:
2017-02-15 21:15:11.881 [main] DEBUG org.apache.kafka.common.metrics.Metrics - Added sensor with name io-time:
2017-02-15 21:15:11.888 [main] DEBUG org.apache.kafka.common.metrics.Metrics - Added sensor with name batch-size
2017-02-15 21:15:11.888 [main] DEBUG org.apache.kafka.common.metrics.Metrics - Added sensor with name compression-rate
2017-02-15 21:15:11.888 [main] DEBUG org.apache.kafka.common.metrics.Metrics - Added sensor with name queue-time
2017-02-15 21:15:11.888 [main] DEBUG org.apache.kafka.common.metrics.Metrics - Added sensor with name request-time
2017-02-15 21:15:11.889 [main] DEBUG org.apache.kafka.common.metrics.Metrics - Added sensor with name produce-throttle-time
2017-02-15 21:15:11.889 [main] DEBUG org.apache.kafka.common.metrics.Metrics - Added sensor with name records-per-request
2017-02-15 21:15:11.889 [main] DEBUG org.apache.kafka.common.metrics.Metrics - Added sensor with name record-retries
2017-02-15 21:15:11.889 [main] DEBUG org.apache.kafka.common.metrics.Metrics - Added sensor with name errors
2017-02-15 21:15:11.890 [main] DEBUG org.apache.kafka.common.metrics.Metrics - Added sensor with name record-size-max
2017-02-15 21:15:11.892 [kafka-producer-network-thread | producer-1] DEBUG org.apache.kafka.clients.producer.internals.Sender - Starting Kafka producer I/O thread.
2017-02-15 21:15:11.897 [main] INFO  org.apache.kafka.common.utils.AppInfoParser - Kafka version : 0.10.1.0
2017-02-15 21:15:11.898 [main] INFO  org.apache.kafka.common.utils.AppInfoParser - Kafka commitId : 3402a74efb23d1d4
2017-02-15 21:15:11.899 [main] DEBUG org.apache.kafka.clients.producer.KafkaProducer - Kafka producer started
2017-02-15 21:15:19.109 [kafka-producer-network-thread | producer-1] DEBUG org.apache.kafka.clients.NetworkClient - Initialize connection to node -1 for sending metadata request
2017-02-15 21:15:19.110 [kafka-producer-network-thread | producer-1] DEBUG org.apache.kafka.clients.NetworkClient - Initiating connection to node -1 at 10.1.131.18:9092.
2017-02-15 21:15:19.155 [kafka-producer-network-thread | producer-1] DEBUG org.apache.kafka.common.metrics.Metrics - Added sensor with name node--1.bytes-sent
2017-02-15 21:15:19.156 [kafka-producer-network-thread | producer-1] DEBUG org.apache.kafka.common.metrics.Metrics - Added sensor with name node--1.bytes-received
2017-02-15 21:15:19.156 [kafka-producer-network-thread | producer-1] DEBUG org.apache.kafka.common.metrics.Metrics - Added sensor with name node--1.latency
2017-02-15 21:15:19.156 [kafka-producer-network-thread | producer-1] DEBUG org.apache.kafka.common.network.Selector - Created socket with SO_RCVBUF = 32768, SO_SNDBUF = 131072, SO_TIMEOUT = 0 to node -1
2017-02-15 21:15:19.156 [kafka-producer-network-thread | producer-1] DEBUG org.apache.kafka.clients.NetworkClient - Completed connection to node -1
2017-02-15 21:15:19.254 [kafka-producer-network-thread | producer-1] DEBUG org.apache.kafka.clients.NetworkClient - Sending metadata request {topics=[file_syn3]} to node -1
2017-02-15 21:15:19.331 [kafka-producer-network-thread | producer-1] DEBUG org.apache.kafka.clients.Metadata - Updated cluster metadata version 2 to Cluster(id = 5ynpwwfGT3KEdCwLvR2Jog, nodes = [10.1.131.18:9092 (id: 0 rack: null)], partitions = [Partition(topic = file_syn3, partition = 0, leader = 0, replicas = [0,], isr = [0,])])
2017-02-15 21:15:19.384 [kafka-producer-network-thread | producer-1] DEBUG org.apache.kafka.clients.NetworkClient - Initiating connection to node 0 at 10.1.131.18:9092.
2017-02-15 21:15:19.424 [kafka-producer-network-thread | producer-1] DEBUG org.apache.kafka.common.metrics.Metrics - Added sensor with name node-0.bytes-sent
2017-02-15 21:15:19.424 [kafka-producer-network-thread | producer-1] DEBUG org.apache.kafka.common.metrics.Metrics - Added sensor with name node-0.bytes-received
2017-02-15 21:15:19.424 [kafka-producer-network-thread | producer-1] DEBUG org.apache.kafka.common.metrics.Metrics - Added sensor with name node-0.latency
2017-02-15 21:15:19.425 [kafka-producer-network-thread | producer-1] DEBUG org.apache.kafka.common.network.Selector - Created socket with SO_RCVBUF = 32768, SO_SNDBUF = 131072, SO_TIMEOUT = 0 to node 0
2017-02-15 21:15:19.425 [kafka-producer-network-thread | producer-1] DEBUG org.apache.kafka.clients.NetworkClient - Completed connection to node 0
2017-02-15 21:15:19.425 [kafka-producer-network-thread | producer-1] DEBUG org.apache.kafka.common.metrics.Metrics - Added sensor with name topic.file_syn3.records-per-batch
2017-02-15 21:15:19.426 [kafka-producer-network-thread | producer-1] DEBUG org.apache.kafka.common.metrics.Metrics - Added sensor with name topic.file_syn3.bytes
2017-02-15 21:15:19.426 [kafka-producer-network-thread | producer-1] DEBUG org.apache.kafka.common.metrics.Metrics - Added sensor with name topic.file_syn3.compression-rate
2017-02-15 21:15:19.426 [kafka-producer-network-thread | producer-1] DEBUG org.apache.kafka.common.metrics.Metrics - Added sensor with name topic.file_syn3.record-retries
2017-02-15 21:15:19.426 [kafka-producer-network-thread | producer-1] DEBUG org.apache.kafka.common.metrics.Metrics - Added sensor with name topic.file_syn3.record-errors
2017-02-15 21:16:32.825 [main] INFO  org.apache.kafka.clients.producer.ProducerConfig - ProducerConfig values: 
	acks = 1
	batch.size = 16384
	block.on.buffer.full = false
	bootstrap.servers = [10.1.131.18:9092]
	buffer.memory = 33554432
	client.id = 
	compression.type = none
	connections.max.idle.ms = 540000
	interceptor.classes = null
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 0
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1000000000
	metadata.fetch.timeout.ms = 60000
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	receive.buffer.bytes = 32768
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 0
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	timeout.ms = 30000
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer

2017-02-15 21:16:32.887 [main] INFO  org.apache.kafka.clients.producer.ProducerConfig - ProducerConfig values: 
	acks = 1
	batch.size = 16384
	block.on.buffer.full = false
	bootstrap.servers = [10.1.131.18:9092]
	buffer.memory = 33554432
	client.id = producer-1
	compression.type = none
	connections.max.idle.ms = 540000
	interceptor.classes = null
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 0
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1000000000
	metadata.fetch.timeout.ms = 60000
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	receive.buffer.bytes = 32768
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 0
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	timeout.ms = 30000
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer

2017-02-15 21:16:32.904 [main] DEBUG org.apache.kafka.common.metrics.Metrics - Added sensor with name bufferpool-wait-time
2017-02-15 21:16:32.911 [main] DEBUG org.apache.kafka.common.metrics.Metrics - Added sensor with name buffer-exhausted-records
2017-02-15 21:16:32.917 [main] DEBUG org.apache.kafka.clients.Metadata - Updated cluster metadata version 1 to Cluster(id = null, nodes = [10.1.131.18:9092 (id: -1 rack: null)], partitions = [])
2017-02-15 21:16:32.942 [main] DEBUG org.apache.kafka.common.metrics.Metrics - Added sensor with name connections-closed:
2017-02-15 21:16:32.943 [main] DEBUG org.apache.kafka.common.metrics.Metrics - Added sensor with name connections-created:
2017-02-15 21:16:32.943 [main] DEBUG org.apache.kafka.common.metrics.Metrics - Added sensor with name bytes-sent-received:
2017-02-15 21:16:32.943 [main] DEBUG org.apache.kafka.common.metrics.Metrics - Added sensor with name bytes-sent:
2017-02-15 21:16:32.945 [main] DEBUG org.apache.kafka.common.metrics.Metrics - Added sensor with name bytes-received:
2017-02-15 21:16:32.945 [main] DEBUG org.apache.kafka.common.metrics.Metrics - Added sensor with name select-time:
2017-02-15 21:16:32.946 [main] DEBUG org.apache.kafka.common.metrics.Metrics - Added sensor with name io-time:
2017-02-15 21:16:32.954 [main] DEBUG org.apache.kafka.common.metrics.Metrics - Added sensor with name batch-size
2017-02-15 21:16:32.955 [main] DEBUG org.apache.kafka.common.metrics.Metrics - Added sensor with name compression-rate
2017-02-15 21:16:32.955 [main] DEBUG org.apache.kafka.common.metrics.Metrics - Added sensor with name queue-time
2017-02-15 21:16:32.955 [main] DEBUG org.apache.kafka.common.metrics.Metrics - Added sensor with name request-time
2017-02-15 21:16:32.955 [main] DEBUG org.apache.kafka.common.metrics.Metrics - Added sensor with name produce-throttle-time
2017-02-15 21:16:32.956 [main] DEBUG org.apache.kafka.common.metrics.Metrics - Added sensor with name records-per-request
2017-02-15 21:16:32.956 [main] DEBUG org.apache.kafka.common.metrics.Metrics - Added sensor with name record-retries
2017-02-15 21:16:32.956 [main] DEBUG org.apache.kafka.common.metrics.Metrics - Added sensor with name errors
2017-02-15 21:16:32.956 [main] DEBUG org.apache.kafka.common.metrics.Metrics - Added sensor with name record-size-max
2017-02-15 21:16:32.959 [kafka-producer-network-thread | producer-1] DEBUG org.apache.kafka.clients.producer.internals.Sender - Starting Kafka producer I/O thread.
2017-02-15 21:16:32.966 [main] INFO  org.apache.kafka.common.utils.AppInfoParser - Kafka version : 0.10.1.0
2017-02-15 21:16:32.966 [main] INFO  org.apache.kafka.common.utils.AppInfoParser - Kafka commitId : 3402a74efb23d1d4
2017-02-15 21:16:32.967 [main] DEBUG org.apache.kafka.clients.producer.KafkaProducer - Kafka producer started
2017-02-15 21:16:36.302 [kafka-producer-network-thread | producer-1] DEBUG org.apache.kafka.clients.NetworkClient - Initialize connection to node -1 for sending metadata request
2017-02-15 21:16:36.303 [kafka-producer-network-thread | producer-1] DEBUG org.apache.kafka.clients.NetworkClient - Initiating connection to node -1 at 10.1.131.18:9092.
2017-02-15 21:16:36.343 [kafka-producer-network-thread | producer-1] DEBUG org.apache.kafka.common.metrics.Metrics - Added sensor with name node--1.bytes-sent
2017-02-15 21:16:36.345 [kafka-producer-network-thread | producer-1] DEBUG org.apache.kafka.common.metrics.Metrics - Added sensor with name node--1.bytes-received
2017-02-15 21:16:36.346 [kafka-producer-network-thread | producer-1] DEBUG org.apache.kafka.common.metrics.Metrics - Added sensor with name node--1.latency
2017-02-15 21:16:36.346 [kafka-producer-network-thread | producer-1] DEBUG org.apache.kafka.common.network.Selector - Created socket with SO_RCVBUF = 32768, SO_SNDBUF = 131072, SO_TIMEOUT = 0 to node -1
2017-02-15 21:16:36.347 [kafka-producer-network-thread | producer-1] DEBUG org.apache.kafka.clients.NetworkClient - Completed connection to node -1
2017-02-15 21:16:36.442 [kafka-producer-network-thread | producer-1] DEBUG org.apache.kafka.clients.NetworkClient - Sending metadata request {topics=[file_syn3]} to node -1
2017-02-15 21:16:36.513 [kafka-producer-network-thread | producer-1] DEBUG org.apache.kafka.clients.Metadata - Updated cluster metadata version 2 to Cluster(id = 5ynpwwfGT3KEdCwLvR2Jog, nodes = [10.1.131.18:9092 (id: 0 rack: null)], partitions = [Partition(topic = file_syn3, partition = 0, leader = 0, replicas = [0,], isr = [0,])])
2017-02-15 21:16:36.567 [kafka-producer-network-thread | producer-1] DEBUG org.apache.kafka.clients.NetworkClient - Initiating connection to node 0 at 10.1.131.18:9092.
2017-02-15 21:16:36.607 [kafka-producer-network-thread | producer-1] DEBUG org.apache.kafka.common.metrics.Metrics - Added sensor with name node-0.bytes-sent
2017-02-15 21:16:36.607 [kafka-producer-network-thread | producer-1] DEBUG org.apache.kafka.common.metrics.Metrics - Added sensor with name node-0.bytes-received
2017-02-15 21:16:36.608 [kafka-producer-network-thread | producer-1] DEBUG org.apache.kafka.common.metrics.Metrics - Added sensor with name node-0.latency
2017-02-15 21:16:36.608 [kafka-producer-network-thread | producer-1] DEBUG org.apache.kafka.common.network.Selector - Created socket with SO_RCVBUF = 32768, SO_SNDBUF = 131072, SO_TIMEOUT = 0 to node 0
2017-02-15 21:16:36.608 [kafka-producer-network-thread | producer-1] DEBUG org.apache.kafka.clients.NetworkClient - Completed connection to node 0
2017-02-15 21:16:36.608 [kafka-producer-network-thread | producer-1] DEBUG org.apache.kafka.common.metrics.Metrics - Added sensor with name topic.file_syn3.records-per-batch
2017-02-15 21:16:36.608 [kafka-producer-network-thread | producer-1] DEBUG org.apache.kafka.common.metrics.Metrics - Added sensor with name topic.file_syn3.bytes
2017-02-15 21:16:36.609 [kafka-producer-network-thread | producer-1] DEBUG org.apache.kafka.common.metrics.Metrics - Added sensor with name topic.file_syn3.compression-rate
2017-02-15 21:16:36.609 [kafka-producer-network-thread | producer-1] DEBUG org.apache.kafka.common.metrics.Metrics - Added sensor with name topic.file_syn3.record-retries
2017-02-15 21:16:36.609 [kafka-producer-network-thread | producer-1] DEBUG org.apache.kafka.common.metrics.Metrics - Added sensor with name topic.file_syn3.record-errors
2017-02-15 21:17:58.703 [main] INFO  org.apache.kafka.clients.producer.ProducerConfig - ProducerConfig values: 
	acks = 1
	batch.size = 16384
	block.on.buffer.full = false
	bootstrap.servers = [10.1.131.18:9092]
	buffer.memory = 33554432
	client.id = 
	compression.type = none
	connections.max.idle.ms = 540000
	interceptor.classes = null
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 0
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1000000000
	metadata.fetch.timeout.ms = 60000
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	receive.buffer.bytes = 32768
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 0
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	timeout.ms = 30000
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer

2017-02-15 21:17:58.764 [main] INFO  org.apache.kafka.clients.producer.ProducerConfig - ProducerConfig values: 
	acks = 1
	batch.size = 16384
	block.on.buffer.full = false
	bootstrap.servers = [10.1.131.18:9092]
	buffer.memory = 33554432
	client.id = producer-1
	compression.type = none
	connections.max.idle.ms = 540000
	interceptor.classes = null
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 0
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1000000000
	metadata.fetch.timeout.ms = 60000
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	receive.buffer.bytes = 32768
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 0
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	timeout.ms = 30000
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer

2017-02-15 21:17:58.781 [main] DEBUG org.apache.kafka.common.metrics.Metrics - Added sensor with name bufferpool-wait-time
2017-02-15 21:17:58.789 [main] DEBUG org.apache.kafka.common.metrics.Metrics - Added sensor with name buffer-exhausted-records
2017-02-15 21:17:58.792 [main] DEBUG org.apache.kafka.clients.Metadata - Updated cluster metadata version 1 to Cluster(id = null, nodes = [10.1.131.18:9092 (id: -1 rack: null)], partitions = [])
2017-02-15 21:17:58.820 [main] DEBUG org.apache.kafka.common.metrics.Metrics - Added sensor with name connections-closed:
2017-02-15 21:17:58.821 [main] DEBUG org.apache.kafka.common.metrics.Metrics - Added sensor with name connections-created:
2017-02-15 21:17:58.821 [main] DEBUG org.apache.kafka.common.metrics.Metrics - Added sensor with name bytes-sent-received:
2017-02-15 21:17:58.821 [main] DEBUG org.apache.kafka.common.metrics.Metrics - Added sensor with name bytes-sent:
2017-02-15 21:17:58.823 [main] DEBUG org.apache.kafka.common.metrics.Metrics - Added sensor with name bytes-received:
2017-02-15 21:17:58.823 [main] DEBUG org.apache.kafka.common.metrics.Metrics - Added sensor with name select-time:
2017-02-15 21:17:58.823 [main] DEBUG org.apache.kafka.common.metrics.Metrics - Added sensor with name io-time:
2017-02-15 21:17:58.832 [main] DEBUG org.apache.kafka.common.metrics.Metrics - Added sensor with name batch-size
2017-02-15 21:17:58.832 [main] DEBUG org.apache.kafka.common.metrics.Metrics - Added sensor with name compression-rate
2017-02-15 21:17:58.832 [main] DEBUG org.apache.kafka.common.metrics.Metrics - Added sensor with name queue-time
2017-02-15 21:17:58.833 [main] DEBUG org.apache.kafka.common.metrics.Metrics - Added sensor with name request-time
2017-02-15 21:17:58.833 [main] DEBUG org.apache.kafka.common.metrics.Metrics - Added sensor with name produce-throttle-time
2017-02-15 21:17:58.833 [main] DEBUG org.apache.kafka.common.metrics.Metrics - Added sensor with name records-per-request
2017-02-15 21:17:58.834 [main] DEBUG org.apache.kafka.common.metrics.Metrics - Added sensor with name record-retries
2017-02-15 21:17:58.834 [main] DEBUG org.apache.kafka.common.metrics.Metrics - Added sensor with name errors
2017-02-15 21:17:58.834 [main] DEBUG org.apache.kafka.common.metrics.Metrics - Added sensor with name record-size-max
2017-02-15 21:17:58.837 [kafka-producer-network-thread | producer-1] DEBUG org.apache.kafka.clients.producer.internals.Sender - Starting Kafka producer I/O thread.
2017-02-15 21:17:58.842 [main] INFO  org.apache.kafka.common.utils.AppInfoParser - Kafka version : 0.10.1.0
2017-02-15 21:17:58.843 [main] INFO  org.apache.kafka.common.utils.AppInfoParser - Kafka commitId : 3402a74efb23d1d4
2017-02-15 21:17:58.844 [main] DEBUG org.apache.kafka.clients.producer.KafkaProducer - Kafka producer started
2017-02-15 21:18:00.951 [kafka-producer-network-thread | producer-1] DEBUG org.apache.kafka.clients.NetworkClient - Initialize connection to node -1 for sending metadata request
2017-02-15 21:18:00.951 [kafka-producer-network-thread | producer-1] DEBUG org.apache.kafka.clients.NetworkClient - Initiating connection to node -1 at 10.1.131.18:9092.
2017-02-15 21:18:00.992 [kafka-producer-network-thread | producer-1] DEBUG org.apache.kafka.common.metrics.Metrics - Added sensor with name node--1.bytes-sent
2017-02-15 21:18:00.992 [kafka-producer-network-thread | producer-1] DEBUG org.apache.kafka.common.metrics.Metrics - Added sensor with name node--1.bytes-received
2017-02-15 21:18:00.993 [kafka-producer-network-thread | producer-1] DEBUG org.apache.kafka.common.metrics.Metrics - Added sensor with name node--1.latency
2017-02-15 21:18:00.993 [kafka-producer-network-thread | producer-1] DEBUG org.apache.kafka.common.network.Selector - Created socket with SO_RCVBUF = 32768, SO_SNDBUF = 131072, SO_TIMEOUT = 0 to node -1
2017-02-15 21:18:00.993 [kafka-producer-network-thread | producer-1] DEBUG org.apache.kafka.clients.NetworkClient - Completed connection to node -1
2017-02-15 21:18:01.093 [kafka-producer-network-thread | producer-1] DEBUG org.apache.kafka.clients.NetworkClient - Sending metadata request {topics=[file_syn3]} to node -1
2017-02-15 21:18:01.167 [kafka-producer-network-thread | producer-1] DEBUG org.apache.kafka.clients.Metadata - Updated cluster metadata version 2 to Cluster(id = 5ynpwwfGT3KEdCwLvR2Jog, nodes = [10.1.131.18:9092 (id: 0 rack: null)], partitions = [Partition(topic = file_syn3, partition = 0, leader = 0, replicas = [0,], isr = [0,])])
2017-02-15 21:18:01.220 [kafka-producer-network-thread | producer-1] DEBUG org.apache.kafka.clients.NetworkClient - Initiating connection to node 0 at 10.1.131.18:9092.
2017-02-15 21:18:01.260 [kafka-producer-network-thread | producer-1] DEBUG org.apache.kafka.common.metrics.Metrics - Added sensor with name node-0.bytes-sent
2017-02-15 21:18:01.261 [kafka-producer-network-thread | producer-1] DEBUG org.apache.kafka.common.metrics.Metrics - Added sensor with name node-0.bytes-received
2017-02-15 21:18:01.261 [kafka-producer-network-thread | producer-1] DEBUG org.apache.kafka.common.metrics.Metrics - Added sensor with name node-0.latency
2017-02-15 21:18:01.262 [kafka-producer-network-thread | producer-1] DEBUG org.apache.kafka.common.network.Selector - Created socket with SO_RCVBUF = 32768, SO_SNDBUF = 131072, SO_TIMEOUT = 0 to node 0
2017-02-15 21:18:01.262 [kafka-producer-network-thread | producer-1] DEBUG org.apache.kafka.clients.NetworkClient - Completed connection to node 0
2017-02-15 21:18:01.263 [kafka-producer-network-thread | producer-1] DEBUG org.apache.kafka.common.metrics.Metrics - Added sensor with name topic.file_syn3.records-per-batch
2017-02-15 21:18:01.264 [kafka-producer-network-thread | producer-1] DEBUG org.apache.kafka.common.metrics.Metrics - Added sensor with name topic.file_syn3.bytes
2017-02-15 21:18:01.264 [kafka-producer-network-thread | producer-1] DEBUG org.apache.kafka.common.metrics.Metrics - Added sensor with name topic.file_syn3.compression-rate
2017-02-15 21:18:01.264 [kafka-producer-network-thread | producer-1] DEBUG org.apache.kafka.common.metrics.Metrics - Added sensor with name topic.file_syn3.record-retries
2017-02-15 21:18:01.265 [kafka-producer-network-thread | producer-1] DEBUG org.apache.kafka.common.metrics.Metrics - Added sensor with name topic.file_syn3.record-errors
2017-02-15 21:19:04.386 [main] INFO  org.apache.kafka.clients.producer.ProducerConfig - ProducerConfig values: 
	acks = 1
	batch.size = 16384
	block.on.buffer.full = false
	bootstrap.servers = [10.1.131.18:9092]
	buffer.memory = 33554432
	client.id = 
	compression.type = none
	connections.max.idle.ms = 540000
	interceptor.classes = null
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 0
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1000000000
	metadata.fetch.timeout.ms = 60000
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	receive.buffer.bytes = 32768
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 0
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	timeout.ms = 30000
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer

2017-02-15 21:19:04.458 [main] INFO  org.apache.kafka.clients.producer.ProducerConfig - ProducerConfig values: 
	acks = 1
	batch.size = 16384
	block.on.buffer.full = false
	bootstrap.servers = [10.1.131.18:9092]
	buffer.memory = 33554432
	client.id = producer-1
	compression.type = none
	connections.max.idle.ms = 540000
	interceptor.classes = null
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 0
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1000000000
	metadata.fetch.timeout.ms = 60000
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	receive.buffer.bytes = 32768
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 0
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	timeout.ms = 30000
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer

2017-02-15 21:19:04.481 [main] DEBUG org.apache.kafka.common.metrics.Metrics - Added sensor with name bufferpool-wait-time
2017-02-15 21:19:04.492 [main] DEBUG org.apache.kafka.common.metrics.Metrics - Added sensor with name buffer-exhausted-records
2017-02-15 21:19:04.497 [main] DEBUG org.apache.kafka.clients.Metadata - Updated cluster metadata version 1 to Cluster(id = null, nodes = [10.1.131.18:9092 (id: -1 rack: null)], partitions = [])
2017-02-15 21:19:04.533 [main] DEBUG org.apache.kafka.common.metrics.Metrics - Added sensor with name connections-closed:
2017-02-15 21:19:04.534 [main] DEBUG org.apache.kafka.common.metrics.Metrics - Added sensor with name connections-created:
2017-02-15 21:19:04.534 [main] DEBUG org.apache.kafka.common.metrics.Metrics - Added sensor with name bytes-sent-received:
2017-02-15 21:19:04.535 [main] DEBUG org.apache.kafka.common.metrics.Metrics - Added sensor with name bytes-sent:
2017-02-15 21:19:04.537 [main] DEBUG org.apache.kafka.common.metrics.Metrics - Added sensor with name bytes-received:
2017-02-15 21:19:04.538 [main] DEBUG org.apache.kafka.common.metrics.Metrics - Added sensor with name select-time:
2017-02-15 21:19:04.539 [main] DEBUG org.apache.kafka.common.metrics.Metrics - Added sensor with name io-time:
2017-02-15 21:19:04.551 [main] DEBUG org.apache.kafka.common.metrics.Metrics - Added sensor with name batch-size
2017-02-15 21:19:04.552 [main] DEBUG org.apache.kafka.common.metrics.Metrics - Added sensor with name compression-rate
2017-02-15 21:19:04.552 [main] DEBUG org.apache.kafka.common.metrics.Metrics - Added sensor with name queue-time
2017-02-15 21:19:04.552 [main] DEBUG org.apache.kafka.common.metrics.Metrics - Added sensor with name request-time
2017-02-15 21:19:04.553 [main] DEBUG org.apache.kafka.common.metrics.Metrics - Added sensor with name produce-throttle-time
2017-02-15 21:19:04.553 [main] DEBUG org.apache.kafka.common.metrics.Metrics - Added sensor with name records-per-request
2017-02-15 21:19:04.553 [main] DEBUG org.apache.kafka.common.metrics.Metrics - Added sensor with name record-retries
2017-02-15 21:19:04.553 [main] DEBUG org.apache.kafka.common.metrics.Metrics - Added sensor with name errors
2017-02-15 21:19:04.554 [main] DEBUG org.apache.kafka.common.metrics.Metrics - Added sensor with name record-size-max
2017-02-15 21:19:04.558 [kafka-producer-network-thread | producer-1] DEBUG org.apache.kafka.clients.producer.internals.Sender - Starting Kafka producer I/O thread.
2017-02-15 21:19:04.565 [main] INFO  org.apache.kafka.common.utils.AppInfoParser - Kafka version : 0.10.1.0
2017-02-15 21:19:04.565 [main] INFO  org.apache.kafka.common.utils.AppInfoParser - Kafka commitId : 3402a74efb23d1d4
2017-02-15 21:19:04.567 [main] DEBUG org.apache.kafka.clients.producer.KafkaProducer - Kafka producer started
2017-02-15 21:19:15.342 [main] INFO  org.apache.kafka.clients.producer.ProducerConfig - ProducerConfig values: 
	acks = 1
	batch.size = 16384
	block.on.buffer.full = false
	bootstrap.servers = [10.1.131.18:9092]
	buffer.memory = 33554432
	client.id = 
	compression.type = none
	connections.max.idle.ms = 540000
	interceptor.classes = null
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 0
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1000000000
	metadata.fetch.timeout.ms = 60000
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	receive.buffer.bytes = 32768
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 0
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	timeout.ms = 30000
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer

2017-02-15 21:19:15.405 [main] INFO  org.apache.kafka.clients.producer.ProducerConfig - ProducerConfig values: 
	acks = 1
	batch.size = 16384
	block.on.buffer.full = false
	bootstrap.servers = [10.1.131.18:9092]
	buffer.memory = 33554432
	client.id = producer-1
	compression.type = none
	connections.max.idle.ms = 540000
	interceptor.classes = null
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 0
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1000000000
	metadata.fetch.timeout.ms = 60000
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	receive.buffer.bytes = 32768
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 0
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	timeout.ms = 30000
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer

2017-02-15 21:19:15.422 [main] DEBUG org.apache.kafka.common.metrics.Metrics - Added sensor with name bufferpool-wait-time
2017-02-15 21:19:15.429 [main] DEBUG org.apache.kafka.common.metrics.Metrics - Added sensor with name buffer-exhausted-records
2017-02-15 21:19:15.434 [main] DEBUG org.apache.kafka.clients.Metadata - Updated cluster metadata version 1 to Cluster(id = null, nodes = [10.1.131.18:9092 (id: -1 rack: null)], partitions = [])
2017-02-15 21:19:15.459 [main] DEBUG org.apache.kafka.common.metrics.Metrics - Added sensor with name connections-closed:
2017-02-15 21:19:15.460 [main] DEBUG org.apache.kafka.common.metrics.Metrics - Added sensor with name connections-created:
2017-02-15 21:19:15.460 [main] DEBUG org.apache.kafka.common.metrics.Metrics - Added sensor with name bytes-sent-received:
2017-02-15 21:19:15.460 [main] DEBUG org.apache.kafka.common.metrics.Metrics - Added sensor with name bytes-sent:
2017-02-15 21:19:15.462 [main] DEBUG org.apache.kafka.common.metrics.Metrics - Added sensor with name bytes-received:
2017-02-15 21:19:15.462 [main] DEBUG org.apache.kafka.common.metrics.Metrics - Added sensor with name select-time:
2017-02-15 21:19:15.463 [main] DEBUG org.apache.kafka.common.metrics.Metrics - Added sensor with name io-time:
2017-02-15 21:19:15.470 [main] DEBUG org.apache.kafka.common.metrics.Metrics - Added sensor with name batch-size
2017-02-15 21:19:15.471 [main] DEBUG org.apache.kafka.common.metrics.Metrics - Added sensor with name compression-rate
2017-02-15 21:19:15.471 [main] DEBUG org.apache.kafka.common.metrics.Metrics - Added sensor with name queue-time
2017-02-15 21:19:15.472 [main] DEBUG org.apache.kafka.common.metrics.Metrics - Added sensor with name request-time
2017-02-15 21:19:15.472 [main] DEBUG org.apache.kafka.common.metrics.Metrics - Added sensor with name produce-throttle-time
2017-02-15 21:19:15.472 [main] DEBUG org.apache.kafka.common.metrics.Metrics - Added sensor with name records-per-request
2017-02-15 21:19:15.473 [main] DEBUG org.apache.kafka.common.metrics.Metrics - Added sensor with name record-retries
2017-02-15 21:19:15.473 [main] DEBUG org.apache.kafka.common.metrics.Metrics - Added sensor with name errors
2017-02-15 21:19:15.473 [main] DEBUG org.apache.kafka.common.metrics.Metrics - Added sensor with name record-size-max
2017-02-15 21:19:15.476 [kafka-producer-network-thread | producer-1] DEBUG org.apache.kafka.clients.producer.internals.Sender - Starting Kafka producer I/O thread.
2017-02-15 21:19:15.482 [main] INFO  org.apache.kafka.common.utils.AppInfoParser - Kafka version : 0.10.1.0
2017-02-15 21:19:15.482 [main] INFO  org.apache.kafka.common.utils.AppInfoParser - Kafka commitId : 3402a74efb23d1d4
2017-02-15 21:19:15.483 [main] DEBUG org.apache.kafka.clients.producer.KafkaProducer - Kafka producer started
2017-02-15 21:19:18.126 [kafka-producer-network-thread | producer-1] DEBUG org.apache.kafka.clients.NetworkClient - Initialize connection to node -1 for sending metadata request
2017-02-15 21:19:18.126 [kafka-producer-network-thread | producer-1] DEBUG org.apache.kafka.clients.NetworkClient - Initiating connection to node -1 at 10.1.131.18:9092.
2017-02-15 21:19:18.171 [kafka-producer-network-thread | producer-1] DEBUG org.apache.kafka.common.metrics.Metrics - Added sensor with name node--1.bytes-sent
2017-02-15 21:19:18.172 [kafka-producer-network-thread | producer-1] DEBUG org.apache.kafka.common.metrics.Metrics - Added sensor with name node--1.bytes-received
2017-02-15 21:19:18.172 [kafka-producer-network-thread | producer-1] DEBUG org.apache.kafka.common.metrics.Metrics - Added sensor with name node--1.latency
2017-02-15 21:19:18.173 [kafka-producer-network-thread | producer-1] DEBUG org.apache.kafka.common.network.Selector - Created socket with SO_RCVBUF = 32768, SO_SNDBUF = 131072, SO_TIMEOUT = 0 to node -1
2017-02-15 21:19:18.173 [kafka-producer-network-thread | producer-1] DEBUG org.apache.kafka.clients.NetworkClient - Completed connection to node -1
2017-02-15 21:19:18.269 [kafka-producer-network-thread | producer-1] DEBUG org.apache.kafka.clients.NetworkClient - Sending metadata request {topics=[file_syn5]} to node -1
2017-02-15 21:19:18.345 [kafka-producer-network-thread | producer-1] DEBUG org.apache.kafka.clients.Metadata - Updated cluster metadata version 2 to Cluster(id = 5ynpwwfGT3KEdCwLvR2Jog, nodes = [10.1.131.18:9092 (id: 0 rack: null)], partitions = [Partition(topic = file_syn5, partition = 0, leader = 0, replicas = [0,], isr = [0,])])
2017-02-15 21:19:18.405 [kafka-producer-network-thread | producer-1] DEBUG org.apache.kafka.clients.NetworkClient - Initiating connection to node 0 at 10.1.131.18:9092.
2017-02-15 21:19:18.447 [kafka-producer-network-thread | producer-1] DEBUG org.apache.kafka.common.metrics.Metrics - Added sensor with name node-0.bytes-sent
2017-02-15 21:19:18.448 [kafka-producer-network-thread | producer-1] DEBUG org.apache.kafka.common.metrics.Metrics - Added sensor with name node-0.bytes-received
2017-02-15 21:19:18.448 [kafka-producer-network-thread | producer-1] DEBUG org.apache.kafka.common.metrics.Metrics - Added sensor with name node-0.latency
2017-02-15 21:19:18.448 [kafka-producer-network-thread | producer-1] DEBUG org.apache.kafka.common.network.Selector - Created socket with SO_RCVBUF = 32768, SO_SNDBUF = 131072, SO_TIMEOUT = 0 to node 0
2017-02-15 21:19:18.448 [kafka-producer-network-thread | producer-1] DEBUG org.apache.kafka.clients.NetworkClient - Completed connection to node 0
2017-02-15 21:19:18.449 [kafka-producer-network-thread | producer-1] DEBUG org.apache.kafka.common.metrics.Metrics - Added sensor with name topic.file_syn5.records-per-batch
2017-02-15 21:19:18.449 [kafka-producer-network-thread | producer-1] DEBUG org.apache.kafka.common.metrics.Metrics - Added sensor with name topic.file_syn5.bytes
2017-02-15 21:19:18.449 [kafka-producer-network-thread | producer-1] DEBUG org.apache.kafka.common.metrics.Metrics - Added sensor with name topic.file_syn5.compression-rate
2017-02-15 21:19:18.450 [kafka-producer-network-thread | producer-1] DEBUG org.apache.kafka.common.metrics.Metrics - Added sensor with name topic.file_syn5.record-retries
2017-02-15 21:19:18.450 [kafka-producer-network-thread | producer-1] DEBUG org.apache.kafka.common.metrics.Metrics - Added sensor with name topic.file_syn5.record-errors
2017-02-15 21:21:38.422 [main] INFO  org.apache.kafka.clients.producer.ProducerConfig - ProducerConfig values: 
	acks = 1
	batch.size = 16384
	block.on.buffer.full = false
	bootstrap.servers = [10.1.131.18:9092]
	buffer.memory = 33554432
	client.id = 
	compression.type = none
	connections.max.idle.ms = 540000
	interceptor.classes = null
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 0
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1000000000
	metadata.fetch.timeout.ms = 60000
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	receive.buffer.bytes = 32768
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 0
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	timeout.ms = 30000
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer

2017-02-15 21:21:38.486 [main] INFO  org.apache.kafka.clients.producer.ProducerConfig - ProducerConfig values: 
	acks = 1
	batch.size = 16384
	block.on.buffer.full = false
	bootstrap.servers = [10.1.131.18:9092]
	buffer.memory = 33554432
	client.id = producer-1
	compression.type = none
	connections.max.idle.ms = 540000
	interceptor.classes = null
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 0
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1000000000
	metadata.fetch.timeout.ms = 60000
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	receive.buffer.bytes = 32768
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 0
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	timeout.ms = 30000
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer

2017-02-15 21:21:38.501 [main] DEBUG org.apache.kafka.common.metrics.Metrics - Added sensor with name bufferpool-wait-time
2017-02-15 21:21:38.507 [main] DEBUG org.apache.kafka.common.metrics.Metrics - Added sensor with name buffer-exhausted-records
2017-02-15 21:21:38.510 [main] DEBUG org.apache.kafka.clients.Metadata - Updated cluster metadata version 1 to Cluster(id = null, nodes = [10.1.131.18:9092 (id: -1 rack: null)], partitions = [])
2017-02-15 21:21:38.535 [main] DEBUG org.apache.kafka.common.metrics.Metrics - Added sensor with name connections-closed:
2017-02-15 21:21:38.536 [main] DEBUG org.apache.kafka.common.metrics.Metrics - Added sensor with name connections-created:
2017-02-15 21:21:38.536 [main] DEBUG org.apache.kafka.common.metrics.Metrics - Added sensor with name bytes-sent-received:
2017-02-15 21:21:38.536 [main] DEBUG org.apache.kafka.common.metrics.Metrics - Added sensor with name bytes-sent:
2017-02-15 21:21:38.538 [main] DEBUG org.apache.kafka.common.metrics.Metrics - Added sensor with name bytes-received:
2017-02-15 21:21:38.539 [main] DEBUG org.apache.kafka.common.metrics.Metrics - Added sensor with name select-time:
2017-02-15 21:21:38.539 [main] DEBUG org.apache.kafka.common.metrics.Metrics - Added sensor with name io-time:
2017-02-15 21:21:38.546 [main] DEBUG org.apache.kafka.common.metrics.Metrics - Added sensor with name batch-size
2017-02-15 21:21:38.546 [main] DEBUG org.apache.kafka.common.metrics.Metrics - Added sensor with name compression-rate
2017-02-15 21:21:38.547 [main] DEBUG org.apache.kafka.common.metrics.Metrics - Added sensor with name queue-time
2017-02-15 21:21:38.547 [main] DEBUG org.apache.kafka.common.metrics.Metrics - Added sensor with name request-time
2017-02-15 21:21:38.547 [main] DEBUG org.apache.kafka.common.metrics.Metrics - Added sensor with name produce-throttle-time
2017-02-15 21:21:38.548 [main] DEBUG org.apache.kafka.common.metrics.Metrics - Added sensor with name records-per-request
2017-02-15 21:21:38.548 [main] DEBUG org.apache.kafka.common.metrics.Metrics - Added sensor with name record-retries
2017-02-15 21:21:38.548 [main] DEBUG org.apache.kafka.common.metrics.Metrics - Added sensor with name errors
2017-02-15 21:21:38.548 [main] DEBUG org.apache.kafka.common.metrics.Metrics - Added sensor with name record-size-max
2017-02-15 21:21:38.552 [kafka-producer-network-thread | producer-1] DEBUG org.apache.kafka.clients.producer.internals.Sender - Starting Kafka producer I/O thread.
2017-02-15 21:21:38.557 [main] INFO  org.apache.kafka.common.utils.AppInfoParser - Kafka version : 0.10.1.0
2017-02-15 21:21:38.558 [main] INFO  org.apache.kafka.common.utils.AppInfoParser - Kafka commitId : 3402a74efb23d1d4
2017-02-15 21:21:38.558 [main] DEBUG org.apache.kafka.clients.producer.KafkaProducer - Kafka producer started
2017-02-15 21:21:51.888 [kafka-producer-network-thread | producer-1] DEBUG org.apache.kafka.clients.NetworkClient - Initialize connection to node -1 for sending metadata request
2017-02-15 21:21:51.888 [kafka-producer-network-thread | producer-1] DEBUG org.apache.kafka.clients.NetworkClient - Initiating connection to node -1 at 10.1.131.18:9092.
2017-02-15 21:21:51.930 [kafka-producer-network-thread | producer-1] DEBUG org.apache.kafka.common.metrics.Metrics - Added sensor with name node--1.bytes-sent
2017-02-15 21:21:51.930 [kafka-producer-network-thread | producer-1] DEBUG org.apache.kafka.common.metrics.Metrics - Added sensor with name node--1.bytes-received
2017-02-15 21:21:51.931 [kafka-producer-network-thread | producer-1] DEBUG org.apache.kafka.common.metrics.Metrics - Added sensor with name node--1.latency
2017-02-15 21:21:51.931 [kafka-producer-network-thread | producer-1] DEBUG org.apache.kafka.common.network.Selector - Created socket with SO_RCVBUF = 32768, SO_SNDBUF = 131072, SO_TIMEOUT = 0 to node -1
2017-02-15 21:21:51.931 [kafka-producer-network-thread | producer-1] DEBUG org.apache.kafka.clients.NetworkClient - Completed connection to node -1
2017-02-15 21:21:52.029 [kafka-producer-network-thread | producer-1] DEBUG org.apache.kafka.clients.NetworkClient - Sending metadata request {topics=[file_syn6]} to node -1
2017-02-15 21:21:52.102 [kafka-producer-network-thread | producer-1] DEBUG org.apache.kafka.clients.Metadata - Updated cluster metadata version 2 to Cluster(id = 5ynpwwfGT3KEdCwLvR2Jog, nodes = [10.1.131.18:9092 (id: 0 rack: null)], partitions = [Partition(topic = file_syn6, partition = 0, leader = 0, replicas = [0,], isr = [0,])])
2017-02-15 21:21:52.154 [kafka-producer-network-thread | producer-1] DEBUG org.apache.kafka.clients.NetworkClient - Initiating connection to node 0 at 10.1.131.18:9092.
2017-02-15 21:21:52.194 [kafka-producer-network-thread | producer-1] DEBUG org.apache.kafka.common.metrics.Metrics - Added sensor with name node-0.bytes-sent
2017-02-15 21:21:52.195 [kafka-producer-network-thread | producer-1] DEBUG org.apache.kafka.common.metrics.Metrics - Added sensor with name node-0.bytes-received
2017-02-15 21:21:52.195 [kafka-producer-network-thread | producer-1] DEBUG org.apache.kafka.common.metrics.Metrics - Added sensor with name node-0.latency
2017-02-15 21:21:52.196 [kafka-producer-network-thread | producer-1] DEBUG org.apache.kafka.common.network.Selector - Created socket with SO_RCVBUF = 32768, SO_SNDBUF = 131072, SO_TIMEOUT = 0 to node 0
2017-02-15 21:21:52.196 [kafka-producer-network-thread | producer-1] DEBUG org.apache.kafka.clients.NetworkClient - Completed connection to node 0
2017-02-15 21:21:52.196 [kafka-producer-network-thread | producer-1] DEBUG org.apache.kafka.common.metrics.Metrics - Added sensor with name topic.file_syn6.records-per-batch
2017-02-15 21:21:52.196 [kafka-producer-network-thread | producer-1] DEBUG org.apache.kafka.common.metrics.Metrics - Added sensor with name topic.file_syn6.bytes
2017-02-15 21:21:52.196 [kafka-producer-network-thread | producer-1] DEBUG org.apache.kafka.common.metrics.Metrics - Added sensor with name topic.file_syn6.compression-rate
2017-02-15 21:21:52.197 [kafka-producer-network-thread | producer-1] DEBUG org.apache.kafka.common.metrics.Metrics - Added sensor with name topic.file_syn6.record-retries
2017-02-15 21:21:52.197 [kafka-producer-network-thread | producer-1] DEBUG org.apache.kafka.common.metrics.Metrics - Added sensor with name topic.file_syn6.record-errors
2017-02-15 21:24:04.373 [main] INFO  org.apache.kafka.clients.producer.ProducerConfig - ProducerConfig values: 
	acks = 1
	batch.size = 16384
	block.on.buffer.full = false
	bootstrap.servers = [10.1.131.18:9092]
	buffer.memory = 33554432
	client.id = 
	compression.type = none
	connections.max.idle.ms = 540000
	interceptor.classes = null
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 0
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1000000000
	metadata.fetch.timeout.ms = 60000
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	receive.buffer.bytes = 32768
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 0
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	timeout.ms = 30000
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer

2017-02-15 21:24:04.438 [main] INFO  org.apache.kafka.clients.producer.ProducerConfig - ProducerConfig values: 
	acks = 1
	batch.size = 16384
	block.on.buffer.full = false
	bootstrap.servers = [10.1.131.18:9092]
	buffer.memory = 33554432
	client.id = producer-1
	compression.type = none
	connections.max.idle.ms = 540000
	interceptor.classes = null
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 0
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1000000000
	metadata.fetch.timeout.ms = 60000
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	receive.buffer.bytes = 32768
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 0
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	timeout.ms = 30000
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer

2017-02-15 21:24:04.461 [main] DEBUG org.apache.kafka.common.metrics.Metrics - Added sensor with name bufferpool-wait-time
2017-02-15 21:24:04.468 [main] DEBUG org.apache.kafka.common.metrics.Metrics - Added sensor with name buffer-exhausted-records
2017-02-15 21:24:04.475 [main] DEBUG org.apache.kafka.clients.Metadata - Updated cluster metadata version 1 to Cluster(id = null, nodes = [10.1.131.18:9092 (id: -1 rack: null)], partitions = [])
2017-02-15 21:24:04.500 [main] DEBUG org.apache.kafka.common.metrics.Metrics - Added sensor with name connections-closed:
2017-02-15 21:24:04.500 [main] DEBUG org.apache.kafka.common.metrics.Metrics - Added sensor with name connections-created:
2017-02-15 21:24:04.500 [main] DEBUG org.apache.kafka.common.metrics.Metrics - Added sensor with name bytes-sent-received:
2017-02-15 21:24:04.500 [main] DEBUG org.apache.kafka.common.metrics.Metrics - Added sensor with name bytes-sent:
2017-02-15 21:24:04.502 [main] DEBUG org.apache.kafka.common.metrics.Metrics - Added sensor with name bytes-received:
2017-02-15 21:24:04.502 [main] DEBUG org.apache.kafka.common.metrics.Metrics - Added sensor with name select-time:
2017-02-15 21:24:04.503 [main] DEBUG org.apache.kafka.common.metrics.Metrics - Added sensor with name io-time:
2017-02-15 21:24:04.511 [main] DEBUG org.apache.kafka.common.metrics.Metrics - Added sensor with name batch-size
2017-02-15 21:24:04.511 [main] DEBUG org.apache.kafka.common.metrics.Metrics - Added sensor with name compression-rate
2017-02-15 21:24:04.511 [main] DEBUG org.apache.kafka.common.metrics.Metrics - Added sensor with name queue-time
2017-02-15 21:24:04.512 [main] DEBUG org.apache.kafka.common.metrics.Metrics - Added sensor with name request-time
2017-02-15 21:24:04.512 [main] DEBUG org.apache.kafka.common.metrics.Metrics - Added sensor with name produce-throttle-time
2017-02-15 21:24:04.512 [main] DEBUG org.apache.kafka.common.metrics.Metrics - Added sensor with name records-per-request
2017-02-15 21:24:04.513 [main] DEBUG org.apache.kafka.common.metrics.Metrics - Added sensor with name record-retries
2017-02-15 21:24:04.513 [main] DEBUG org.apache.kafka.common.metrics.Metrics - Added sensor with name errors
2017-02-15 21:24:04.513 [main] DEBUG org.apache.kafka.common.metrics.Metrics - Added sensor with name record-size-max
2017-02-15 21:24:04.516 [kafka-producer-network-thread | producer-1] DEBUG org.apache.kafka.clients.producer.internals.Sender - Starting Kafka producer I/O thread.
2017-02-15 21:24:04.522 [main] INFO  org.apache.kafka.common.utils.AppInfoParser - Kafka version : 0.10.1.0
2017-02-15 21:24:04.523 [main] INFO  org.apache.kafka.common.utils.AppInfoParser - Kafka commitId : 3402a74efb23d1d4
2017-02-15 21:24:04.524 [main] DEBUG org.apache.kafka.clients.producer.KafkaProducer - Kafka producer started
2017-02-15 21:24:14.014 [kafka-producer-network-thread | producer-1] DEBUG org.apache.kafka.clients.NetworkClient - Initialize connection to node -1 for sending metadata request
2017-02-15 21:24:14.014 [kafka-producer-network-thread | producer-1] DEBUG org.apache.kafka.clients.NetworkClient - Initiating connection to node -1 at 10.1.131.18:9092.
2017-02-15 21:24:14.153 [kafka-producer-network-thread | producer-1] DEBUG org.apache.kafka.common.metrics.Metrics - Added sensor with name node--1.bytes-sent
2017-02-15 21:24:14.154 [kafka-producer-network-thread | producer-1] DEBUG org.apache.kafka.common.metrics.Metrics - Added sensor with name node--1.bytes-received
2017-02-15 21:24:14.154 [kafka-producer-network-thread | producer-1] DEBUG org.apache.kafka.common.metrics.Metrics - Added sensor with name node--1.latency
2017-02-15 21:24:14.155 [kafka-producer-network-thread | producer-1] DEBUG org.apache.kafka.common.network.Selector - Created socket with SO_RCVBUF = 32768, SO_SNDBUF = 131072, SO_TIMEOUT = 0 to node -1
2017-02-15 21:24:14.155 [kafka-producer-network-thread | producer-1] DEBUG org.apache.kafka.clients.NetworkClient - Completed connection to node -1
2017-02-15 21:24:14.255 [kafka-producer-network-thread | producer-1] DEBUG org.apache.kafka.clients.NetworkClient - Sending metadata request {topics=[file_syn7]} to node -1
2017-02-15 21:24:14.443 [kafka-producer-network-thread | producer-1] DEBUG org.apache.kafka.clients.Metadata - Updated cluster metadata version 2 to Cluster(id = 5ynpwwfGT3KEdCwLvR2Jog, nodes = [10.1.131.18:9092 (id: 0 rack: null)], partitions = [Partition(topic = file_syn7, partition = 0, leader = 0, replicas = [0,], isr = [0,])])
2017-02-15 21:24:14.895 [kafka-producer-network-thread | producer-1] DEBUG org.apache.kafka.clients.NetworkClient - Initiating connection to node 0 at 10.1.131.18:9092.
2017-02-15 21:24:14.948 [kafka-producer-network-thread | producer-1] DEBUG org.apache.kafka.common.metrics.Metrics - Added sensor with name node-0.bytes-sent
2017-02-15 21:24:14.949 [kafka-producer-network-thread | producer-1] DEBUG org.apache.kafka.common.metrics.Metrics - Added sensor with name node-0.bytes-received
2017-02-15 21:24:14.949 [kafka-producer-network-thread | producer-1] DEBUG org.apache.kafka.common.metrics.Metrics - Added sensor with name node-0.latency
2017-02-15 21:24:14.949 [kafka-producer-network-thread | producer-1] DEBUG org.apache.kafka.common.network.Selector - Created socket with SO_RCVBUF = 32768, SO_SNDBUF = 131072, SO_TIMEOUT = 0 to node 0
2017-02-15 21:24:14.949 [kafka-producer-network-thread | producer-1] DEBUG org.apache.kafka.clients.NetworkClient - Completed connection to node 0
2017-02-15 21:24:14.950 [kafka-producer-network-thread | producer-1] DEBUG org.apache.kafka.common.metrics.Metrics - Added sensor with name topic.file_syn7.records-per-batch
2017-02-15 21:24:14.950 [kafka-producer-network-thread | producer-1] DEBUG org.apache.kafka.common.metrics.Metrics - Added sensor with name topic.file_syn7.bytes
2017-02-15 21:24:14.950 [kafka-producer-network-thread | producer-1] DEBUG org.apache.kafka.common.metrics.Metrics - Added sensor with name topic.file_syn7.compression-rate
2017-02-15 21:24:14.951 [kafka-producer-network-thread | producer-1] DEBUG org.apache.kafka.common.metrics.Metrics - Added sensor with name topic.file_syn7.record-retries
2017-02-15 21:24:14.951 [kafka-producer-network-thread | producer-1] DEBUG org.apache.kafka.common.metrics.Metrics - Added sensor with name topic.file_syn7.record-errors
2017-02-15 21:29:25.518 [main] INFO  org.apache.kafka.clients.producer.ProducerConfig - ProducerConfig values: 
	acks = 1
	batch.size = 16384
	block.on.buffer.full = false
	bootstrap.servers = [10.1.131.18:9092]
	buffer.memory = 33554432
	client.id = 
	compression.type = none
	connections.max.idle.ms = 540000
	interceptor.classes = null
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 0
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1000000000
	metadata.fetch.timeout.ms = 60000
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	receive.buffer.bytes = 32768
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 0
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	timeout.ms = 30000
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer

2017-02-15 21:29:25.627 [main] INFO  org.apache.kafka.clients.producer.ProducerConfig - ProducerConfig values: 
	acks = 1
	batch.size = 16384
	block.on.buffer.full = false
	bootstrap.servers = [10.1.131.18:9092]
	buffer.memory = 33554432
	client.id = producer-1
	compression.type = none
	connections.max.idle.ms = 540000
	interceptor.classes = null
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 0
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1000000000
	metadata.fetch.timeout.ms = 60000
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	receive.buffer.bytes = 32768
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 0
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	timeout.ms = 30000
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer

2017-02-15 21:29:25.642 [main] DEBUG org.apache.kafka.common.metrics.Metrics - Added sensor with name bufferpool-wait-time
2017-02-15 21:29:25.652 [main] DEBUG org.apache.kafka.common.metrics.Metrics - Added sensor with name buffer-exhausted-records
2017-02-15 21:29:25.655 [main] DEBUG org.apache.kafka.clients.Metadata - Updated cluster metadata version 1 to Cluster(id = null, nodes = [10.1.131.18:9092 (id: -1 rack: null)], partitions = [])
2017-02-15 21:29:25.681 [main] DEBUG org.apache.kafka.common.metrics.Metrics - Added sensor with name connections-closed:
2017-02-15 21:29:25.682 [main] DEBUG org.apache.kafka.common.metrics.Metrics - Added sensor with name connections-created:
2017-02-15 21:29:25.682 [main] DEBUG org.apache.kafka.common.metrics.Metrics - Added sensor with name bytes-sent-received:
2017-02-15 21:29:25.683 [main] DEBUG org.apache.kafka.common.metrics.Metrics - Added sensor with name bytes-sent:
2017-02-15 21:29:25.684 [main] DEBUG org.apache.kafka.common.metrics.Metrics - Added sensor with name bytes-received:
2017-02-15 21:29:25.685 [main] DEBUG org.apache.kafka.common.metrics.Metrics - Added sensor with name select-time:
2017-02-15 21:29:25.685 [main] DEBUG org.apache.kafka.common.metrics.Metrics - Added sensor with name io-time:
2017-02-15 21:29:25.695 [main] DEBUG org.apache.kafka.common.metrics.Metrics - Added sensor with name batch-size
2017-02-15 21:29:25.695 [main] DEBUG org.apache.kafka.common.metrics.Metrics - Added sensor with name compression-rate
2017-02-15 21:29:25.696 [main] DEBUG org.apache.kafka.common.metrics.Metrics - Added sensor with name queue-time
2017-02-15 21:29:25.696 [main] DEBUG org.apache.kafka.common.metrics.Metrics - Added sensor with name request-time
2017-02-15 21:29:25.696 [main] DEBUG org.apache.kafka.common.metrics.Metrics - Added sensor with name produce-throttle-time
2017-02-15 21:29:25.697 [main] DEBUG org.apache.kafka.common.metrics.Metrics - Added sensor with name records-per-request
2017-02-15 21:29:25.697 [main] DEBUG org.apache.kafka.common.metrics.Metrics - Added sensor with name record-retries
2017-02-15 21:29:25.697 [main] DEBUG org.apache.kafka.common.metrics.Metrics - Added sensor with name errors
2017-02-15 21:29:25.697 [main] DEBUG org.apache.kafka.common.metrics.Metrics - Added sensor with name record-size-max
2017-02-15 21:29:25.700 [kafka-producer-network-thread | producer-1] DEBUG org.apache.kafka.clients.producer.internals.Sender - Starting Kafka producer I/O thread.
2017-02-15 21:29:25.707 [main] INFO  org.apache.kafka.common.utils.AppInfoParser - Kafka version : 0.10.1.0
2017-02-15 21:29:25.707 [main] INFO  org.apache.kafka.common.utils.AppInfoParser - Kafka commitId : 3402a74efb23d1d4
2017-02-15 21:29:25.708 [main] DEBUG org.apache.kafka.clients.producer.KafkaProducer - Kafka producer started
2017-02-15 21:29:31.246 [kafka-producer-network-thread | producer-1] DEBUG org.apache.kafka.clients.NetworkClient - Initialize connection to node -1 for sending metadata request
2017-02-15 21:29:31.246 [kafka-producer-network-thread | producer-1] DEBUG org.apache.kafka.clients.NetworkClient - Initiating connection to node -1 at 10.1.131.18:9092.
2017-02-15 21:29:31.288 [kafka-producer-network-thread | producer-1] DEBUG org.apache.kafka.common.metrics.Metrics - Added sensor with name node--1.bytes-sent
2017-02-15 21:29:31.289 [kafka-producer-network-thread | producer-1] DEBUG org.apache.kafka.common.metrics.Metrics - Added sensor with name node--1.bytes-received
2017-02-15 21:29:31.289 [kafka-producer-network-thread | producer-1] DEBUG org.apache.kafka.common.metrics.Metrics - Added sensor with name node--1.latency
2017-02-15 21:29:31.290 [kafka-producer-network-thread | producer-1] DEBUG org.apache.kafka.common.network.Selector - Created socket with SO_RCVBUF = 32768, SO_SNDBUF = 131072, SO_TIMEOUT = 0 to node -1
2017-02-15 21:29:31.290 [kafka-producer-network-thread | producer-1] DEBUG org.apache.kafka.clients.NetworkClient - Completed connection to node -1
2017-02-15 21:29:31.395 [kafka-producer-network-thread | producer-1] DEBUG org.apache.kafka.clients.NetworkClient - Sending metadata request {topics=[file_syn8]} to node -1
2017-02-15 21:29:31.478 [kafka-producer-network-thread | producer-1] DEBUG org.apache.kafka.clients.Metadata - Updated cluster metadata version 2 to Cluster(id = 5ynpwwfGT3KEdCwLvR2Jog, nodes = [10.1.131.18:9092 (id: 0 rack: null)], partitions = [Partition(topic = file_syn8, partition = 0, leader = 0, replicas = [0,], isr = [0,])])
2017-02-15 21:29:31.990 [kafka-producer-network-thread | producer-1] DEBUG org.apache.kafka.clients.NetworkClient - Initiating connection to node 0 at 10.1.131.18:9092.
2017-02-15 21:29:32.031 [kafka-producer-network-thread | producer-1] DEBUG org.apache.kafka.common.metrics.Metrics - Added sensor with name node-0.bytes-sent
2017-02-15 21:29:32.031 [kafka-producer-network-thread | producer-1] DEBUG org.apache.kafka.common.metrics.Metrics - Added sensor with name node-0.bytes-received
2017-02-15 21:29:32.031 [kafka-producer-network-thread | producer-1] DEBUG org.apache.kafka.common.metrics.Metrics - Added sensor with name node-0.latency
2017-02-15 21:29:32.032 [kafka-producer-network-thread | producer-1] DEBUG org.apache.kafka.common.network.Selector - Created socket with SO_RCVBUF = 32768, SO_SNDBUF = 131072, SO_TIMEOUT = 0 to node 0
2017-02-15 21:29:32.032 [kafka-producer-network-thread | producer-1] DEBUG org.apache.kafka.clients.NetworkClient - Completed connection to node 0
2017-02-15 21:29:32.032 [kafka-producer-network-thread | producer-1] DEBUG org.apache.kafka.common.metrics.Metrics - Added sensor with name topic.file_syn8.records-per-batch
2017-02-15 21:29:32.032 [kafka-producer-network-thread | producer-1] DEBUG org.apache.kafka.common.metrics.Metrics - Added sensor with name topic.file_syn8.bytes
2017-02-15 21:29:32.033 [kafka-producer-network-thread | producer-1] DEBUG org.apache.kafka.common.metrics.Metrics - Added sensor with name topic.file_syn8.compression-rate
2017-02-15 21:29:32.033 [kafka-producer-network-thread | producer-1] DEBUG org.apache.kafka.common.metrics.Metrics - Added sensor with name topic.file_syn8.record-retries
2017-02-15 21:29:32.033 [kafka-producer-network-thread | producer-1] DEBUG org.apache.kafka.common.metrics.Metrics - Added sensor with name topic.file_syn8.record-errors
2017-02-15 21:39:48.159 [main] INFO  org.apache.kafka.clients.producer.ProducerConfig - ProducerConfig values: 
	acks = 1
	batch.size = 16384
	block.on.buffer.full = false
	bootstrap.servers = [10.1.131.18:9092]
	buffer.memory = 33554432
	client.id = 
	compression.type = none
	connections.max.idle.ms = 540000
	interceptor.classes = null
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 0
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1000000000
	metadata.fetch.timeout.ms = 60000
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	receive.buffer.bytes = 32768
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 0
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	timeout.ms = 30000
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer

2017-02-15 21:39:48.440 [main] INFO  org.apache.kafka.clients.producer.ProducerConfig - ProducerConfig values: 
	acks = 1
	batch.size = 16384
	block.on.buffer.full = false
	bootstrap.servers = [10.1.131.18:9092]
	buffer.memory = 33554432
	client.id = producer-1
	compression.type = none
	connections.max.idle.ms = 540000
	interceptor.classes = null
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 0
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1000000000
	metadata.fetch.timeout.ms = 60000
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	receive.buffer.bytes = 32768
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 0
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	timeout.ms = 30000
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer

2017-02-15 21:39:48.475 [main] DEBUG org.apache.kafka.common.metrics.Metrics - Added sensor with name bufferpool-wait-time
2017-02-15 21:39:48.481 [main] DEBUG org.apache.kafka.common.metrics.Metrics - Added sensor with name buffer-exhausted-records
2017-02-15 21:39:48.484 [main] DEBUG org.apache.kafka.clients.Metadata - Updated cluster metadata version 1 to Cluster(id = null, nodes = [10.1.131.18:9092 (id: -1 rack: null)], partitions = [])
2017-02-15 21:39:48.514 [main] DEBUG org.apache.kafka.common.metrics.Metrics - Added sensor with name connections-closed:
2017-02-15 21:39:48.515 [main] DEBUG org.apache.kafka.common.metrics.Metrics - Added sensor with name connections-created:
2017-02-15 21:39:48.515 [main] DEBUG org.apache.kafka.common.metrics.Metrics - Added sensor with name bytes-sent-received:
2017-02-15 21:39:48.515 [main] DEBUG org.apache.kafka.common.metrics.Metrics - Added sensor with name bytes-sent:
2017-02-15 21:39:48.517 [main] DEBUG org.apache.kafka.common.metrics.Metrics - Added sensor with name bytes-received:
2017-02-15 21:39:48.517 [main] DEBUG org.apache.kafka.common.metrics.Metrics - Added sensor with name select-time:
2017-02-15 21:39:48.518 [main] DEBUG org.apache.kafka.common.metrics.Metrics - Added sensor with name io-time:
2017-02-15 21:39:48.526 [main] DEBUG org.apache.kafka.common.metrics.Metrics - Added sensor with name batch-size
2017-02-15 21:39:48.527 [main] DEBUG org.apache.kafka.common.metrics.Metrics - Added sensor with name compression-rate
2017-02-15 21:39:48.527 [main] DEBUG org.apache.kafka.common.metrics.Metrics - Added sensor with name queue-time
2017-02-15 21:39:48.527 [main] DEBUG org.apache.kafka.common.metrics.Metrics - Added sensor with name request-time
2017-02-15 21:39:48.528 [main] DEBUG org.apache.kafka.common.metrics.Metrics - Added sensor with name produce-throttle-time
2017-02-15 21:39:48.528 [main] DEBUG org.apache.kafka.common.metrics.Metrics - Added sensor with name records-per-request
2017-02-15 21:39:48.528 [main] DEBUG org.apache.kafka.common.metrics.Metrics - Added sensor with name record-retries
2017-02-15 21:39:48.528 [main] DEBUG org.apache.kafka.common.metrics.Metrics - Added sensor with name errors
2017-02-15 21:39:48.528 [main] DEBUG org.apache.kafka.common.metrics.Metrics - Added sensor with name record-size-max
2017-02-15 21:39:48.531 [kafka-producer-network-thread | producer-1] DEBUG org.apache.kafka.clients.producer.internals.Sender - Starting Kafka producer I/O thread.
2017-02-15 21:39:48.538 [main] INFO  org.apache.kafka.common.utils.AppInfoParser - Kafka version : 0.10.1.0
2017-02-15 21:39:48.538 [main] INFO  org.apache.kafka.common.utils.AppInfoParser - Kafka commitId : 3402a74efb23d1d4
2017-02-15 21:39:48.539 [main] DEBUG org.apache.kafka.clients.producer.KafkaProducer - Kafka producer started
2017-02-15 21:39:51.181 [kafka-producer-network-thread | producer-1] DEBUG org.apache.kafka.clients.NetworkClient - Initialize connection to node -1 for sending metadata request
2017-02-15 21:39:51.181 [kafka-producer-network-thread | producer-1] DEBUG org.apache.kafka.clients.NetworkClient - Initiating connection to node -1 at 10.1.131.18:9092.
2017-02-15 21:39:51.222 [kafka-producer-network-thread | producer-1] DEBUG org.apache.kafka.common.metrics.Metrics - Added sensor with name node--1.bytes-sent
2017-02-15 21:39:51.222 [kafka-producer-network-thread | producer-1] DEBUG org.apache.kafka.common.metrics.Metrics - Added sensor with name node--1.bytes-received
2017-02-15 21:39:51.223 [kafka-producer-network-thread | producer-1] DEBUG org.apache.kafka.common.metrics.Metrics - Added sensor with name node--1.latency
2017-02-15 21:39:51.223 [kafka-producer-network-thread | producer-1] DEBUG org.apache.kafka.common.network.Selector - Created socket with SO_RCVBUF = 32768, SO_SNDBUF = 131072, SO_TIMEOUT = 0 to node -1
2017-02-15 21:39:51.223 [kafka-producer-network-thread | producer-1] DEBUG org.apache.kafka.clients.NetworkClient - Completed connection to node -1
2017-02-15 21:39:51.340 [kafka-producer-network-thread | producer-1] DEBUG org.apache.kafka.clients.NetworkClient - Sending metadata request {topics=[file_syn9]} to node -1
2017-02-15 21:39:51.426 [kafka-producer-network-thread | producer-1] DEBUG org.apache.kafka.clients.Metadata - Updated cluster metadata version 2 to Cluster(id = 5ynpwwfGT3KEdCwLvR2Jog, nodes = [10.1.131.18:9092 (id: 0 rack: null)], partitions = [Partition(topic = file_syn9, partition = 0, leader = 0, replicas = [0,], isr = [0,])])
2017-02-15 21:39:51.602 [kafka-producer-network-thread | producer-1] DEBUG org.apache.kafka.clients.NetworkClient - Initiating connection to node 0 at 10.1.131.18:9092.
2017-02-15 21:39:51.642 [kafka-producer-network-thread | producer-1] DEBUG org.apache.kafka.common.metrics.Metrics - Added sensor with name node-0.bytes-sent
2017-02-15 21:39:51.642 [kafka-producer-network-thread | producer-1] DEBUG org.apache.kafka.common.metrics.Metrics - Added sensor with name node-0.bytes-received
2017-02-15 21:39:51.642 [kafka-producer-network-thread | producer-1] DEBUG org.apache.kafka.common.metrics.Metrics - Added sensor with name node-0.latency
2017-02-15 21:39:51.643 [kafka-producer-network-thread | producer-1] DEBUG org.apache.kafka.common.network.Selector - Created socket with SO_RCVBUF = 32768, SO_SNDBUF = 131072, SO_TIMEOUT = 0 to node 0
2017-02-15 21:39:51.643 [kafka-producer-network-thread | producer-1] DEBUG org.apache.kafka.clients.NetworkClient - Completed connection to node 0
2017-02-15 21:39:51.643 [kafka-producer-network-thread | producer-1] DEBUG org.apache.kafka.common.metrics.Metrics - Added sensor with name topic.file_syn9.records-per-batch
2017-02-15 21:39:51.643 [kafka-producer-network-thread | producer-1] DEBUG org.apache.kafka.common.metrics.Metrics - Added sensor with name topic.file_syn9.bytes
2017-02-15 21:39:51.643 [kafka-producer-network-thread | producer-1] DEBUG org.apache.kafka.common.metrics.Metrics - Added sensor with name topic.file_syn9.compression-rate
2017-02-15 21:39:51.644 [kafka-producer-network-thread | producer-1] DEBUG org.apache.kafka.common.metrics.Metrics - Added sensor with name topic.file_syn9.record-retries
2017-02-15 21:39:51.644 [kafka-producer-network-thread | producer-1] DEBUG org.apache.kafka.common.metrics.Metrics - Added sensor with name topic.file_syn9.record-errors
2017-02-15 21:50:10.481 [main] INFO  org.apache.kafka.clients.producer.ProducerConfig - ProducerConfig values: 
	acks = 1
	batch.size = 16384
	block.on.buffer.full = false
	bootstrap.servers = [10.1.131.18:9092]
	buffer.memory = 33554432
	client.id = 
	compression.type = none
	connections.max.idle.ms = 540000
	interceptor.classes = null
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 0
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1000000000
	metadata.fetch.timeout.ms = 60000
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	receive.buffer.bytes = 32768
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 0
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	timeout.ms = 30000
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer

2017-02-15 21:50:10.550 [main] INFO  org.apache.kafka.clients.producer.ProducerConfig - ProducerConfig values: 
	acks = 1
	batch.size = 16384
	block.on.buffer.full = false
	bootstrap.servers = [10.1.131.18:9092]
	buffer.memory = 33554432
	client.id = producer-1
	compression.type = none
	connections.max.idle.ms = 540000
	interceptor.classes = null
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 0
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1000000000
	metadata.fetch.timeout.ms = 60000
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	receive.buffer.bytes = 32768
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 0
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	timeout.ms = 30000
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer

2017-02-15 21:50:10.560 [main] DEBUG org.apache.kafka.common.metrics.Metrics - Added sensor with name bufferpool-wait-time
2017-02-15 21:50:10.566 [main] DEBUG org.apache.kafka.common.metrics.Metrics - Added sensor with name buffer-exhausted-records
2017-02-15 21:50:10.568 [main] DEBUG org.apache.kafka.clients.Metadata - Updated cluster metadata version 1 to Cluster(id = null, nodes = [10.1.131.18:9092 (id: -1 rack: null)], partitions = [])
2017-02-15 21:50:10.591 [main] DEBUG org.apache.kafka.common.metrics.Metrics - Added sensor with name connections-closed:
2017-02-15 21:50:10.591 [main] DEBUG org.apache.kafka.common.metrics.Metrics - Added sensor with name connections-created:
2017-02-15 21:50:10.591 [main] DEBUG org.apache.kafka.common.metrics.Metrics - Added sensor with name bytes-sent-received:
2017-02-15 21:50:10.592 [main] DEBUG org.apache.kafka.common.metrics.Metrics - Added sensor with name bytes-sent:
2017-02-15 21:50:10.593 [main] DEBUG org.apache.kafka.common.metrics.Metrics - Added sensor with name bytes-received:
2017-02-15 21:50:10.594 [main] DEBUG org.apache.kafka.common.metrics.Metrics - Added sensor with name select-time:
2017-02-15 21:50:10.594 [main] DEBUG org.apache.kafka.common.metrics.Metrics - Added sensor with name io-time:
2017-02-15 21:50:10.601 [main] DEBUG org.apache.kafka.common.metrics.Metrics - Added sensor with name batch-size
2017-02-15 21:50:10.601 [main] DEBUG org.apache.kafka.common.metrics.Metrics - Added sensor with name compression-rate
2017-02-15 21:50:10.602 [main] DEBUG org.apache.kafka.common.metrics.Metrics - Added sensor with name queue-time
2017-02-15 21:50:10.602 [main] DEBUG org.apache.kafka.common.metrics.Metrics - Added sensor with name request-time
2017-02-15 21:50:10.602 [main] DEBUG org.apache.kafka.common.metrics.Metrics - Added sensor with name produce-throttle-time
2017-02-15 21:50:10.603 [main] DEBUG org.apache.kafka.common.metrics.Metrics - Added sensor with name records-per-request
2017-02-15 21:50:10.603 [main] DEBUG org.apache.kafka.common.metrics.Metrics - Added sensor with name record-retries
2017-02-15 21:50:10.603 [main] DEBUG org.apache.kafka.common.metrics.Metrics - Added sensor with name errors
2017-02-15 21:50:10.603 [main] DEBUG org.apache.kafka.common.metrics.Metrics - Added sensor with name record-size-max
2017-02-15 21:50:10.606 [kafka-producer-network-thread | producer-1] DEBUG org.apache.kafka.clients.producer.internals.Sender - Starting Kafka producer I/O thread.
2017-02-15 21:50:10.611 [main] INFO  org.apache.kafka.common.utils.AppInfoParser - Kafka version : 0.10.1.0
2017-02-15 21:50:10.611 [main] INFO  org.apache.kafka.common.utils.AppInfoParser - Kafka commitId : 3402a74efb23d1d4
2017-02-15 21:50:10.612 [main] DEBUG org.apache.kafka.clients.producer.KafkaProducer - Kafka producer started
2017-02-15 21:50:13.852 [kafka-producer-network-thread | producer-1] DEBUG org.apache.kafka.clients.NetworkClient - Initialize connection to node -1 for sending metadata request
2017-02-15 21:50:13.852 [kafka-producer-network-thread | producer-1] DEBUG org.apache.kafka.clients.NetworkClient - Initiating connection to node -1 at 10.1.131.18:9092.
2017-02-15 21:50:13.893 [kafka-producer-network-thread | producer-1] DEBUG org.apache.kafka.common.metrics.Metrics - Added sensor with name node--1.bytes-sent
2017-02-15 21:50:13.893 [kafka-producer-network-thread | producer-1] DEBUG org.apache.kafka.common.metrics.Metrics - Added sensor with name node--1.bytes-received
2017-02-15 21:50:13.893 [kafka-producer-network-thread | producer-1] DEBUG org.apache.kafka.common.metrics.Metrics - Added sensor with name node--1.latency
2017-02-15 21:50:13.894 [kafka-producer-network-thread | producer-1] DEBUG org.apache.kafka.common.network.Selector - Created socket with SO_RCVBUF = 32768, SO_SNDBUF = 131072, SO_TIMEOUT = 0 to node -1
2017-02-15 21:50:13.894 [kafka-producer-network-thread | producer-1] DEBUG org.apache.kafka.clients.NetworkClient - Completed connection to node -1
2017-02-15 21:50:14.004 [kafka-producer-network-thread | producer-1] DEBUG org.apache.kafka.clients.NetworkClient - Sending metadata request {topics=[file_syn10]} to node -1
2017-02-15 21:50:14.076 [kafka-producer-network-thread | producer-1] DEBUG org.apache.kafka.clients.Metadata - Updated cluster metadata version 2 to Cluster(id = 5ynpwwfGT3KEdCwLvR2Jog, nodes = [10.1.131.18:9092 (id: 0 rack: null)], partitions = [Partition(topic = file_syn10, partition = 0, leader = 0, replicas = [0,], isr = [0,])])
2017-02-15 21:50:14.132 [kafka-producer-network-thread | producer-1] DEBUG org.apache.kafka.clients.NetworkClient - Initiating connection to node 0 at 10.1.131.18:9092.
2017-02-15 21:50:14.171 [kafka-producer-network-thread | producer-1] DEBUG org.apache.kafka.common.metrics.Metrics - Added sensor with name node-0.bytes-sent
2017-02-15 21:50:14.172 [kafka-producer-network-thread | producer-1] DEBUG org.apache.kafka.common.metrics.Metrics - Added sensor with name node-0.bytes-received
2017-02-15 21:50:14.172 [kafka-producer-network-thread | producer-1] DEBUG org.apache.kafka.common.metrics.Metrics - Added sensor with name node-0.latency
2017-02-15 21:50:14.173 [kafka-producer-network-thread | producer-1] DEBUG org.apache.kafka.common.network.Selector - Created socket with SO_RCVBUF = 32768, SO_SNDBUF = 131072, SO_TIMEOUT = 0 to node 0
2017-02-15 21:50:14.173 [kafka-producer-network-thread | producer-1] DEBUG org.apache.kafka.clients.NetworkClient - Completed connection to node 0
2017-02-15 21:50:14.173 [kafka-producer-network-thread | producer-1] DEBUG org.apache.kafka.common.metrics.Metrics - Added sensor with name topic.file_syn10.records-per-batch
2017-02-15 21:50:14.173 [kafka-producer-network-thread | producer-1] DEBUG org.apache.kafka.common.metrics.Metrics - Added sensor with name topic.file_syn10.bytes
2017-02-15 21:50:14.174 [kafka-producer-network-thread | producer-1] DEBUG org.apache.kafka.common.metrics.Metrics - Added sensor with name topic.file_syn10.compression-rate
2017-02-15 21:50:14.174 [kafka-producer-network-thread | producer-1] DEBUG org.apache.kafka.common.metrics.Metrics - Added sensor with name topic.file_syn10.record-retries
2017-02-15 21:50:14.174 [kafka-producer-network-thread | producer-1] DEBUG org.apache.kafka.common.metrics.Metrics - Added sensor with name topic.file_syn10.record-errors
2017-02-15 21:53:05.351 [main] INFO  org.apache.kafka.clients.producer.ProducerConfig - ProducerConfig values: 
	acks = 1
	batch.size = 16384
	block.on.buffer.full = false
	bootstrap.servers = [10.1.131.18:9092]
	buffer.memory = 33554432
	client.id = 
	compression.type = none
	connections.max.idle.ms = 540000
	interceptor.classes = null
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 0
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1000000000
	metadata.fetch.timeout.ms = 60000
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	receive.buffer.bytes = 32768
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 0
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	timeout.ms = 30000
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer

2017-02-15 21:53:05.422 [main] INFO  org.apache.kafka.clients.producer.ProducerConfig - ProducerConfig values: 
	acks = 1
	batch.size = 16384
	block.on.buffer.full = false
	bootstrap.servers = [10.1.131.18:9092]
	buffer.memory = 33554432
	client.id = producer-1
	compression.type = none
	connections.max.idle.ms = 540000
	interceptor.classes = null
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 0
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1000000000
	metadata.fetch.timeout.ms = 60000
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	receive.buffer.bytes = 32768
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 0
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	timeout.ms = 30000
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer

2017-02-15 21:53:05.435 [main] DEBUG org.apache.kafka.common.metrics.Metrics - Added sensor with name bufferpool-wait-time
2017-02-15 21:53:05.442 [main] DEBUG org.apache.kafka.common.metrics.Metrics - Added sensor with name buffer-exhausted-records
2017-02-15 21:53:05.446 [main] DEBUG org.apache.kafka.clients.Metadata - Updated cluster metadata version 1 to Cluster(id = null, nodes = [10.1.131.18:9092 (id: -1 rack: null)], partitions = [])
2017-02-15 21:53:05.471 [main] DEBUG org.apache.kafka.common.metrics.Metrics - Added sensor with name connections-closed:
2017-02-15 21:53:05.472 [main] DEBUG org.apache.kafka.common.metrics.Metrics - Added sensor with name connections-created:
2017-02-15 21:53:05.472 [main] DEBUG org.apache.kafka.common.metrics.Metrics - Added sensor with name bytes-sent-received:
2017-02-15 21:53:05.472 [main] DEBUG org.apache.kafka.common.metrics.Metrics - Added sensor with name bytes-sent:
2017-02-15 21:53:05.474 [main] DEBUG org.apache.kafka.common.metrics.Metrics - Added sensor with name bytes-received:
2017-02-15 21:53:05.474 [main] DEBUG org.apache.kafka.common.metrics.Metrics - Added sensor with name select-time:
2017-02-15 21:53:05.474 [main] DEBUG org.apache.kafka.common.metrics.Metrics - Added sensor with name io-time:
2017-02-15 21:53:05.482 [main] DEBUG org.apache.kafka.common.metrics.Metrics - Added sensor with name batch-size
2017-02-15 21:53:05.482 [main] DEBUG org.apache.kafka.common.metrics.Metrics - Added sensor with name compression-rate
2017-02-15 21:53:05.482 [main] DEBUG org.apache.kafka.common.metrics.Metrics - Added sensor with name queue-time
2017-02-15 21:53:05.483 [main] DEBUG org.apache.kafka.common.metrics.Metrics - Added sensor with name request-time
2017-02-15 21:53:05.483 [main] DEBUG org.apache.kafka.common.metrics.Metrics - Added sensor with name produce-throttle-time
2017-02-15 21:53:05.483 [main] DEBUG org.apache.kafka.common.metrics.Metrics - Added sensor with name records-per-request
2017-02-15 21:53:05.484 [main] DEBUG org.apache.kafka.common.metrics.Metrics - Added sensor with name record-retries
2017-02-15 21:53:05.484 [main] DEBUG org.apache.kafka.common.metrics.Metrics - Added sensor with name errors
2017-02-15 21:53:05.484 [main] DEBUG org.apache.kafka.common.metrics.Metrics - Added sensor with name record-size-max
2017-02-15 21:53:05.487 [kafka-producer-network-thread | producer-1] DEBUG org.apache.kafka.clients.producer.internals.Sender - Starting Kafka producer I/O thread.
2017-02-15 21:53:05.495 [main] INFO  org.apache.kafka.common.utils.AppInfoParser - Kafka version : 0.10.1.0
2017-02-15 21:53:05.496 [main] INFO  org.apache.kafka.common.utils.AppInfoParser - Kafka commitId : 3402a74efb23d1d4
2017-02-15 21:53:05.498 [main] DEBUG org.apache.kafka.clients.producer.KafkaProducer - Kafka producer started
2017-02-15 21:53:08.337 [kafka-producer-network-thread | producer-1] DEBUG org.apache.kafka.clients.NetworkClient - Initialize connection to node -1 for sending metadata request
2017-02-15 21:53:08.337 [kafka-producer-network-thread | producer-1] DEBUG org.apache.kafka.clients.NetworkClient - Initiating connection to node -1 at 10.1.131.18:9092.
2017-02-15 21:53:08.380 [kafka-producer-network-thread | producer-1] DEBUG org.apache.kafka.common.metrics.Metrics - Added sensor with name node--1.bytes-sent
2017-02-15 21:53:08.381 [kafka-producer-network-thread | producer-1] DEBUG org.apache.kafka.common.metrics.Metrics - Added sensor with name node--1.bytes-received
2017-02-15 21:53:08.381 [kafka-producer-network-thread | producer-1] DEBUG org.apache.kafka.common.metrics.Metrics - Added sensor with name node--1.latency
2017-02-15 21:53:08.382 [kafka-producer-network-thread | producer-1] DEBUG org.apache.kafka.common.network.Selector - Created socket with SO_RCVBUF = 32768, SO_SNDBUF = 131072, SO_TIMEOUT = 0 to node -1
2017-02-15 21:53:08.382 [kafka-producer-network-thread | producer-1] DEBUG org.apache.kafka.clients.NetworkClient - Completed connection to node -1
2017-02-15 21:53:08.499 [kafka-producer-network-thread | producer-1] DEBUG org.apache.kafka.clients.NetworkClient - Sending metadata request {topics=[file_syn11]} to node -1
2017-02-15 21:53:08.575 [kafka-producer-network-thread | producer-1] DEBUG org.apache.kafka.clients.Metadata - Updated cluster metadata version 2 to Cluster(id = 5ynpwwfGT3KEdCwLvR2Jog, nodes = [10.1.131.18:9092 (id: 0 rack: null)], partitions = [Partition(topic = file_syn11, partition = 0, leader = 0, replicas = [0,], isr = [0,])])
2017-02-15 21:53:08.632 [kafka-producer-network-thread | producer-1] DEBUG org.apache.kafka.clients.NetworkClient - Initiating connection to node 0 at 10.1.131.18:9092.
2017-02-15 21:53:08.672 [kafka-producer-network-thread | producer-1] DEBUG org.apache.kafka.common.metrics.Metrics - Added sensor with name node-0.bytes-sent
2017-02-15 21:53:08.673 [kafka-producer-network-thread | producer-1] DEBUG org.apache.kafka.common.metrics.Metrics - Added sensor with name node-0.bytes-received
2017-02-15 21:53:08.673 [kafka-producer-network-thread | producer-1] DEBUG org.apache.kafka.common.metrics.Metrics - Added sensor with name node-0.latency
2017-02-15 21:53:08.673 [kafka-producer-network-thread | producer-1] DEBUG org.apache.kafka.common.network.Selector - Created socket with SO_RCVBUF = 32768, SO_SNDBUF = 131072, SO_TIMEOUT = 0 to node 0
2017-02-15 21:53:08.673 [kafka-producer-network-thread | producer-1] DEBUG org.apache.kafka.clients.NetworkClient - Completed connection to node 0
2017-02-15 21:53:08.674 [kafka-producer-network-thread | producer-1] DEBUG org.apache.kafka.common.metrics.Metrics - Added sensor with name topic.file_syn11.records-per-batch
2017-02-15 21:53:08.674 [kafka-producer-network-thread | producer-1] DEBUG org.apache.kafka.common.metrics.Metrics - Added sensor with name topic.file_syn11.bytes
2017-02-15 21:53:08.674 [kafka-producer-network-thread | producer-1] DEBUG org.apache.kafka.common.metrics.Metrics - Added sensor with name topic.file_syn11.compression-rate
2017-02-15 21:53:08.674 [kafka-producer-network-thread | producer-1] DEBUG org.apache.kafka.common.metrics.Metrics - Added sensor with name topic.file_syn11.record-retries
2017-02-15 21:53:08.675 [kafka-producer-network-thread | producer-1] DEBUG org.apache.kafka.common.metrics.Metrics - Added sensor with name topic.file_syn11.record-errors
2017-02-15 21:58:08.542 [kafka-producer-network-thread | producer-1] DEBUG org.apache.kafka.clients.NetworkClient - Sending metadata request {topics=[file_syn11]} to node 0
2017-02-15 21:58:08.582 [kafka-producer-network-thread | producer-1] DEBUG org.apache.kafka.clients.Metadata - Updated cluster metadata version 3 to Cluster(id = 5ynpwwfGT3KEdCwLvR2Jog, nodes = [10.1.131.18:9092 (id: 0 rack: null)], partitions = [Partition(topic = file_syn11, partition = 0, leader = 0, replicas = [0,], isr = [0,])])
2017-02-15 22:04:36.139 [main] INFO  org.apache.kafka.clients.producer.ProducerConfig - ProducerConfig values: 
	acks = 1
	batch.size = 16384
	block.on.buffer.full = false
	bootstrap.servers = [10.1.131.18:9092]
	buffer.memory = 33554432
	client.id = 
	compression.type = none
	connections.max.idle.ms = 540000
	interceptor.classes = null
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 0
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1000000000
	metadata.fetch.timeout.ms = 60000
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	receive.buffer.bytes = 32768
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 0
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	timeout.ms = 30000
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer

2017-02-15 22:04:36.197 [main] INFO  org.apache.kafka.clients.producer.ProducerConfig - ProducerConfig values: 
	acks = 1
	batch.size = 16384
	block.on.buffer.full = false
	bootstrap.servers = [10.1.131.18:9092]
	buffer.memory = 33554432
	client.id = producer-1
	compression.type = none
	connections.max.idle.ms = 540000
	interceptor.classes = null
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 0
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1000000000
	metadata.fetch.timeout.ms = 60000
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	receive.buffer.bytes = 32768
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 0
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	timeout.ms = 30000
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer

2017-02-15 22:04:36.214 [main] DEBUG org.apache.kafka.common.metrics.Metrics - Added sensor with name bufferpool-wait-time
2017-02-15 22:04:36.221 [main] DEBUG org.apache.kafka.common.metrics.Metrics - Added sensor with name buffer-exhausted-records
2017-02-15 22:04:36.224 [main] DEBUG org.apache.kafka.clients.Metadata - Updated cluster metadata version 1 to Cluster(id = null, nodes = [10.1.131.18:9092 (id: -1 rack: null)], partitions = [])
2017-02-15 22:04:36.251 [main] DEBUG org.apache.kafka.common.metrics.Metrics - Added sensor with name connections-closed:
2017-02-15 22:04:36.251 [main] DEBUG org.apache.kafka.common.metrics.Metrics - Added sensor with name connections-created:
2017-02-15 22:04:36.251 [main] DEBUG org.apache.kafka.common.metrics.Metrics - Added sensor with name bytes-sent-received:
2017-02-15 22:04:36.251 [main] DEBUG org.apache.kafka.common.metrics.Metrics - Added sensor with name bytes-sent:
2017-02-15 22:04:36.253 [main] DEBUG org.apache.kafka.common.metrics.Metrics - Added sensor with name bytes-received:
2017-02-15 22:04:36.253 [main] DEBUG org.apache.kafka.common.metrics.Metrics - Added sensor with name select-time:
2017-02-15 22:04:36.254 [main] DEBUG org.apache.kafka.common.metrics.Metrics - Added sensor with name io-time:
2017-02-15 22:04:36.260 [main] DEBUG org.apache.kafka.common.metrics.Metrics - Added sensor with name batch-size
2017-02-15 22:04:36.260 [main] DEBUG org.apache.kafka.common.metrics.Metrics - Added sensor with name compression-rate
2017-02-15 22:04:36.260 [main] DEBUG org.apache.kafka.common.metrics.Metrics - Added sensor with name queue-time
2017-02-15 22:04:36.261 [main] DEBUG org.apache.kafka.common.metrics.Metrics - Added sensor with name request-time
2017-02-15 22:04:36.261 [main] DEBUG org.apache.kafka.common.metrics.Metrics - Added sensor with name produce-throttle-time
2017-02-15 22:04:36.261 [main] DEBUG org.apache.kafka.common.metrics.Metrics - Added sensor with name records-per-request
2017-02-15 22:04:36.262 [main] DEBUG org.apache.kafka.common.metrics.Metrics - Added sensor with name record-retries
2017-02-15 22:04:36.262 [main] DEBUG org.apache.kafka.common.metrics.Metrics - Added sensor with name errors
2017-02-15 22:04:36.262 [main] DEBUG org.apache.kafka.common.metrics.Metrics - Added sensor with name record-size-max
2017-02-15 22:04:36.265 [kafka-producer-network-thread | producer-1] DEBUG org.apache.kafka.clients.producer.internals.Sender - Starting Kafka producer I/O thread.
2017-02-15 22:04:36.272 [main] INFO  org.apache.kafka.common.utils.AppInfoParser - Kafka version : 0.10.1.0
2017-02-15 22:04:36.273 [main] INFO  org.apache.kafka.common.utils.AppInfoParser - Kafka commitId : 3402a74efb23d1d4
2017-02-15 22:04:36.274 [main] DEBUG org.apache.kafka.clients.producer.KafkaProducer - Kafka producer started
2017-02-15 22:04:49.947 [kafka-producer-network-thread | producer-1] DEBUG org.apache.kafka.clients.NetworkClient - Initialize connection to node -1 for sending metadata request
2017-02-15 22:04:49.947 [kafka-producer-network-thread | producer-1] DEBUG org.apache.kafka.clients.NetworkClient - Initiating connection to node -1 at 10.1.131.18:9092.
2017-02-15 22:04:50.005 [kafka-producer-network-thread | producer-1] DEBUG org.apache.kafka.common.metrics.Metrics - Added sensor with name node--1.bytes-sent
2017-02-15 22:04:50.006 [kafka-producer-network-thread | producer-1] DEBUG org.apache.kafka.common.metrics.Metrics - Added sensor with name node--1.bytes-received
2017-02-15 22:04:50.006 [kafka-producer-network-thread | producer-1] DEBUG org.apache.kafka.common.metrics.Metrics - Added sensor with name node--1.latency
2017-02-15 22:04:50.007 [kafka-producer-network-thread | producer-1] DEBUG org.apache.kafka.common.network.Selector - Created socket with SO_RCVBUF = 32768, SO_SNDBUF = 131072, SO_TIMEOUT = 0 to node -1
2017-02-15 22:04:50.007 [kafka-producer-network-thread | producer-1] DEBUG org.apache.kafka.clients.NetworkClient - Completed connection to node -1
2017-02-15 22:04:50.090 [kafka-producer-network-thread | producer-1] DEBUG org.apache.kafka.clients.NetworkClient - Sending metadata request {topics=[file_syn12]} to node -1
2017-02-15 22:04:50.242 [kafka-producer-network-thread | producer-1] DEBUG org.apache.kafka.clients.Metadata - Updated cluster metadata version 2 to Cluster(id = 5ynpwwfGT3KEdCwLvR2Jog, nodes = [10.1.131.18:9092 (id: 0 rack: null)], partitions = [Partition(topic = file_syn12, partition = 0, leader = 0, replicas = [0,], isr = [0,])])
2017-02-15 22:04:50.260 [kafka-producer-network-thread | producer-1] DEBUG org.apache.kafka.clients.NetworkClient - Initiating connection to node 0 at 10.1.131.18:9092.
2017-02-15 22:04:50.349 [kafka-producer-network-thread | producer-1] DEBUG org.apache.kafka.common.metrics.Metrics - Added sensor with name node-0.bytes-sent
2017-02-15 22:04:50.349 [kafka-producer-network-thread | producer-1] DEBUG org.apache.kafka.common.metrics.Metrics - Added sensor with name node-0.bytes-received
2017-02-15 22:04:50.350 [kafka-producer-network-thread | producer-1] DEBUG org.apache.kafka.common.metrics.Metrics - Added sensor with name node-0.latency
2017-02-15 22:04:50.350 [kafka-producer-network-thread | producer-1] DEBUG org.apache.kafka.common.network.Selector - Created socket with SO_RCVBUF = 32768, SO_SNDBUF = 131072, SO_TIMEOUT = 0 to node 0
2017-02-15 22:04:50.351 [kafka-producer-network-thread | producer-1] DEBUG org.apache.kafka.clients.NetworkClient - Completed connection to node 0
2017-02-15 22:04:50.351 [kafka-producer-network-thread | producer-1] DEBUG org.apache.kafka.common.metrics.Metrics - Added sensor with name topic.file_syn12.records-per-batch
2017-02-15 22:04:50.352 [kafka-producer-network-thread | producer-1] DEBUG org.apache.kafka.common.metrics.Metrics - Added sensor with name topic.file_syn12.bytes
2017-02-15 22:04:50.352 [kafka-producer-network-thread | producer-1] DEBUG org.apache.kafka.common.metrics.Metrics - Added sensor with name topic.file_syn12.compression-rate
2017-02-15 22:04:50.352 [kafka-producer-network-thread | producer-1] DEBUG org.apache.kafka.common.metrics.Metrics - Added sensor with name topic.file_syn12.record-retries
2017-02-15 22:04:50.352 [kafka-producer-network-thread | producer-1] DEBUG org.apache.kafka.common.metrics.Metrics - Added sensor with name topic.file_syn12.record-errors
